{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Copie de generate-embeddings.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"CT3SsPNNO5_i","colab_type":"code","colab":{}},"source":["# Copyright (c) 2019-present, Facebook, Inc.\n","# All rights reserved.\n","#\n","# This source code is licensed under the license found in the\n","# LICENSE file in the root directory of this source tree.\n","#"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5VYxLBeBO5_m","colab_type":"code","colab":{}},"source":["#\n","# Code to generate sentence representations from a pretrained model.\n","# This can be used to initialize a cross-lingual classifier, for instance.\n","#"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YyyjVMkGPLGc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"4893d787-a271-4726-cfcf-c47cb60c2e8d","executionInfo":{"status":"ok","timestamp":1587799974365,"user_tz":-120,"elapsed":48487,"user":{"displayName":"Pascal Tikeng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwUG1KwvT0FSpaKD7QYyfcxFH68TlCegHG8wC1=s64","userId":"06092546780793260792"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6V4ErNirPWY0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"139d6a68-1eb3-4c7a-d9a4-32adf39f4a8a","executionInfo":{"status":"ok","timestamp":1587799979879,"user_tz":-120,"elapsed":3315,"user":{"displayName":"Pascal Tikeng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwUG1KwvT0FSpaKD7QYyfcxFH68TlCegHG8wC1=s64","userId":"06092546780793260792"}}},"source":["% bookmark HOME \"/content/drive/My Drive/African_Translator/from_github/XLM\" \n","%cd -b HOME"],"execution_count":2,"outputs":[{"output_type":"stream","text":["(bookmark:HOME) -> /content/drive/My Drive/African_Translator/from_github/XLM\n","/content/drive/.shortcut-targets-by-id/1PdPd2d1303vfDNzoJKH48Ww6NcPS5YrJ/African_Translator/from_github/XLM\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NFpEl1GUO5_p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"eb88d400-6bb3-4ca4-e876-3e90d5f8cd4e","executionInfo":{"status":"ok","timestamp":1587800002392,"user_tz":-120,"elapsed":18873,"user":{"displayName":"Pascal Tikeng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwUG1KwvT0FSpaKD7QYyfcxFH68TlCegHG8wC1=s64","userId":"06092546780793260792"}}},"source":["import os\n","import torch\n","\n","from src.utils import AttrDict\n","from src.data.dictionary import Dictionary, BOS_WORD, EOS_WORD, PAD_WORD, UNK_WORD, MASK_WORD\n","from src.model.transformer import TransformerModel"],"execution_count":3,"outputs":[{"output_type":"stream","text":["FAISS library was not found.\n","FAISS not available. Switching to standard nearest neighbors search implementation.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"fJLVF4R5O5_s","colab_type":"text"},"source":["## Reload a pretrained model"]},{"cell_type":"code","metadata":{"id":"MJDNtrOiO5_t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"7201b4ea-8ec0-4a9e-ef1c-060ce43ae730","executionInfo":{"status":"ok","timestamp":1587800030971,"user_tz":-120,"elapsed":22889,"user":{"displayName":"Pascal Tikeng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwUG1KwvT0FSpaKD7QYyfcxFH68TlCegHG8wC1=s64","userId":"06092546780793260792"}}},"source":["#model_path = 'models/mlm_100_1280.pth'\n","model_path = '/content/drive/My Drive/African_Translator/from_github/XLM/dumped/test_enfr_mlm/16r7b9ka67/best-valid_mlm_ppl.pth'\n","reloaded = torch.load(model_path)\n","params = AttrDict(reloaded['params'])\n","print(\"Supported languages: %s\" % \", \".join(params.lang2id.keys()))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Supported languages: en, fr\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cxwfUdAlO5_v","colab_type":"text"},"source":["## Build dictionary / update parameters / build model"]},{"cell_type":"code","metadata":{"id":"rd_Q3482O5_w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"28bc975d-d468-4841-c9d7-87435fca9626","executionInfo":{"status":"ok","timestamp":1587800869569,"user_tz":-120,"elapsed":2309,"user":{"displayName":"Pascal Tikeng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwUG1KwvT0FSpaKD7QYyfcxFH68TlCegHG8wC1=s64","userId":"06092546780793260792"}}},"source":["# build dictionary / update parameters\n","dico = Dictionary(reloaded['dico_id2word'], reloaded['dico_word2id'], reloaded['dico_counts'])\n","params.n_words = len(dico)\n","params.bos_index = dico.index(BOS_WORD)\n","params.eos_index = dico.index(EOS_WORD)\n","params.pad_index = dico.index(PAD_WORD)\n","params.unk_index = dico.index(UNK_WORD)\n","params.mask_index = dico.index(MASK_WORD)\n","\n","# build model / reload weights\n","model = TransformerModel(params = params, dico = dico, is_encoder = True, with_output = True)\n","model.eval()\n","model.load_state_dict(reloaded['model'])"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"URFKx3vbSw9o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"90b23594-cc76-41d4-e6ca-61cb068f1978","executionInfo":{"status":"ok","timestamp":1587800650606,"user_tz":-120,"elapsed":1870,"user":{"displayName":"Pascal Tikeng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwUG1KwvT0FSpaKD7QYyfcxFH68TlCegHG8wC1=s64","userId":"06092546780793260792"}}},"source":["print(model)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["TransformerModel(\n","  (position_embeddings): Embedding(512, 1024)\n","  (lang_embeddings): Embedding(2, 1024)\n","  (embeddings): Embedding(9659, 1024, padding_idx=2)\n","  (layer_norm_emb): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","  (attentions): ModuleList(\n","    (0): MultiHeadAttention(\n","      (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","      (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","      (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","      (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","    )\n","    (1): MultiHeadAttention(\n","      (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","      (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","      (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","      (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","    )\n","    (2): MultiHeadAttention(\n","      (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","      (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","      (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","      (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","    )\n","    (3): MultiHeadAttention(\n","      (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","      (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","      (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","      (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","    )\n","    (4): MultiHeadAttention(\n","      (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","      (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","      (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","      (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","    )\n","    (5): MultiHeadAttention(\n","      (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","      (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","      (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","      (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","    )\n","  )\n","  (layer_norm1): ModuleList(\n","    (0): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","    (1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","    (2): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","    (3): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","    (4): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","    (5): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","  )\n","  (ffns): ModuleList(\n","    (0): TransformerFFN(\n","      (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n","      (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n","    )\n","    (1): TransformerFFN(\n","      (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n","      (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n","    )\n","    (2): TransformerFFN(\n","      (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n","      (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n","    )\n","    (3): TransformerFFN(\n","      (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n","      (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n","    )\n","    (4): TransformerFFN(\n","      (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n","      (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n","    )\n","    (5): TransformerFFN(\n","      (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n","      (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n","    )\n","  )\n","  (layer_norm2): ModuleList(\n","    (0): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","    (1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","    (2): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","    (3): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","    (4): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","    (5): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","  )\n","  (memories): ModuleDict()\n","  (pred_layer): PredLayer(\n","    (proj): Linear(in_features=1024, out_features=9659, bias=True)\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1bVQycQyO5_y","colab_type":"text"},"source":["\n","## Get sentence representations"]},{"cell_type":"markdown","metadata":{"id":"lEMO-kHqO5_z","colab_type":"text"},"source":["Sentences have to be in the BPE format, i.e. tokenized sentences on which you applied fastBPE.\n","\n","Below you can see an example for English and French sentences."]},{"cell_type":"code","metadata":{"id":"yCAjUQwFO5_z","colab_type":"code","colab":{}},"source":["# Below is one way to bpe-ize sentences\n","codes = \"\" # path to the codes of the model\n","fastbpe = os.path.join(os.getcwd(), 'tools/fastBPE/fast')\n","\n","def to_bpe(sentences):\n","    # write sentences to tmp file\n","    with open('/tmp/sentences.bpe', 'w') as fwrite:\n","        for sent in sentences:\n","            fwrite.write(sent + '\\n')\n","    \n","    # apply bpe to tmp file\n","    os.system('%s applybpe /tmp/sentences.bpe /tmp/sentences %s' % (fastbpe, codes))\n","    \n","    # load bpe-ized sentences\n","    sentences_bpe = []\n","    with open('/tmp/sentences.bpe') as f:\n","        for line in f:\n","            sentences_bpe.append(line.rstrip())\n","    \n","    return sentences_bpe\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"21FptAPJO5_2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"4b2348ce-58f8-40cd-c048-b86624673f27","executionInfo":{"status":"ok","timestamp":1587800225781,"user_tz":-120,"elapsed":1927,"user":{"displayName":"Pascal Tikeng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwUG1KwvT0FSpaKD7QYyfcxFH68TlCegHG8wC1=s64","userId":"06092546780793260792"}}},"source":["# Below are already BPE-ized sentences\n","\n","# list of (sentences, lang)\n","sentences = [\n","    'once he had worn trendy italian leather shoes and jeans from paris that had cost three hundred euros .', # en\n","    'Le français est la seule langue étrangère proposée dans le système éducatif .', # fr\n","]\n","\n","# bpe-ize sentences\n","sentences = to_bpe(sentences)\n","print('\\n\\n'.join(sentences))\n","\n","# check how many tokens are OOV\n","n_w = len([w for w in ' '.join(sentences).split()])\n","n_oov = len([w for w in ' '.join(sentences).split() if w not in dico.word2id])\n","print('Number of out-of-vocab words: %s/%s' % (n_oov, n_w))\n","\n","# add </s> sentence delimiters\n","sentences = [(('</s> %s </s>' % sent.strip()).split()) for sent in sentences]"],"execution_count":10,"outputs":[{"output_type":"stream","text":["once he had worn trendy italian leather shoes and jeans from paris that had cost three hundred euros . blablandnodo\n","\n","Le français est la seule langue étrangère proposée dans le système éducatif .\n","Number of out-of-vocab words: 13/33\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dhir7vjuO5_5","colab_type":"text"},"source":["### Create batch"]},{"cell_type":"code","metadata":{"id":"cEyMcI8cO5_5","colab_type":"code","colab":{}},"source":["bs = len(sentences)\n","slen = max([len(sent) for sent in sentences])\n","\n","word_ids = torch.LongTensor(slen, bs).fill_(params.pad_index)\n","for i in range(len(sentences)):\n","    sent = torch.LongTensor([dico.index(w) for w in sentences[i]])\n","    word_ids[:len(sent), i] = sent\n","\n","lengths = torch.LongTensor([len(sent) for sent in sentences])\n","                             \n","# NOTE: No more language id (removed it in a later version)\n","# langs = torch.LongTensor([params.lang2id[lang] for _, lang in sentences]).unsqueeze(0).expand(slen, bs) if params.n_langs > 1 else None\n","langs = None\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pHUSGXXKO5_7","colab_type":"text"},"source":["### Forward"]},{"cell_type":"code","metadata":{"id":"8gcYm1O0O5_8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"outputId":"e2959e00-1fa7-4e54-fc75-ddbfd0586bde","executionInfo":{"status":"ok","timestamp":1587800571212,"user_tz":-120,"elapsed":2318,"user":{"displayName":"Pascal Tikeng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwUG1KwvT0FSpaKD7QYyfcxFH68TlCegHG8wC1=s64","userId":"06092546780793260792"}}},"source":["tensor = model('fwd', x=word_ids, lengths=lengths, langs=langs, causal=False).contiguous()\n","print(tensor.size())"],"execution_count":11,"outputs":[{"output_type":"stream","text":["tensor([[[ 1.0043,  1.3356,  1.1830,  ...,  0.3952, -0.1379,  0.2779],\n","         [ 0.9566,  1.4682,  1.3344,  ...,  0.5169, -0.4460,  0.1688]],\n","\n","        [[ 1.3772,  0.3458,  1.4081,  ...,  2.5558,  0.6799,  0.5485],\n","         [ 0.7248,  0.6524,  1.9140,  ...,  2.4721,  0.2964,  0.0548]],\n","\n","        [[ 1.5902,  0.5192, -0.1281,  ...,  0.1359, -2.1216, -0.2077],\n","         [ 0.9734,  0.9857,  1.1935,  ...,  2.1771, -0.8057,  0.2012]],\n","\n","        ...,\n","\n","        [[ 0.4444,  0.6856,  1.2785,  ...,  1.8183,  0.4155,  1.1290],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000]],\n","\n","        [[ 1.1060,  1.5340,  0.6061,  ...,  2.5929, -0.9947, -0.1349],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000]],\n","\n","        [[ 0.2880,  1.1748,  0.9947,  ...,  0.0865, -0.5463,  0.6289],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000]]],\n","       grad_fn=<CopyBackwards>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W5xvbCb6TqbY","colab_type":"code","colab":{}},"source":["tensor = model('predict', x=word_ids, lengths=lengths, langs=langs, causal=False).contiguous()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q96XNo1mO5_-","colab_type":"text"},"source":["The variable `tensor` is of shape `(sequence_length, batch_size, model_dimension)`.\n","\n","`tensor[0]` is a tensor of shape `(batch_size, model_dimension)` that corresponds to the first hidden state of the last layer of each sentence.\n","\n","This is this vector that we use to finetune on the GLUE and XNLI tasks."]}]}