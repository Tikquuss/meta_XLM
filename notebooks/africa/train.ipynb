{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train.ipynb","provenance":[],"collapsed_sections":["xMd7DhW2i0HK","FrwKCzV17UBv"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"PwEcOOqFiyQS","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"xMd7DhW2i0HK","colab_type":"text"},"source":["# **Workspace**"]},{"cell_type":"code","metadata":{"id":"Jg16u2FnlAIX","colab_type":"code","outputId":"450bf39c-f822-447c-8022-76e61a381cfe","executionInfo":{"status":"ok","timestamp":1589019764689,"user_tz":-120,"elapsed":45122,"user":{"displayName":"Pascal Notsawo","photoUrl":"","userId":"05128058352342027621"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hykuZ2GytM2N","colab_type":"code","outputId":"24abdb90-d3fb-43f9-d932-ffbc07841ebb","executionInfo":{"status":"ok","timestamp":1589019844644,"user_tz":-120,"elapsed":77391,"user":{"displayName":"Pascal Notsawo","photoUrl":"","userId":"05128058352342027621"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["! rsync -av --progress /content/drive/\"My Drive\"/African_Translator/from_github/XLM /content --exclude data/for_test --exclude data/for_the_hypothesis --exclude data/para --exclude data/processed --exclude data/testFASTBPE --exclude dumped --exclude apex --exclude .git --exclude tools/mosesdecoder --exclude tools/fastBPE\n","#! rm -R /content/XLM"],"execution_count":0,"outputs":[{"output_type":"stream","text":["sending incremental file list\n","XLM/\n","XLM/.gitignore\n","          1,577 100%    0.00kB/s    0:00:00 (xfr#1, to-chk=89/91)\n","XLM/CODE_OF_CONDUCT.md\n","            244 100%    0.30kB/s    0:00:00 (xfr#2, to-chk=88/91)\n","XLM/CONTRIBUTING.md\n","            572 100%    0.00kB/s    0:00:00 (xfr#3, to-chk=87/91)\n","XLM/Copie de generate-embeddings.ipynb\n","         17,469 100%   17.39kB/s    0:00:00 (xfr#4, to-chk=86/91)\n","XLM/LICENSE\n","         19,336 100%    0.00kB/s    0:00:00 (xfr#5, to-chk=85/91)\n","XLM/PKM-layer.ipynb\n","         13,810 100%   13.65kB/s    0:00:00 (xfr#6, to-chk=84/91)\n","XLM/README.md\n","         39,290 100%    6.22MB/s    0:00:00 (xfr#7, to-chk=83/91)\n","XLM/apply_bpe_preprocess.sh\n","            366 100%    0.33kB/s    0:00:01 (xfr#8, to-chk=82/91)\n","XLM/generate-embeddings.ipynb\n","          9,613 100%    0.00kB/s    0:00:00 (xfr#9, to-chk=81/91)\n","XLM/get-data-glue.sh\n","          6,143 100%    5.54kB/s    0:00:01 (xfr#10, to-chk=80/91)\n","XLM/get-data-nmt.sh\n","         15,009 100%    0.00kB/s    0:00:00 (xfr#11, to-chk=79/91)\n","XLM/get-data-para.sh\n","          7,099 100%    5.93kB/s    0:00:01 (xfr#12, to-chk=78/91)\n","XLM/get-data-wiki.sh\n","          2,122 100%    0.00kB/s    0:00:00 (xfr#13, to-chk=77/91)\n","XLM/get-data-xnli.sh\n","          2,807 100%    3.21kB/s    0:00:00 (xfr#14, to-chk=76/91)\n","XLM/get_africa_data.sh\n","          5,502 100%    0.00kB/s    0:00:00 (xfr#15, to-chk=75/91)\n","XLM/get_data_hypothesis.sh\n","          6,871 100%    6.49kB/s    0:00:01 (xfr#16, to-chk=74/91)\n","XLM/get_data_test.sh\n","          7,454 100%    0.00kB/s    0:00:00 (xfr#17, to-chk=73/91)\n","XLM/glue-xnli.py\n","          4,531 100%    4.65kB/s    0:00:00 (xfr#18, to-chk=72/91)\n","XLM/install-tools.sh\n","          1,822 100%    0.00kB/s    0:00:00 (xfr#19, to-chk=71/91)\n","XLM/lm_train.sh\n","            396 100%    0.62kB/s    0:00:00 (xfr#20, to-chk=70/91)\n","XLM/prepare-glue.sh\n","          1,758 100%    1.20kB/s    0:00:01 (xfr#21, to-chk=69/91)\n","XLM/prepare-xnli.sh\n","          2,659 100%    0.00kB/s    0:00:00 (xfr#22, to-chk=68/91)\n","XLM/preprocess.py\n","          1,459 100%    1.92kB/s    0:00:00 (xfr#23, to-chk=67/91)\n","XLM/train.py\n","         16,203 100%    0.00kB/s    0:00:00 (xfr#24, to-chk=66/91)\n","XLM/train.sh\n","            741 100%    0.92kB/s    0:00:00 (xfr#25, to-chk=65/91)\n","XLM/train_test.sh\n","          1,435 100%    0.99kB/s    0:00:01 (xfr#26, to-chk=64/91)\n","XLM/translate.py\n","          5,565 100%    0.00kB/s    0:00:00 (xfr#27, to-chk=63/91)\n","XLM/translate_our.py\n","          7,713 100%    8.40kB/s    0:00:00 (xfr#28, to-chk=62/91)\n","XLM/umt_train.sh\n","          1,422 100%    0.00kB/s    0:00:00 (xfr#29, to-chk=61/91)\n","XLM/.ipynb_checkpoints/\n","XLM/data/\n","XLM/src/\n","XLM/src/__init__.py\n","              0 100%    0.00kB/s    0:00:00 (xfr#30, to-chk=56/91)\n","XLM/src/logger.py\n","          1,873 100%    1.62kB/s    0:00:01 (xfr#31, to-chk=55/91)\n","XLM/src/optim.py\n","         10,378 100%    0.00kB/s    0:00:00 (xfr#32, to-chk=54/91)\n","XLM/src/slurm.py\n","          6,323 100%    9.44kB/s    0:00:00 (xfr#33, to-chk=53/91)\n","XLM/src/trainer.py\n","         37,434 100%   25.56kB/s    0:00:01 (xfr#34, to-chk=52/91)\n","XLM/src/utils.py\n","          9,934 100%   16.39kB/s    0:00:00 (xfr#35, to-chk=51/91)\n","XLM/src/__pycache__/\n","XLM/src/__pycache__/__init__.cpython-36.pyc\n","            206 100%    0.15kB/s    0:00:01 (xfr#36, to-chk=46/91)\n","XLM/src/__pycache__/logger.cpython-36.pyc\n","          1,708 100%    0.00kB/s    0:00:00 (xfr#37, to-chk=45/91)\n","XLM/src/__pycache__/optim.cpython-36.pyc\n","          8,244 100%   12.56kB/s    0:00:00 (xfr#38, to-chk=44/91)\n","XLM/src/__pycache__/slurm.cpython-36.pyc\n","          3,872 100%    0.00kB/s    0:00:00 (xfr#39, to-chk=43/91)\n","XLM/src/__pycache__/trainer.cpython-36.pyc\n","         26,871 100%   32.68kB/s    0:00:00 (xfr#40, to-chk=42/91)\n","XLM/src/__pycache__/utils.cpython-36.pyc\n","         10,935 100%    0.00kB/s    0:00:00 (xfr#41, to-chk=41/91)\n","XLM/src/data/\n","XLM/src/data/__init__.py\n","              0 100%    0.00kB/s    0:00:00 (xfr#42, to-chk=40/91)\n","XLM/src/data/dataset.py\n","         14,631 100%   21.11kB/s    0:00:00 (xfr#43, to-chk=39/91)\n","XLM/src/data/dictionary.py\n","          7,763 100%    0.00kB/s    0:00:00 (xfr#44, to-chk=38/91)\n","XLM/src/data/loader.py\n","         16,435 100%   21.72kB/s    0:00:00 (xfr#45, to-chk=37/91)\n","XLM/src/data/__pycache__/\n","XLM/src/data/__pycache__/__init__.cpython-36.pyc\n","            211 100%    0.15kB/s    0:00:01 (xfr#46, to-chk=35/91)\n","XLM/src/data/__pycache__/dataset.cpython-36.pyc\n","         12,502 100%    0.00kB/s    0:00:00 (xfr#47, to-chk=34/91)\n","XLM/src/data/__pycache__/dictionary.cpython-36.pyc\n","          7,517 100%    5.39kB/s    0:00:01 (xfr#48, to-chk=33/91)\n","XLM/src/data/__pycache__/loader.cpython-36.pyc\n","         12,271 100%    0.00kB/s    0:00:00 (xfr#49, to-chk=32/91)\n","XLM/src/evaluation/\n","XLM/src/evaluation/__init__.py\n","              0 100%    0.00kB/s    0:00:00 (xfr#50, to-chk=31/91)\n","XLM/src/evaluation/evaluator.py\n","         22,358 100%   29.43kB/s    0:00:00 (xfr#51, to-chk=30/91)\n","XLM/src/evaluation/glue.py\n","         11,415 100%    0.00kB/s    0:00:00 (xfr#52, to-chk=29/91)\n","XLM/src/evaluation/multi-bleu.perl\n","          5,233 100%    6.08kB/s    0:00:00 (xfr#53, to-chk=28/91)\n","XLM/src/evaluation/xnli.py\n","          8,561 100%    5.72kB/s    0:00:01 (xfr#54, to-chk=27/91)\n","XLM/src/evaluation/__pycache__/\n","XLM/src/evaluation/__pycache__/__init__.cpython-36.pyc\n","            217 100%    0.00kB/s    0:00:00 (xfr#55, to-chk=25/91)\n","XLM/src/evaluation/__pycache__/evaluator.cpython-36.pyc\n","         15,871 100%   17.38kB/s    0:00:00 (xfr#56, to-chk=24/91)\n","XLM/src/model/\n","XLM/src/model/__init__.py\n","          7,971 100%    0.00kB/s    0:00:00 (xfr#57, to-chk=23/91)\n","XLM/src/model/embedder.py\n","          4,816 100%    5.02kB/s    0:00:00 (xfr#58, to-chk=22/91)\n","XLM/src/model/pretrain.py\n","          2,987 100%    0.00kB/s    0:00:00 (xfr#59, to-chk=21/91)\n","XLM/src/model/transformer.py\n","         30,221 100%   30.90kB/s    0:00:00 (xfr#60, to-chk=20/91)\n","XLM/src/model/__pycache__/\n","XLM/src/model/__pycache__/__init__.cpython-36.pyc\n","          7,494 100%    0.00kB/s    0:00:00 (xfr#61, to-chk=17/91)\n","XLM/src/model/__pycache__/pretrain.cpython-36.pyc\n","          2,791 100%    2.91kB/s    0:00:00 (xfr#62, to-chk=16/91)\n","XLM/src/model/__pycache__/transformer.cpython-36.pyc\n","         19,918 100%    0.00kB/s    0:00:00 (xfr#63, to-chk=15/91)\n","XLM/src/model/memory/\n","XLM/src/model/memory/__init__.py\n","             34 100%    0.04kB/s    0:00:00 (xfr#64, to-chk=14/91)\n","XLM/src/model/memory/memory.py\n","         33,186 100%  408.20kB/s    0:00:00 (xfr#65, to-chk=13/91)\n","XLM/src/model/memory/query.py\n","          9,282 100%   14.19kB/s    0:00:00 (xfr#66, to-chk=12/91)\n","XLM/src/model/memory/utils.py\n","          5,082 100%    3.82kB/s    0:00:01 (xfr#67, to-chk=11/91)\n","XLM/src/model/memory/__pycache__/\n","XLM/src/model/memory/__pycache__/__init__.cpython-36.pyc\n","            263 100%    0.00kB/s    0:00:00 (xfr#68, to-chk=9/91)\n","XLM/src/model/memory/__pycache__/memory.cpython-36.pyc\n","         19,712 100%   26.12kB/s    0:00:00 (xfr#69, to-chk=8/91)\n","XLM/src/model/memory/__pycache__/query.cpython-36.pyc\n","          9,364 100%    6.67kB/s    0:00:01 (xfr#70, to-chk=7/91)\n","XLM/src/model/memory/__pycache__/utils.cpython-36.pyc\n","          4,942 100%    0.00kB/s    0:00:00 (xfr#71, to-chk=6/91)\n","XLM/tools/\n","XLM/tools/README.md\n","            845 100%    1.12kB/s    0:00:00 (xfr#72, to-chk=5/91)\n","XLM/tools/lowercase_and_remove_accent.py\n","          1,314 100%    0.00kB/s    0:00:00 (xfr#73, to-chk=4/91)\n","XLM/tools/segment_th.py\n","            355 100%    0.46kB/s    0:00:00 (xfr#74, to-chk=3/91)\n","XLM/tools/tokenize.sh\n","          1,236 100%    0.00kB/s    0:00:00 (xfr#75, to-chk=2/91)\n","XLM/tools/tokenizer_our.sh\n","          1,053 100%    1.16kB/s    0:00:00 (xfr#76, to-chk=1/91)\n","XLM/tools/.ipynb_checkpoints/\n","\n","sent 622,303 bytes  received 1,560 bytes  8,725.36 bytes/sec\n","total size is 616,617  speedup is 0.99\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8NiKDya-tSKk","colab_type":"code","outputId":"5a621df0-1d64-435f-da35-4a97245e268a","executionInfo":{"status":"ok","timestamp":1589020317347,"user_tz":-120,"elapsed":1703,"user":{"displayName":"Pascal Notsawo","photoUrl":"","userId":"05128058352342027621"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["% bookmark HOME \"/content/XLM\" \n","%cd -b HOME"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(bookmark:HOME) -> /content/XLM\n","/content/XLM\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YsYX9LySwrlQ","colab_type":"code","outputId":"fb204741-89a0-4027-a0ac-c49d387d9e36","executionInfo":{"status":"ok","timestamp":1589020346692,"user_tz":-120,"elapsed":29328,"user":{"displayName":"Pascal Notsawo","photoUrl":"","userId":"05128058352342027621"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# Dependencies : fastBPE et Moses (l'installation prend moins de temps que la copie)\n","% cd tools\n","! git clone https://github.com/moses-smt/mosesdecoder\n","! git clone https://github.com/glample/fastBPE && cd fastBPE && g++ -std=c++11 -pthread -O3 fastBPE/main.cc -IfastBPE -o fast"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/XLM/tools\n","Cloning into 'mosesdecoder'...\n","remote: Enumerating objects: 30, done.\u001b[K\n","remote: Counting objects: 100% (30/30), done.\u001b[K\n","remote: Compressing objects: 100% (25/25), done.\u001b[K\n","remote: Total 147544 (delta 12), reused 15 (delta 5), pack-reused 147514\u001b[K\n","Receiving objects: 100% (147544/147544), 129.75 MiB | 12.65 MiB/s, done.\n","Resolving deltas: 100% (113998/113998), done.\n","Cloning into 'fastBPE'...\n","remote: Enumerating objects: 5, done.\u001b[K\n","remote: Counting objects: 100% (5/5), done.\u001b[K\n","remote: Compressing objects: 100% (5/5), done.\u001b[K\n","remote: Total 59 (delta 0), reused 1 (delta 0), pack-reused 54\u001b[K\n","Unpacking objects: 100% (59/59), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"72ir_8StwxJT","colab_type":"code","outputId":"d370db63-ce91-4d32-af74-effc0a117f1d","executionInfo":{"status":"ok","timestamp":1589020351918,"user_tz":-120,"elapsed":1535,"user":{"displayName":"Pascal Notsawo","photoUrl":"","userId":"05128058352342027621"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%cd -b HOME"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(bookmark:HOME) -> /content/XLM\n","/content/XLM\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bHpMu-d1lIJ6","colab_type":"text"},"source":["# **Data**"]},{"cell_type":"code","metadata":{"id":"gxqMuHPOlnMu","colab_type":"code","colab":{}},"source":["import os\n","import csv"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"glico_S9kRnE","colab_type":"code","colab":{}},"source":["langues_all = [\n","            # langues presentes dans l'ancien et le nouveau testament\n","           'Francais', \"Anglais\",  \"BIBALDA_TA_PELDETTA\", 'Bulu',  'Guiziga', \"Fulfulde_Adamaoua\",  \n","           \"Fulfulde_DC\", 'KALATA_KO_SC_Gbaya', 'KALATA_KO_DC_Gbaya', 'Kapsiki_DC', 'Tupurri',\n","           \n","           # langues presentes uniquement dans le nouveau testament\n","          'Bafia', 'Dii', 'Ejagham', 'Ghomala', 'Vute', 'Limbum', 'MKPAMAN_AMVOE_Ewondo', 'Mofa', \n","           \"Mofu_Gudur\", \"Ngiemboon\", 'Doyayo', \"Guidar\", 'Peere_Nt&Psalms', 'Samba_Leko', \n","           \"Du_na_sdik_na_wiini_Alaw\"\n","]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlCkH0s3iy3x","colab_type":"code","colab":{}},"source":["def get_data_from_bible(csv_path, books, output_dir, data_type = \"para\", langues=[], cell_error = \"__Error__\"):\n","    \"\"\"\n","    csv_path: folder containing the csvs folder\n","    books : list of the books of the bibles to be considered (there must exist for each of these books a books.csv file in ../csvs/)\n","    output: folder in which the lens folders will be created (mono or para)\n","    data_type: monolingual one or parallel one\n","    languages: list of languages to be considered (these languages must be included in the list of languages above)\n","    cell_error: text to be used to mark erroneous text pairs during webscrapping (these pairs are excluded from the data)\n","    \"\"\"\n","\n","    # Si aucune langue n'est spécifiée, on selectionne tout les langues\n","    if langues == [] :\n","      langues = langues_all\n","    \n","    l = len(langues)\n","    for i in range(l-1):\n","      for j in range(i+1, l):\n","        li = langues[i]\n","        lj = langues[j]\n","        print(li + '-' + lj)\n","\n","        repertoire = output_dir+\"/\"+data_type\n","        if not os.path.exists(repertoire):\n","          os.makedirs(repertoire)\n","\n","        if data_type == \"para\":\n","          repertoire = repertoire +\"/\"+ li +'-'+ lj\n","          if not os.path.exists(repertoire):\n","            os.makedirs(repertoire)\n","          repertoire = [repertoire + \"/\" + li + '-' + lj + \".\" for _ in range(2)]\n","        elif data_type == \"mono\":\n","          repertoire = [repertoire + \"/\" + li, repertoire +\"/\"+ lj]\n","          for rep in repertoire :\n","            if not os.path.exists(rep):\n","              os.makedirs(rep)\n","          repertoire = [r +\"/\" for r in repertoire]\n","\n","        with open(repertoire[0] + li + '.txt', 'w') as txtfile1:\n","          with open(repertoire[1] + lj + '.txt', 'w') as txtfile2:\n","            \n","            for fichier in books:\n","              try :\n","                with open(csv_path+\"/csvs/\"+fichier+'csv', 'r') as csvfile:\n","                  f_csv = csv.reader(csvfile)\n","                  filenames = []\n","                  try :\n","                    fieldnames = next(f_csv)\n","                  except StopIteration as si :\n","                    print(si)\n","                  try :\n","                    index_i = fieldnames.index(li)\n","                    index_j = fieldnames.index(lj)\n","                    versert = fieldnames.index(\"livre.chapitre.verset\")\n","                    for ligne in f_csv:\n","                      x_i = ligne[index_i] \n","                      y_i =  ligne[index_j]\n","                      if x_i != cell_error and y_i != cell_error :\n","                          txtfile1.writelines(x_i+'\\n')\n","                          txtfile2.writelines(y_i+'\\n')\n","                  except Exception as ex:\n","                    print(ex)\n","              except Exception as ex :\n","                print(ex)\n","                pass"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJqbxbNzkoKK","colab_type":"code","colab":{}},"source":["livres = [\n","    # Ancien testatement\n","    'GEN.', 'EXO.', 'LEV.', 'NUM.', 'DEU.', 'JOS.', 'JDG.', 'RUT.',   '1SA.', '2SA.', '1KI.', '2KI.', \n","    '1CH.', '2CH.', 'EZR.', 'NEH.', 'EST.', 'JOB.', 'PSA.', 'PRO.', 'ECC.', 'SNG.',  'ISA.', 'JER.', \n","    'LAM.', 'EZK.', 'DAN.', 'HOS.', 'JOL.', 'AMO.', 'OBA.', 'JON.', 'MIC.', 'NAM.', 'HAB.', 'ZEP.', \n","    'HAG.', 'ZEC.', 'MAL.',\n","\n","    # Nouveau testament\n","    'MAT.', 'MRK.', 'LUK.', 'JHN.', 'ACT.', 'ROM.', '1CO.', '2CO.', 'GAL.', 'EPH.', 'PHP.', 'COL.', \n","    '1TH.', '2TH.', '1TI.', '2TI.', 'TIT.', 'PHM.', 'HEB.', 'JAS.', '1PE.',  '2PE.', '1JN.', '2JN.', \n","    '3JN.', 'JUD.', 'REV.'\n","]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y6V-i2N5ksJN","colab_type":"code","outputId":"cd0a75a9-5e74-4aa9-98f5-bd4129bb9da1","executionInfo":{"status":"ok","timestamp":1589022094208,"user_tz":-120,"elapsed":5751,"user":{"displayName":"Pascal Notsawo","photoUrl":"","userId":"05128058352342027621"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["csv_path = \"/content/drive/My Drive/African_Translator/datasets/YourVersion\"\n","output_dir = \"/content/XLM/data/africa\"\n","! mkdir /content/XLM/data/africa\n","data_type = \"para\"\n","langues = [\"Anglais\", \"Bulu\"]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘/content/XLM/data/africa’: File exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HwS-x13VkwBL","colab_type":"code","outputId":"b7acdbd2-d00c-4699-8fc9-7c4aa3b90d94","executionInfo":{"status":"ok","timestamp":1589022102682,"user_tz":-120,"elapsed":3892,"user":{"displayName":"Pascal Notsawo","photoUrl":"","userId":"05128058352342027621"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["get_data_from_bible(csv_path = csv_path, livres = livres, output_dir = output_dir, data_type = data_type, langues = langues)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Anglais-Bulu\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eTRraJmY17H5","colab_type":"code","outputId":"24d0c738-78cd-459d-bb6c-65257fdfcb7b","executionInfo":{"status":"ok","timestamp":1589022142582,"user_tz":-120,"elapsed":5975,"user":{"displayName":"Pascal Notsawo","photoUrl":"","userId":"05128058352342027621"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["# dossier (contenant/dans le quel stocker) les données \n","% env PARA_PATH=data/africa/para\n","! mkdir -p $PARA_PATH\n","\n","% env nCodes=30000\n","% env shuf_n_samples=100000\n","\n","# Pourcentage des données de test et de validation (en %) \n","# todo : bon ? \n","% env test_size=10\n","% env val_size=10"],"execution_count":0,"outputs":[{"output_type":"stream","text":["env: PARA_PATH=data/africa/para\n","env: nCodes=30000\n","env: shuf_n_samples=100000\n","env: test_size=10\n","env: val_size=10\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vgPVu0Jk2KXH","colab_type":"code","outputId":"cffda45e-4156-4721-b039-16ca875759d2","executionInfo":{"status":"ok","timestamp":1589022163082,"user_tz":-120,"elapsed":15978,"user":{"displayName":"Pascal Notsawo","photoUrl":"","userId":"05128058352342027621"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# tools paths\n","#% env TOKENIZE=$TOOLS_PATH/tokenize.sh\n","% env TOKENIZE=tools/tokenizer_our.sh\n","#% env LOWER_REMOVE_ACCENT=$TOOLS_PATH/lowercase_and_remove_accent.py\n","% env LOWER_REMOVE_ACCENT=tools/lowercase_and_remove_accent.py\n","#% env FASTBPE=$TOOLS_PATH/fastBPE/fast\n","% env FASTBPE=tools/fastBPE/fast\n","\n","#% env OUTPATH $PROCESSED_PATH/$pair/$nCodes\n","# nommage du fichier en fonction de 'nCodes'\n","% env OUTPATH data/africa/processed/30000\n","\n","! mkdir -p $OUTPATH\n","\n","! chmod +x $FASTBPE\n","! chmod +x get_data_hypothesis.sh\n","! chmod +x tools/mosesdecoder/scripts/tokenizer/*.perl"],"execution_count":0,"outputs":[{"output_type":"stream","text":["env: TOKENIZE=tools/tokenizer_our.sh\n","env: LOWER_REMOVE_ACCENT=tools/lowercase_and_remove_accent.py\n","env: FASTBPE=tools/fastBPE/fast\n","env: OUTPATH=data/africa/processed/30000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U6K_qGRT2Rp8","colab_type":"code","outputId":"e98b9206-4653-4d0b-bae4-9da09ed88e0c","executionInfo":{"status":"ok","timestamp":1589022165639,"user_tz":-120,"elapsed":1365,"user":{"displayName":"Pascal Notsawo","photoUrl":"","userId":"05128058352342027621"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["% env threads_for_tokenizer=16"],"execution_count":0,"outputs":[{"output_type":"stream","text":["env: threads_for_tokenizer=16\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DNS4mYng2Wrt","colab_type":"code","outputId":"cbe4740a-fb2d-428e-9c2b-2c40364b80e8","executionInfo":{"status":"ok","timestamp":1589022195438,"user_tz":-120,"elapsed":27470,"user":{"displayName":"Pascal Notsawo","photoUrl":"","userId":"05128058352342027621"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["! chmod +x get_africa_data.sh\n","! ./get_africa_data.sh Anglais-Bulu "],"execution_count":0,"outputs":[{"output_type":"stream","text":["dir data/africa/para/Anglais-Bulu already exists\n","\n","\n","*** Cleaning and tokenizing Anglais-Bulu data ... ***\n","Tokenizer Version 1.1\n","Language: Anglais\n","Number of threads: 16\n","WARNING: No known abbreviations for language 'Anglais', attempting fall-back to English version...\n","*** Tokenized (+ lowercase + accent-removal) Anglais-Bulu.Anglais data to data/africa/para/Anglais-Bulu/? ***\n","Tokenizer Version 1.1\n","Language: Bulu\n","Number of threads: 16\n","WARNING: No known abbreviations for language 'Bulu', attempting fall-back to English version...\n","*** Tokenized (+ lowercase + accent-removal) Anglais-Bulu.Bulu data to data/africa/para/Anglais-Bulu/? ***\n","\n","\n","*** split into train / valid / test ***\n","\n","\n","\n","***build the training set for BPE tokenization (30000 codes)***\n","\n","\n","***shuf ... Generating 100000 random permutations of train data and store result in data/africa/processed/30000/Anglais-Bulu/bpe.train***\n","\n","\n","***Learn the BPE vocabulary on the training set : data/africa/processed/30000/bpe.train***\n","Loading vocabulary from data/africa/processed/30000/Anglais-Bulu/bpe.train ...\n","Read 6038010 words (22141 unique) from text file.\n","tcmalloc: large alloc 12000002048 bytes == 0x562ec9a70000 @  0x7f5059cb7887 0x562ec874e8f3 0x562ec874378f 0x7f50590f2b97 0x562ec8743a1a\n","\n","\n","***Get the post-BPE vocab***\n","Loading codes from data/africa/processed/30000/Anglais-Bulu/codes ...\n","Read 30000 codes from the codes file.\n","Loading vocabulary from data/africa/processed/30000/Anglais-Bulu/bpe.train ...\n","Read 6038010 words (22141 unique) from text file.\n","Applying BPE to data/africa/processed/30000/Anglais-Bulu/bpe.train ...\n","Modified 6038010 words from text file.\n","Read 6038576 words (22306 unique) from text file.\n","\n","\n","***Apply BPE tokenization on the parallel corpora, and binarize everything using preprocess.py.***\n","Loading codes from data/africa/processed/30000/Anglais-Bulu/codes ...\n","Read 30000 codes from the codes file.\n","Loading vocabulary from data/africa/para/Anglais-Bulu/Anglais-Bulu.Anglais.train ...\n","Read 691524 words (11773 unique) from text file.\n","Applying BPE to data/africa/para/Anglais-Bulu/Anglais-Bulu.Anglais.train ...\n","Modified 691524 words from text file.\n","INFO - 05/09/20 13:03:08 - 0:00:00 - Read 22320 words from the vocabulary file.\n","\n","Saving the data to data/africa/processed/30000/Anglais-Bulu/Anglais-Bulu.Anglais.train.pth ...\n","INFO - 05/09/20 13:03:09 - 0:00:01 - 691905 words (22320 unique) in 22854 sentences.\n","INFO - 05/09/20 13:03:09 - 0:00:01 - 61 unknown words (61 unique), covering 0.01% of the data.\n","Loading codes from data/africa/processed/30000/Anglais-Bulu/codes ...\n","Read 30000 codes from the codes file.\n","Loading vocabulary from data/africa/para/Anglais-Bulu/Anglais-Bulu.Anglais.valid ...\n","Read 86045 words (5220 unique) from text file.\n","Applying BPE to data/africa/para/Anglais-Bulu/Anglais-Bulu.Anglais.valid ...\n","Modified 86045 words from text file.\n","INFO - 05/09/20 13:03:10 - 0:00:00 - Read 22320 words from the vocabulary file.\n","\n","Saving the data to data/africa/processed/30000/Anglais-Bulu/Anglais-Bulu.Anglais.valid.pth ...\n","INFO - 05/09/20 13:03:10 - 0:00:00 - 86874 words (22320 unique) in 2856 sentences.\n","INFO - 05/09/20 13:03:10 - 0:00:00 - 744 unknown words (547 unique), covering 0.86% of the data.\n","Loading codes from data/africa/processed/30000/Anglais-Bulu/codes ...\n","Read 30000 codes from the codes file.\n","Loading vocabulary from data/africa/para/Anglais-Bulu/Anglais-Bulu.Anglais.test ...\n","Read 87615 words (5159 unique) from text file.\n","Applying BPE to data/africa/para/Anglais-Bulu/Anglais-Bulu.Anglais.test ...\n","Modified 87615 words from text file.\n","INFO - 05/09/20 13:03:11 - 0:00:00 - Read 22320 words from the vocabulary file.\n","\n","Saving the data to data/africa/processed/30000/Anglais-Bulu/Anglais-Bulu.Anglais.test.pth ...\n","INFO - 05/09/20 13:03:11 - 0:00:00 - 88338 words (22320 unique) in 2856 sentences.\n","INFO - 05/09/20 13:03:11 - 0:00:00 - 594 unknown words (451 unique), covering 0.67% of the data.\n","Loading codes from data/africa/processed/30000/Anglais-Bulu/codes ...\n","Read 30000 codes from the codes file.\n","Loading vocabulary from data/africa/para/Anglais-Bulu/Anglais-Bulu.Bulu.train ...\n","Read 689058 words (11162 unique) from text file.\n","Applying BPE to data/africa/para/Anglais-Bulu/Anglais-Bulu.Bulu.train ...\n","Modified 689058 words from text file.\n","INFO - 05/09/20 13:03:12 - 0:00:00 - Read 22320 words from the vocabulary file.\n","\n","Saving the data to data/africa/processed/30000/Anglais-Bulu/Anglais-Bulu.Bulu.train.pth ...\n","INFO - 05/09/20 13:03:13 - 0:00:01 - 689397 words (22320 unique) in 22854 sentences.\n","INFO - 05/09/20 13:03:13 - 0:00:01 - 55 unknown words (53 unique), covering 0.01% of the data.\n","Loading codes from data/africa/processed/30000/Anglais-Bulu/codes ...\n","Read 30000 codes from the codes file.\n","Loading vocabulary from data/africa/para/Anglais-Bulu/Anglais-Bulu.Bulu.valid ...\n","Read 85530 words (4595 unique) from text file.\n","Applying BPE to data/africa/para/Anglais-Bulu/Anglais-Bulu.Bulu.valid ...\n","Modified 85530 words from text file.\n","INFO - 05/09/20 13:03:13 - 0:00:00 - Read 22320 words from the vocabulary file.\n","\n","Saving the data to data/africa/processed/30000/Anglais-Bulu/Anglais-Bulu.Bulu.valid.pth ...\n","INFO - 05/09/20 13:03:14 - 0:00:00 - 86292 words (22320 unique) in 2856 sentences.\n","INFO - 05/09/20 13:03:14 - 0:00:00 - 487 unknown words (365 unique), covering 0.56% of the data.\n","Loading codes from data/africa/processed/30000/Anglais-Bulu/codes ...\n","Read 30000 codes from the codes file.\n","Loading vocabulary from data/africa/para/Anglais-Bulu/Anglais-Bulu.Bulu.test ...\n","Read 87091 words (4689 unique) from text file.\n","Applying BPE to data/africa/para/Anglais-Bulu/Anglais-Bulu.Bulu.test ...\n","Modified 87091 words from text file.\n","INFO - 05/09/20 13:03:14 - 0:00:00 - Read 22320 words from the vocabulary file.\n","\n","Saving the data to data/africa/processed/30000/Anglais-Bulu/Anglais-Bulu.Bulu.test.pth ...\n","INFO - 05/09/20 13:03:15 - 0:00:00 - 87841 words (22320 unique) in 2856 sentences.\n","INFO - 05/09/20 13:03:15 - 0:00:00 - 465 unknown words (353 unique), covering 0.53% of the data.\n","\n","\n","***Using parallel data to construct monolingual data***\n","\n","\n","***Creat the file to train the XLM model with MLM+TLM objective***\n","\n","\n","*** get data for hypothesis with succes : dir data/africa/processed/30000/Anglais-Bulu ***\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zBWJcSTo29MK","colab_type":"code","colab":{}},"source":["#! rm -R /content/XLM/data/africa/para\n","#! rm -R /content/XLM/data/africa/processed"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FrwKCzV17UBv","colab_type":"text"},"source":["# **Dépendances**"]},{"cell_type":"code","metadata":{"id":"fY8PrGzI7TRI","colab_type":"code","outputId":"5d7a629b-62fb-43bc-a349-c5df3819590e","executionInfo":{"status":"ok","timestamp":1589020287294,"user_tz":-120,"elapsed":205501,"user":{"displayName":"Pascal Notsawo","photoUrl":"","userId":"05128058352342027621"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["## apex\n","%cd /content\n","! git clone https://github.com/NVIDIA/apex\n","%cd /content/apex\n","! pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content\n","Cloning into 'apex'...\n","remote: Enumerating objects: 6742, done.\u001b[K\n","remote: Total 6742 (delta 0), reused 0 (delta 0), pack-reused 6742\u001b[K\n","Receiving objects: 100% (6742/6742), 13.74 MiB | 3.22 MiB/s, done.\n","Resolving deltas: 100% (4503/4503), done.\n","/content/apex\n","/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n","  cmdoptions.check_install_build_global(options)\n","Created temporary directory: /tmp/pip-ephem-wheel-cache-9qfistk2\n","Created temporary directory: /tmp/pip-req-tracker-pou2zn5e\n","Created requirements tracker '/tmp/pip-req-tracker-pou2zn5e'\n","Created temporary directory: /tmp/pip-install-zz0fghxd\n","Processing /content/apex\n","  Created temporary directory: /tmp/pip-req-build-fhafgr5q\n","  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-pou2zn5e'\n","    Running setup.py (path:/tmp/pip-req-build-fhafgr5q/setup.py) egg_info for package from file:///content/apex\n","    Running command python setup.py egg_info\n","    torch.__version__  =  1.5.0+cu101\n","    running egg_info\n","    creating /tmp/pip-req-build-fhafgr5q/pip-egg-info/apex.egg-info\n","    writing /tmp/pip-req-build-fhafgr5q/pip-egg-info/apex.egg-info/PKG-INFO\n","    writing dependency_links to /tmp/pip-req-build-fhafgr5q/pip-egg-info/apex.egg-info/dependency_links.txt\n","    writing top-level names to /tmp/pip-req-build-fhafgr5q/pip-egg-info/apex.egg-info/top_level.txt\n","    writing manifest file '/tmp/pip-req-build-fhafgr5q/pip-egg-info/apex.egg-info/SOURCES.txt'\n","    writing manifest file '/tmp/pip-req-build-fhafgr5q/pip-egg-info/apex.egg-info/SOURCES.txt'\n","    /tmp/pip-req-build-fhafgr5q/setup.py:46: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n","      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n","  Source in /tmp/pip-req-build-fhafgr5q has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n","  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-pou2zn5e'\n","Skipping wheel build for apex, due to binaries being disabled for it.\n","Installing collected packages: apex\n","  Created temporary directory: /tmp/pip-record-4p1ma8c8\n","    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-fhafgr5q/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-fhafgr5q/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-4p1ma8c8/install-record.txt --single-version-externally-managed --compile\n","    torch.__version__  =  1.5.0+cu101\n","    /tmp/pip-req-build-fhafgr5q/setup.py:46: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n","      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n","\n","    Compiling cuda extensions with\n","    nvcc: NVIDIA (R) Cuda compiler driver\n","    Copyright (c) 2005-2019 NVIDIA Corporation\n","    Built on Sun_Jul_28_19:07:16_PDT_2019\n","    Cuda compilation tools, release 10.1, V10.1.243\n","    from /usr/local/cuda/bin\n","\n","    running install\n","    running build\n","    running build_py\n","    creating build\n","    creating build/lib.linux-x86_64-3.6\n","    creating build/lib.linux-x86_64-3.6/apex\n","    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n","    creating build/lib.linux-x86_64-3.6/apex/normalization\n","    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n","    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n","    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n","    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n","    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n","    creating build/lib.linux-x86_64-3.6/apex/contrib\n","    copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib\n","    creating build/lib.linux-x86_64-3.6/apex/pyprof\n","    copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof\n","    creating build/lib.linux-x86_64-3.6/apex/optimizers\n","    copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n","    copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n","    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n","    copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n","    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n","    creating build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    creating build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n","    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n","    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n","    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n","    creating build/lib.linux-x86_64-3.6/apex/mlp\n","    copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.6/apex/mlp\n","    copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.6/apex/mlp\n","    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n","    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n","    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n","    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n","    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n","    creating build/lib.linux-x86_64-3.6/apex/RNN\n","    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n","    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n","    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n","    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n","    creating build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    creating build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n","    copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n","    copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n","    creating build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n","    copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n","    copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n","    creating build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    creating build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n","    copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n","    copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n","    creating build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    creating build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n","    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n","    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n","    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n","    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n","    running build_ext\n","    /usr/local/lib/python3.6/dist-packages/torch/utils/cpp_extension.py:304: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n","      warnings.warn(msg.format('we could not find ninja.'))\n","    building 'apex_C' extension\n","    creating build/temp.linux-x86_64-3.6\n","    creating build/temp.linux-x86_64-3.6/csrc\n","    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","    In file included from csrc/flatten_unflatten.cpp:2:0:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h: In member function ‘at::DeprecatedTypeProperties& torch::utils::TensorGroup::type()’:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h:36:28: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","         return tensors[0].type();\n","                                ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/flatten_unflatten.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n","    building 'amp_C' extension\n","    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_61,code=sm_61 -std=c++14\n","    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_61,code=sm_61 -std=c++14\n","    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_61,code=sm_61 -std=c++14\n","    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_61,code=sm_61 -std=c++14\n","    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_61,code=sm_61 -std=c++14\n","    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_61,code=sm_61 -std=c++14\n","    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_61,code=sm_61 -std=c++14\n","    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_61,code=sm_61 -std=c++14\n","    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_61,code=sm_61 -std=c++14\n","    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n","    building 'syncbn' extension\n","    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_61,code=sm_61 -std=c++14\n","    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n","    building 'fused_layer_norm_cuda' extension\n","    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm(at::Tensor, c10::IntArrayRef, double)’:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:129:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(input);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_affine(at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:149:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(input);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:150:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(gamma);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:151:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(beta);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp: In function ‘at::Tensor layer_norm_gradient(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, double)’:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:193:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(dout);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:194:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(mean);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:195:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(invvar);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:196:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(input);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_gradient_affine(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:218:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(dout);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:219:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(mean);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:220:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(invvar);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:221:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(input);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:222:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(gamma);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:223:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(beta);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_61,code=sm_61 -std=c++14\n","    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n","    building 'mlp_cuda' extension\n","    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/mlp.cpp -o build/temp.linux-x86_64-3.6/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)’:\n","    csrc/mlp.cpp:56:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","       for (int i = 0; i < num_layers; i++) {\n","                       ~~^~~~~~~~~~~~\n","    csrc/mlp.cpp:64:77: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","       auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n","                                                                                 ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    csrc/mlp.cpp:65:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n","                                                                       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n","                                                                        ^\n","    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:67:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","                                                          ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","         const auto& the_type = TYPE;                                             \\\n","                                ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:131:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n","         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n","                                                            ^\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n","     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n","                           ^~~~~~~~~~~\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_fp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_fp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_fp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)’:\n","    csrc/mlp.cpp:113:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","       for (int i = 0; i < num_layers; i++) {\n","                       ~~^~~~~~~~~~~~\n","    csrc/mlp.cpp:119:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","       for (int i = 0; i < inputs.size(); i++) {\n","                       ~~^~~~~~~~~~~~~~~\n","    csrc/mlp.cpp:120:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","         outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n","                                                                       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:123:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","                                                          ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","         const auto& the_type = TYPE;                                             \\\n","                                ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:131:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n","         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n","                                                            ^\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n","     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n","                           ^~~~~~~~~~~\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < inputs.size(); i++) {\n","                         ~~^~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                                                                    ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_bp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < inputs.size(); i++) {\n","                         ~~^~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                                                                    ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_bp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < inputs.size(); i++) {\n","                         ~~^~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                                                                    ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_bp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/mlp_cuda.cu -o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_61,code=sm_61 -std=c++14\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\n","\n","    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/mlp.o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so\n","    running install_lib\n","    copying build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n","    copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n","    copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n","    copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n","    creating /usr/local/lib/python3.6/dist-packages/apex\n","    creating /usr/local/lib/python3.6/dist-packages/apex/normalization\n","    copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n","    copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n","    creating /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n","    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n","    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n","    creating /usr/local/lib/python3.6/dist-packages/apex/contrib\n","    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n","    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib\n","    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof\n","    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/nvmarker.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n","    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/data.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/activation.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/convert.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/utility.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/optim.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/blas.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/index_slice_join_mutate.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/randomSample.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/prof.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/base.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/dropout.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/misc.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/softmax.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/embedding.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/usage.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/reduction.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/linear.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/conv.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/recurrentCell.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/loss.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pooling.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/output.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pointwise.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/normalization.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof\n","    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/parse.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/db.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/nvvp.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex\n","    creating /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    creating /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    creating /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n","    copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n","    copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n","    copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n","    copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n","    copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    creating /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    creating /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n","    copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n","    copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n","    copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n","    creating /usr/local/lib/python3.6/dist-packages/apex/mlp\n","    copying build/lib.linux-x86_64-3.6/apex/mlp/mlp.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n","    copying build/lib.linux-x86_64-3.6/apex/mlp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n","    creating /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n","    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n","    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n","    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n","    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n","    creating /usr/local/lib/python3.6/dist-packages/apex/RNN\n","    copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n","    copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n","    copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n","    copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n","    copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/data.py to data.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/base.py to base.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/output.py to output.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/db.py to db.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/opt.py to opt.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/utils.py to utils.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/handle.py to handle.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/compat.py to compat.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/amp.py to amp.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/mlp.py to mlp.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/models.py to models.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n","    running install_egg_info\n","    running egg_info\n","    creating apex.egg-info\n","    writing apex.egg-info/PKG-INFO\n","    writing dependency_links to apex.egg-info/dependency_links.txt\n","    writing top-level names to apex.egg-info/top_level.txt\n","    writing manifest file 'apex.egg-info/SOURCES.txt'\n","    writing manifest file 'apex.egg-info/SOURCES.txt'\n","    Copying apex.egg-info to /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg-info\n","    running install_scripts\n","    writing list of installed files to '/tmp/pip-record-4p1ma8c8/install-record.txt'\n","    Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n","  Removing source in /tmp/pip-req-build-fhafgr5q\n","Successfully installed apex-0.1\n","Cleaning up...\n","Removed build tracker '/tmp/pip-req-tracker-pou2zn5e'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mxsx7-BEsYc5","colab_type":"text"},"source":["# **Train**"]},{"cell_type":"code","metadata":{"id":"wkGC9UTLsXtX","colab_type":"code","outputId":"ffaa6630-4210-4938-c89c-1083ec5b00a0","executionInfo":{"status":"ok","timestamp":1589022211987,"user_tz":-120,"elapsed":2169,"user":{"displayName":"Pascal Notsawo","photoUrl":"","userId":"05128058352342027621"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["%env exp_id=africa\n","#%env batch_size=32\n","%env batch_size=16\n","%env lgs=es-fr\n","# Maximum length of sentences (after BPE)\n","%env max_len=100"],"execution_count":0,"outputs":[{"output_type":"stream","text":["env: exp_id=africa\n","env: batch_size=16\n","env: lgs=es-fr\n","env: max_len=100\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"019wx7fm6BWB","colab_type":"code","outputId":"c8d69e11-af05-4f67-8695-af1d03ea632d","executionInfo":{"status":"ok","timestamp":1589022217433,"user_tz":-120,"elapsed":1759,"user":{"displayName":"Pascal Notsawo","photoUrl":"","userId":"05128058352342027621"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# le plus grand fichier à tensor_len phrases, on cherche le multiple de \"batch_size\" le plus proche de ce \n","# nombre par valeur supérieur : epoch_size doit etre un multiple non nul de ce nombre (pour ne pas gaspiller) \n","\n","main_path = \"/content/XLM/data/africa/para/\"\n","        \n","import io\n","\n","def n_lines(file_path):\n","    return len(io.open(file_path, encoding='UTF-8').read().split('\\n'))\n","\n","tensor_len = n_lines(file_path = main_path + \"Anglais-Bulu/Anglais-Bulu.Anglais.train\")\n","print(\"tensor_len = \" + str(tensor_len))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor_len = 22855\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DmOPfept6pvd","colab_type":"code","outputId":"caf901c1-5d30-4941-9663-deea7788c5ef","executionInfo":{"status":"ok","timestamp":1589022221265,"user_tz":-120,"elapsed":880,"user":{"displayName":"Pascal Notsawo","photoUrl":"","userId":"05128058352342027621"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["tensor_len=22855\n","#batch_size=32\n","batch_size=16\n","\n","def getEpochSize(tensor_len, batch_size):\n","    i = tensor_len\n","    while True :\n","        if i%batch_size == 0 :\n","            return i//batch_size\n","        i = i + 1\n","        \n","epoch_size = getEpochSize(tensor_len, batch_size)\n","print(\"epoch_size = \" + str(epoch_size))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["epoch_size = 1429\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5L7dGGaj6ybO","colab_type":"code","outputId":"8d6ccbd2-9b29-472b-b9f8-dc68768769d1","executionInfo":{"status":"ok","timestamp":1589022364469,"user_tz":-120,"elapsed":3220,"user":{"displayName":"Pascal Notsawo","photoUrl":"","userId":"05128058352342027621"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Et deduire epoch_size (evaluation frequency, -1 for parallel data size)\n","%env epoch_size=1429\n","#%env epoch_size=-1"],"execution_count":0,"outputs":[{"output_type":"stream","text":["env: epoch_size=1429\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I_JacKrE65LU","colab_type":"code","outputId":"d780a46f-07e4-42e5-9de7-7e2606110dbf","executionInfo":{"status":"ok","timestamp":1589022270294,"user_tz":-120,"elapsed":1784,"user":{"displayName":"Pascal Notsawo","photoUrl":"","userId":"05128058352342027621"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["%env remove_long_sentences_train=True\n","%env remove_long_sentences_valid=True\n","%env remove_long_sentences_test=True\n","#--remove_long_sentences_train $remove_long_sentences_train --remove_long_sentences_valid $remove_long_sentences_valid --remove_long_sentences_test $remove_long_sentences_test"],"execution_count":0,"outputs":[{"output_type":"stream","text":["env: remove_long_sentences_train=True\n","env: remove_long_sentences_valid=True\n","env: remove_long_sentences_test=True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m9keczVQ6_U4","colab_type":"code","outputId":"4554b35f-aaf1-4273-8823-ed512f2554f9","executionInfo":{"status":"ok","timestamp":1589022274798,"user_tz":-120,"elapsed":1765,"user":{"displayName":"Pascal Notsawo","photoUrl":"","userId":"05128058352342027621"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# limit the number of examples (-1 by default for non limitation)\n","%env train_n_samples=-1\n","%env valid_n_samples=-1\n","%env test_n_samples=-1\n","#--train_n_samples $train_n_samples --valid_n_samples $valid_n_samples --test_n_samples $test_n_samples"],"execution_count":0,"outputs":[{"output_type":"stream","text":["env: train_n_samples=-1\n","env: valid_n_samples=-1\n","env: test_n_samples=-1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y24p_39i7GWi","colab_type":"text"},"source":["**Pretrain a language model**"]},{"cell_type":"code","metadata":{"id":"UvjwR3mo7KLK","colab_type":"code","outputId":"da91020c-46f9-4ebc-ad09-818282a40a7a","executionInfo":{"status":"ok","timestamp":1589022282283,"user_tz":-120,"elapsed":2298,"user":{"displayName":"Pascal Notsawo","photoUrl":"","userId":"05128058352342027621"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# stopping criterion (if criterion does not improve 10 times)\n","%env stopping_criterion=_valid_mlm_ppl,10\n","%env eval_bleu false\n","%env lgs=Anglais-Bulu\n","%env mlm_steps=Anglais,Bulu,Anglais-Bulu"],"execution_count":0,"outputs":[{"output_type":"stream","text":["env: stopping_criterion=_valid_mlm_ppl,10\n","env: eval_bleu=false\n","env: lgs=Anglais-Bulu\n","env: mlm_steps=Anglais,Bulu,Anglais-Bulu\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7zaPzvvL7OgC","colab_type":"code","outputId":"e753b907-d6b3-40c6-fdb7-fb016f000386","executionInfo":{"status":"ok","timestamp":1589024229227,"user_tz":-120,"elapsed":1607976,"user":{"displayName":"Pascal Notsawo","photoUrl":"","userId":"05128058352342027621"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%env max_epoch=18\n","#! export NGPU=1; python -m torch.distributed.launch --nproc_per_node=$NGPU train.py --exp_name esit_mlm_tlm --dump_path ./dumped/ --data_path $OUTPATH --lgs $lgs --clm_steps '' --mlm_steps $mlm_steps --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout 0.1 --attention_dropout 0.1 --gelu_activation true --batch_size $batch_size --bptt 256 --optimizer adam,lr=0.0001 --epoch_size $epoch_size --max_epoch $max_epoch --validation_metrics _valid_mlm_ppl --stopping_criterion $stopping_criterion --eval_bleu $eval_bleu --exp_id $exp_id --remove_long_sentences_train $remove_long_sentences_train --remove_long_sentences_valid $remove_long_sentences_valid --remove_long_sentences_test $remove_long_sentences_test --train_n_samples $train_n_samples --valid_n_samples $valid_n_samples --test_n_samples $test_n_samples \n","! python train.py --exp_name Anglais_Bulu_mlm_tlm --dump_path ./dumped/ --data_path $OUTPATH/Anglais-Bulu --lgs $lgs --clm_steps '' --mlm_steps $mlm_steps --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout 0.1 --attention_dropout 0.1 --gelu_activation true --batch_size $batch_size --bptt 256 --optimizer adam,lr=0.0001 --epoch_size $epoch_size --max_epoch $max_epoch --validation_metrics _valid_mlm_ppl --stopping_criterion $stopping_criterion --eval_bleu $eval_bleu --exp_id $exp_id --remove_long_sentences_train $remove_long_sentences_train --remove_long_sentences_valid $remove_long_sentences_valid --remove_long_sentences_test $remove_long_sentences_test --train_n_samples $train_n_samples --valid_n_samples $valid_n_samples --test_n_samples $test_n_samples "],"execution_count":0,"outputs":[{"output_type":"stream","text":["env: max_epoch=18\n","FAISS library was not found.\n","FAISS not available. Switching to standard nearest neighbors search implementation.\n","SLURM job: False\n","0 - Number of nodes: 1\n","0 - Node ID        : 0\n","0 - Local rank     : 0\n","0 - Global rank    : 0\n","0 - World size     : 1\n","0 - GPUs per node  : 1\n","0 - Master         : True\n","0 - Multi-node     : False\n","0 - Multi-GPU      : False\n","0 - Hostname       : 09297f1b806a\n","INFO - 05/09/20 13:10:26 - 0:00:00 - ============ Initialized logger ============\n","INFO - 05/09/20 13:10:26 - 0:00:00 - accumulate_gradients: 1\n","                                     ae_steps: []\n","                                     amp: -1\n","                                     asm: False\n","                                     attention_dropout: 0.1\n","                                     batch_size: 16\n","                                     beam_size: 1\n","                                     bptt: 256\n","                                     bt_src_langs: []\n","                                     bt_steps: []\n","                                     clip_grad_norm: 5\n","                                     clm_steps: []\n","                                     command: python train.py --exp_name Anglais_Bulu_mlm_tlm --dump_path './dumped/' --data_path 'data/africa/processed/30000/Anglais-Bulu' --lgs 'Anglais-Bulu' --clm_steps '' --mlm_steps 'Anglais,Bulu,Anglais-Bulu' --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 16 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 1429 --max_epoch 18 --validation_metrics _valid_mlm_ppl --stopping_criterion '_valid_mlm_ppl,10' --eval_bleu false --exp_id africa --remove_long_sentences_train True --remove_long_sentences_valid True --remove_long_sentences_test True --train_n_samples '-1' --valid_n_samples '-1' --test_n_samples '-1' --exp_id \"africa\"\n","                                     context_size: 0\n","                                     data_path: data/africa/processed/30000/Anglais-Bulu\n","                                     debug: False\n","                                     debug_slurm: False\n","                                     debug_train: False\n","                                     dropout: 0.1\n","                                     dump_path: ./dumped/Anglais_Bulu_mlm_tlm/africa\n","                                     early_stopping: False\n","                                     emb_dim: 1024\n","                                     encoder_only: True\n","                                     epoch_size: 1429\n","                                     eval_bleu: False\n","                                     eval_only: False\n","                                     exp_id: africa\n","                                     exp_name: Anglais_Bulu_mlm_tlm\n","                                     fp16: False\n","                                     gelu_activation: True\n","                                     global_rank: 0\n","                                     group_by_size: True\n","                                     id2lang: {0: 'Anglais', 1: 'Bulu'}\n","                                     is_master: True\n","                                     is_slurm_job: False\n","                                     lambda_ae: 1\n","                                     lambda_bt: 1\n","                                     lambda_clm: 1\n","                                     lambda_mlm: 1\n","                                     lambda_mt: 1\n","                                     lambda_pc: 1\n","                                     lang2id: {'Anglais': 0, 'Bulu': 1}\n","                                     langs: ['Anglais', 'Bulu']\n","                                     length_penalty: 1\n","                                     lg_sampling_factor: -1\n","                                     lgs: Anglais-Bulu\n","                                     local_rank: 0\n","                                     master_port: -1\n","                                     max_batch_size: 0\n","                                     max_epoch: 18\n","                                     max_len: 100\n","                                     max_vocab: -1\n","                                     min_count: 0\n","                                     mlm_steps: [('Anglais', None), ('Bulu', None), ('Anglais', 'Bulu')]\n","                                     mono_dataset: {'Anglais': {'train': 'data/africa/processed/30000/Anglais-Bulu/train.Anglais.pth', 'valid': 'data/africa/processed/30000/Anglais-Bulu/valid.Anglais.pth', 'test': 'data/africa/processed/30000/Anglais-Bulu/test.Anglais.pth'}, 'Bulu': {'train': 'data/africa/processed/30000/Anglais-Bulu/train.Bulu.pth', 'valid': 'data/africa/processed/30000/Anglais-Bulu/valid.Bulu.pth', 'test': 'data/africa/processed/30000/Anglais-Bulu/test.Bulu.pth'}}\n","                                     mt_steps: []\n","                                     multi_gpu: False\n","                                     multi_node: False\n","                                     n_gpu_per_node: 1\n","                                     n_heads: 8\n","                                     n_langs: 2\n","                                     n_layers: 6\n","                                     n_nodes: 1\n","                                     n_samples: {'train': -1, 'valid': -1, 'test': -1}\n","                                     node_id: 0\n","                                     optimizer: adam,lr=0.0001\n","                                     para_dataset: {('Anglais', 'Bulu'): {'train': ('data/africa/processed/30000/Anglais-Bulu/train.Anglais-Bulu.Anglais.pth', 'data/africa/processed/30000/Anglais-Bulu/train.Anglais-Bulu.Bulu.pth'), 'valid': ('data/africa/processed/30000/Anglais-Bulu/valid.Anglais-Bulu.Anglais.pth', 'data/africa/processed/30000/Anglais-Bulu/valid.Anglais-Bulu.Bulu.pth'), 'test': ('data/africa/processed/30000/Anglais-Bulu/test.Anglais-Bulu.Anglais.pth', 'data/africa/processed/30000/Anglais-Bulu/test.Anglais-Bulu.Bulu.pth')}}\n","                                     pc_steps: []\n","                                     reload_checkpoint: \n","                                     reload_emb: \n","                                     reload_model: \n","                                     remove_long_sentences: {'train': True, 'valid': True, 'test': True}\n","                                     remove_long_sentences_test: True\n","                                     remove_long_sentences_train: True\n","                                     remove_long_sentences_valid: True\n","                                     sample_alpha: 0\n","                                     save_periodic: 0\n","                                     share_inout_emb: True\n","                                     sinusoidal_embeddings: False\n","                                     split_data: False\n","                                     stopping_criterion: _valid_mlm_ppl,10\n","                                     test_n_samples: -1\n","                                     tokens_per_batch: -1\n","                                     train_n_samples: -1\n","                                     use_lang_emb: True\n","                                     use_memory: False\n","                                     valid_n_samples: -1\n","                                     validation_metrics: _valid_mlm_ppl\n","                                     word_blank: 0\n","                                     word_dropout: 0\n","                                     word_keep: 0.1\n","                                     word_mask: 0.8\n","                                     word_mask_keep_rand: 0.8,0.1,0.1\n","                                     word_pred: 0.15\n","                                     word_rand: 0.1\n","                                     word_shuffle: 0\n","                                     world_size: 1\n","INFO - 05/09/20 13:10:26 - 0:00:00 - The experiment will be stored in ./dumped/Anglais_Bulu_mlm_tlm/africa\n","                                     \n","INFO - 05/09/20 13:10:26 - 0:00:00 - Running command: python train.py --exp_name Anglais_Bulu_mlm_tlm --dump_path './dumped/' --data_path 'data/africa/processed/30000/Anglais-Bulu' --lgs 'Anglais-Bulu' --clm_steps '' --mlm_steps 'Anglais,Bulu,Anglais-Bulu' --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 16 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 1429 --max_epoch 18 --validation_metrics _valid_mlm_ppl --stopping_criterion '_valid_mlm_ppl,10' --eval_bleu false --exp_id africa --remove_long_sentences_train True --remove_long_sentences_valid True --remove_long_sentences_test True --train_n_samples '-1' --valid_n_samples '-1' --test_n_samples '-1'\n","\n","WARNING - 05/09/20 13:10:26 - 0:00:00 - Signal handler installed.\n","INFO - 05/09/20 13:10:26 - 0:00:00 - ============ Monolingual data (Anglais)\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Loading data from data/africa/processed/30000/Anglais-Bulu/train.Anglais.pth ...\n","INFO - 05/09/20 13:10:26 - 0:00:00 - 691905 words (22320 unique) in 22854 sentences. 61 unknown words (61 unique) covering 0.01% of the data.\n","\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Loading data from data/africa/processed/30000/Anglais-Bulu/valid.Anglais.pth ...\n","INFO - 05/09/20 13:10:26 - 0:00:00 - 86874 words (22320 unique) in 2856 sentences. 744 unknown words (547 unique) covering 0.86% of the data.\n","\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Loading data from data/africa/processed/30000/Anglais-Bulu/test.Anglais.pth ...\n","INFO - 05/09/20 13:10:26 - 0:00:00 - 88338 words (22320 unique) in 2856 sentences. 594 unknown words (451 unique) covering 0.67% of the data.\n","\n","INFO - 05/09/20 13:10:26 - 0:00:00 - ============ Monolingual data (Bulu)\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Loading data from data/africa/processed/30000/Anglais-Bulu/train.Bulu.pth ...\n","INFO - 05/09/20 13:10:26 - 0:00:00 - 689397 words (22320 unique) in 22854 sentences. 55 unknown words (53 unique) covering 0.01% of the data.\n","\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Loading data from data/africa/processed/30000/Anglais-Bulu/valid.Bulu.pth ...\n","INFO - 05/09/20 13:10:26 - 0:00:00 - 86292 words (22320 unique) in 2856 sentences. 487 unknown words (365 unique) covering 0.56% of the data.\n","\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Loading data from data/africa/processed/30000/Anglais-Bulu/test.Bulu.pth ...\n","INFO - 05/09/20 13:10:26 - 0:00:00 - 87841 words (22320 unique) in 2856 sentences. 465 unknown words (353 unique) covering 0.53% of the data.\n","\n","\n","INFO - 05/09/20 13:10:26 - 0:00:00 - ============ Parallel data (Anglais-Bulu)\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Loading data from data/africa/processed/30000/Anglais-Bulu/train.Anglais-Bulu.Anglais.pth ...\n","INFO - 05/09/20 13:10:26 - 0:00:00 - 691905 words (22320 unique) in 22854 sentences. 61 unknown words (61 unique) covering 0.01% of the data.\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Loading data from data/africa/processed/30000/Anglais-Bulu/train.Anglais-Bulu.Bulu.pth ...\n","INFO - 05/09/20 13:10:26 - 0:00:00 - 689397 words (22320 unique) in 22854 sentences. 55 unknown words (53 unique) covering 0.01% of the data.\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Removed 0 empty sentences.\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Removed 0 empty sentences.\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Removed 3 too long sentences.\n","\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Loading data from data/africa/processed/30000/Anglais-Bulu/valid.Anglais-Bulu.Anglais.pth ...\n","INFO - 05/09/20 13:10:26 - 0:00:00 - 86874 words (22320 unique) in 2856 sentences. 744 unknown words (547 unique) covering 0.86% of the data.\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Loading data from data/africa/processed/30000/Anglais-Bulu/valid.Anglais-Bulu.Bulu.pth ...\n","INFO - 05/09/20 13:10:26 - 0:00:00 - 86292 words (22320 unique) in 2856 sentences. 487 unknown words (365 unique) covering 0.56% of the data.\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Removed 0 empty sentences.\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Removed 0 empty sentences.\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Removed 0 too long sentences.\n","\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Loading data from data/africa/processed/30000/Anglais-Bulu/test.Anglais-Bulu.Anglais.pth ...\n","INFO - 05/09/20 13:10:26 - 0:00:00 - 88338 words (22320 unique) in 2856 sentences. 594 unknown words (451 unique) covering 0.67% of the data.\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Loading data from data/africa/processed/30000/Anglais-Bulu/test.Anglais-Bulu.Bulu.pth ...\n","INFO - 05/09/20 13:10:26 - 0:00:00 - 87841 words (22320 unique) in 2856 sentences. 465 unknown words (353 unique) covering 0.53% of the data.\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Removed 0 empty sentences.\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Removed 0 empty sentences.\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Removed 0 too long sentences.\n","\n","\n","INFO - 05/09/20 13:10:26 - 0:00:00 - ============ Data summary\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Monolingual data   - train -      Anglais:     22854\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Monolingual data   - valid -      Anglais:      2856\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Monolingual data   -  test -      Anglais:      2856\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Monolingual data   - train -         Bulu:     22854\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Monolingual data   - valid -         Bulu:      2856\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Monolingual data   -  test -         Bulu:      2856\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Parallel data      - train - Anglais-Bulu:     22851\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Parallel data      - valid - Anglais-Bulu:      2856\n","INFO - 05/09/20 13:10:26 - 0:00:00 - Parallel data      -  test - Anglais-Bulu:      2856\n","\n","INFO - 05/09/20 13:10:28 - 0:00:02 - Model: TransformerModel(\n","                                       (position_embeddings): Embedding(512, 1024)\n","                                       (lang_embeddings): Embedding(2, 1024)\n","                                       (embeddings): Embedding(22320, 1024, padding_idx=2)\n","                                       (layer_norm_emb): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                                       (attentions): ModuleList(\n","                                         (0): MultiHeadAttention(\n","                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                         )\n","                                         (1): MultiHeadAttention(\n","                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                         )\n","                                         (2): MultiHeadAttention(\n","                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                         )\n","                                         (3): MultiHeadAttention(\n","                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                         )\n","                                         (4): MultiHeadAttention(\n","                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                         )\n","                                         (5): MultiHeadAttention(\n","                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n","                                         )\n","                                       )\n","                                       (layer_norm1): ModuleList(\n","                                         (0): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                                         (1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                                         (2): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                                         (3): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                                         (4): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                                         (5): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                                       )\n","                                       (ffns): ModuleList(\n","                                         (0): TransformerFFN(\n","                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n","                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n","                                         )\n","                                         (1): TransformerFFN(\n","                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n","                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n","                                         )\n","                                         (2): TransformerFFN(\n","                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n","                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n","                                         )\n","                                         (3): TransformerFFN(\n","                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n","                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n","                                         )\n","                                         (4): TransformerFFN(\n","                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n","                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n","                                         )\n","                                         (5): TransformerFFN(\n","                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n","                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n","                                         )\n","                                       )\n","                                       (layer_norm2): ModuleList(\n","                                         (0): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                                         (1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                                         (2): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                                         (3): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                                         (4): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                                         (5): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                                       )\n","                                       (memories): ModuleDict()\n","                                       (pred_layer): PredLayer(\n","                                         (proj): Linear(in_features=1024, out_features=22320, bias=True)\n","                                       )\n","                                     )\n","INFO - 05/09/20 13:10:28 - 0:00:02 - Number of parameters (model): 98983728\n","INFO - 05/09/20 13:10:31 - 0:00:05 - Found 0 memories.\n","INFO - 05/09/20 13:10:31 - 0:00:05 - Found 6 FFN.\n","INFO - 05/09/20 13:10:31 - 0:00:05 - Found 102 parameters in model.\n","INFO - 05/09/20 13:10:31 - 0:00:05 - Optimizers: model\n","WARNING - 05/09/20 13:10:31 - 0:00:05 - Reloading checkpoint from ./dumped/Anglais_Bulu_mlm_tlm/africa/checkpoint.pth ...\n","WARNING - 05/09/20 13:10:31 - 0:00:05 - Not reloading checkpoint optimizer model.\n","WARNING - 05/09/20 13:10:31 - 0:00:05 - No 'num_updates' for optimizer model.\n","WARNING - 05/09/20 13:10:31 - 0:00:05 - Checkpoint reloaded. Resuming at epoch 2 / iteration 60 ...\n","INFO - 05/09/20 13:10:33 - 0:00:07 - ============ Starting epoch 2 ... ============\n","INFO - 05/09/20 13:10:33 - 0:00:07 - Creating new training data iterator (pred,Anglais) ...\n","/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha)\n","INFO - 05/09/20 13:10:33 - 0:00:07 - Creating new training data iterator (pred,Bulu) ...\n","INFO - 05/09/20 13:10:34 - 0:00:08 - Creating new training data iterator (pred,Anglais,Bulu) ...\n","INFO - 05/09/20 13:10:42 - 0:00:16 -      65 -   21.75 sent/s -   630.76 words/s - MLM-Anglais:  5.9606 || MLM-Bulu:  5.5143 || MLM-Anglais-Bulu:  5.4754 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:10:51 - 0:00:25 -      70 -   26.29 sent/s -   767.11 words/s - MLM-Anglais:  5.4661 || MLM-Bulu:  5.4488 || MLM-Anglais-Bulu:  5.3489 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:11:00 - 0:00:34 -      75 -   25.73 sent/s -   768.67 words/s - MLM-Anglais:  5.4806 || MLM-Bulu:  5.6037 || MLM-Anglais-Bulu:  5.2811 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:11:09 - 0:00:43 -      80 -   26.34 sent/s -   762.71 words/s - MLM-Anglais:  5.3623 || MLM-Bulu:  5.6141 || MLM-Anglais-Bulu:  5.1418 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:11:18 - 0:00:52 -      85 -   26.67 sent/s -   738.00 words/s - MLM-Anglais:  5.5211 || MLM-Bulu:  5.5266 || MLM-Anglais-Bulu:  5.5655 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:11:27 - 0:01:01 -      90 -   25.96 sent/s -   761.69 words/s - MLM-Anglais:  5.4908 || MLM-Bulu:  5.3764 || MLM-Anglais-Bulu:  5.4040 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:11:27 - 0:01:01 - ============ End of epoch 2 ============\n","INFO - 05/09/20 13:12:20 - 0:01:54 - epoch -> 2.000000\n","INFO - 05/09/20 13:12:20 - 0:01:54 - valid_Anglais_mlm_ppl -> 382.638895\n","INFO - 05/09/20 13:12:20 - 0:01:54 - valid_Anglais_mlm_acc -> 6.084266\n","INFO - 05/09/20 13:12:20 - 0:01:54 - valid_Bulu_mlm_ppl -> 385.673524\n","INFO - 05/09/20 13:12:20 - 0:01:54 - valid_Bulu_mlm_acc -> 7.449645\n","INFO - 05/09/20 13:12:20 - 0:01:54 - valid_Anglais_Bulu_mlm_ppl -> 358.512063\n","INFO - 05/09/20 13:12:20 - 0:01:54 - valid_Anglais_Bulu_mlm_acc -> 9.199110\n","INFO - 05/09/20 13:12:20 - 0:01:54 - valid_mlm_ppl -> 384.156210\n","INFO - 05/09/20 13:12:20 - 0:01:54 - valid_mlm_acc -> 6.766955\n","INFO - 05/09/20 13:12:20 - 0:01:54 - test_Anglais_mlm_ppl -> 378.905327\n","INFO - 05/09/20 13:12:20 - 0:01:54 - test_Anglais_mlm_acc -> 6.045030\n","INFO - 05/09/20 13:12:20 - 0:01:54 - test_Bulu_mlm_ppl -> 393.178084\n","INFO - 05/09/20 13:12:20 - 0:01:54 - test_Bulu_mlm_acc -> 7.826720\n","INFO - 05/09/20 13:12:20 - 0:01:54 - test_Anglais_Bulu_mlm_ppl -> 357.007344\n","INFO - 05/09/20 13:12:20 - 0:01:54 - test_Anglais_Bulu_mlm_acc -> 9.451231\n","INFO - 05/09/20 13:12:20 - 0:01:54 - test_mlm_ppl -> 386.041706\n","INFO - 05/09/20 13:12:20 - 0:01:54 - test_mlm_acc -> 6.935875\n","INFO - 05/09/20 13:12:20 - 0:01:54 - __log__:{\"epoch\": 2, \"valid_Anglais_mlm_ppl\": 382.6388954438586, \"valid_Anglais_mlm_acc\": 6.084266352386565, \"valid_Bulu_mlm_ppl\": 385.67352443515483, \"valid_Bulu_mlm_acc\": 7.4496445497630335, \"valid_Anglais_Bulu_mlm_ppl\": 358.5120629560315, \"valid_Anglais_Bulu_mlm_acc\": 9.199110122358176, \"valid_mlm_ppl\": 384.1562099395067, \"valid_mlm_acc\": 6.766955451074799, \"test_Anglais_mlm_ppl\": 378.90532687064973, \"test_Anglais_mlm_acc\": 6.045030044161297, \"test_Bulu_mlm_ppl\": 393.1780843572991, \"test_Bulu_mlm_acc\": 7.826720058245359, \"test_Anglais_Bulu_mlm_ppl\": 357.00734387493435, \"test_Anglais_Bulu_mlm_acc\": 9.45123062898815, \"test_mlm_ppl\": 386.0417056139744, \"test_mlm_acc\": 6.935875051203328}\n","INFO - 05/09/20 13:12:20 - 0:01:54 - New best score for valid_mlm_ppl: 384.156210\n","INFO - 05/09/20 13:12:20 - 0:01:54 - Saving best-valid_mlm_ppl to ./dumped/Anglais_Bulu_mlm_tlm/africa/best-valid_mlm_ppl.pth ...\n","WARNING - 05/09/20 13:12:20 - 0:01:54 - Saving model parameters ...\n","INFO - 05/09/20 13:12:21 - 0:01:55 - New best validation score: 384.156210\n","INFO - 05/09/20 13:12:21 - 0:01:55 - Saving checkpoint to ./dumped/Anglais_Bulu_mlm_tlm/africa/checkpoint.pth ...\n","WARNING - 05/09/20 13:12:21 - 0:01:55 - Saving model parameters ...\n","WARNING - 05/09/20 13:12:21 - 0:01:55 - Saving model optimizer ...\n","INFO - 05/09/20 13:12:26 - 0:02:00 - ============ Starting epoch 3 ... ============\n","INFO - 05/09/20 13:12:35 - 0:02:09 -      95 -    3.53 sent/s -   100.46 words/s - MLM-Anglais:  5.4372 || MLM-Bulu:  5.4657 || MLM-Anglais-Bulu:  5.3095 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:12:45 - 0:02:19 -     100 -   26.18 sent/s -   757.79 words/s - MLM-Anglais:  5.4126 || MLM-Bulu:  5.4552 || MLM-Anglais-Bulu:  5.3386 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:12:54 - 0:02:28 -     105 -   26.67 sent/s -   764.41 words/s - MLM-Anglais:  5.4297 || MLM-Bulu:  5.4795 || MLM-Anglais-Bulu:  5.2966 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:13:03 - 0:02:37 -     110 -   26.19 sent/s -   747.62 words/s - MLM-Anglais:  5.4321 || MLM-Bulu:  5.4021 || MLM-Anglais-Bulu:  5.2110 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:13:12 - 0:02:46 -     115 -   25.85 sent/s -   756.44 words/s - MLM-Anglais:  5.4955 || MLM-Bulu:  5.3388 || MLM-Anglais-Bulu:  5.2288 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:13:21 - 0:02:55 -     120 -   26.03 sent/s -   759.25 words/s - MLM-Anglais:  5.3675 || MLM-Bulu:  5.4143 || MLM-Anglais-Bulu:  5.3003 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:13:21 - 0:02:55 - ============ End of epoch 3 ============\n","INFO - 05/09/20 13:14:13 - 0:03:47 - epoch -> 3.000000\n","INFO - 05/09/20 13:14:13 - 0:03:47 - valid_Anglais_mlm_ppl -> 379.333592\n","INFO - 05/09/20 13:14:13 - 0:03:47 - valid_Anglais_mlm_acc -> 7.542722\n","INFO - 05/09/20 13:14:13 - 0:03:47 - valid_Bulu_mlm_ppl -> 372.582194\n","INFO - 05/09/20 13:14:13 - 0:03:47 - valid_Bulu_mlm_acc -> 6.020438\n","INFO - 05/09/20 13:14:13 - 0:03:47 - valid_Anglais_Bulu_mlm_ppl -> 345.758732\n","INFO - 05/09/20 13:14:13 - 0:03:47 - valid_Anglais_Bulu_mlm_acc -> 8.609566\n","INFO - 05/09/20 13:14:13 - 0:03:47 - valid_mlm_ppl -> 375.957893\n","INFO - 05/09/20 13:14:13 - 0:03:47 - valid_mlm_acc -> 6.781580\n","INFO - 05/09/20 13:14:13 - 0:03:47 - test_Anglais_mlm_ppl -> 368.372173\n","INFO - 05/09/20 13:14:13 - 0:03:47 - test_Anglais_mlm_acc -> 7.992471\n","INFO - 05/09/20 13:14:13 - 0:03:47 - test_Bulu_mlm_ppl -> 382.589461\n","INFO - 05/09/20 13:14:13 - 0:03:47 - test_Bulu_mlm_acc -> 5.780852\n","INFO - 05/09/20 13:14:13 - 0:03:47 - test_Anglais_Bulu_mlm_ppl -> 348.262807\n","INFO - 05/09/20 13:14:13 - 0:03:47 - test_Anglais_Bulu_mlm_acc -> 8.907931\n","INFO - 05/09/20 13:14:13 - 0:03:47 - test_mlm_ppl -> 375.480817\n","INFO - 05/09/20 13:14:13 - 0:03:47 - test_mlm_acc -> 6.886661\n","INFO - 05/09/20 13:14:13 - 0:03:47 - __log__:{\"epoch\": 3, \"valid_Anglais_mlm_ppl\": 379.33359165569874, \"valid_Anglais_mlm_acc\": 7.542722451384797, \"valid_Bulu_mlm_ppl\": 372.5821942308889, \"valid_Bulu_mlm_acc\": 6.0204383886255926, \"valid_Anglais_Bulu_mlm_ppl\": 345.75873195293894, \"valid_Anglais_Bulu_mlm_acc\": 8.60956618464961, \"valid_mlm_ppl\": 375.9578929432938, \"valid_mlm_acc\": 6.781580420005195, \"test_Anglais_mlm_ppl\": 368.3721726525925, \"test_Anglais_mlm_acc\": 7.99247086078332, \"test_Bulu_mlm_ppl\": 382.589460919193, \"test_Bulu_mlm_acc\": 5.78085183836913, \"test_Anglais_Bulu_mlm_ppl\": 348.2628067483648, \"test_Anglais_Bulu_mlm_acc\": 8.907930720145853, \"test_mlm_ppl\": 375.4808167858928, \"test_mlm_acc\": 6.886661349576225}\n","INFO - 05/09/20 13:14:13 - 0:03:47 - New best score for valid_mlm_ppl: 375.957893\n","INFO - 05/09/20 13:14:13 - 0:03:47 - Saving best-valid_mlm_ppl to ./dumped/Anglais_Bulu_mlm_tlm/africa/best-valid_mlm_ppl.pth ...\n","WARNING - 05/09/20 13:14:13 - 0:03:47 - Saving model parameters ...\n","INFO - 05/09/20 13:14:14 - 0:03:48 - New best validation score: 375.957893\n","INFO - 05/09/20 13:14:14 - 0:03:48 - Saving checkpoint to ./dumped/Anglais_Bulu_mlm_tlm/africa/checkpoint.pth ...\n","WARNING - 05/09/20 13:14:14 - 0:03:48 - Saving model parameters ...\n","WARNING - 05/09/20 13:14:14 - 0:03:48 - Saving model optimizer ...\n","INFO - 05/09/20 13:14:21 - 0:03:55 - ============ Starting epoch 4 ... ============\n","INFO - 05/09/20 13:14:30 - 0:04:04 -     125 -    3.49 sent/s -   101.15 words/s - MLM-Anglais:  5.4791 || MLM-Bulu:  5.3622 || MLM-Anglais-Bulu:  5.3317 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:14:39 - 0:04:13 -     130 -   26.47 sent/s -   756.30 words/s - MLM-Anglais:  5.3228 || MLM-Bulu:  5.3929 || MLM-Anglais-Bulu:  5.1179 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:14:48 - 0:04:22 -     135 -   26.09 sent/s -   756.68 words/s - MLM-Anglais:  5.5215 || MLM-Bulu:  5.4117 || MLM-Anglais-Bulu:  5.3715 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:14:57 - 0:04:31 -     140 -   26.40 sent/s -   758.66 words/s - MLM-Anglais:  5.5163 || MLM-Bulu:  5.4497 || MLM-Anglais-Bulu:  5.3387 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:15:07 - 0:04:41 -     145 -   26.09 sent/s -   741.16 words/s - MLM-Anglais:  5.3746 || MLM-Bulu:  5.3657 || MLM-Anglais-Bulu:  5.1569 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:15:16 - 0:04:50 -     150 -   26.39 sent/s -   757.64 words/s - MLM-Anglais:  5.4644 || MLM-Bulu:  5.3688 || MLM-Anglais-Bulu:  5.3930 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:15:16 - 0:04:50 - ============ End of epoch 4 ============\n","INFO - 05/09/20 13:16:08 - 0:05:42 - epoch -> 4.000000\n","INFO - 05/09/20 13:16:08 - 0:05:42 - valid_Anglais_mlm_ppl -> 379.764407\n","INFO - 05/09/20 13:16:08 - 0:05:42 - valid_Anglais_mlm_acc -> 7.395404\n","INFO - 05/09/20 13:16:08 - 0:05:42 - valid_Bulu_mlm_ppl -> 361.653156\n","INFO - 05/09/20 13:16:08 - 0:05:42 - valid_Bulu_mlm_acc -> 7.220083\n","INFO - 05/09/20 13:16:08 - 0:05:42 - valid_Anglais_Bulu_mlm_ppl -> 333.209329\n","INFO - 05/09/20 13:16:08 - 0:05:42 - valid_Anglais_Bulu_mlm_acc -> 9.873934\n","INFO - 05/09/20 13:16:08 - 0:05:42 - valid_mlm_ppl -> 370.708781\n","INFO - 05/09/20 13:16:08 - 0:05:42 - valid_mlm_acc -> 7.307743\n","INFO - 05/09/20 13:16:08 - 0:05:42 - test_Anglais_mlm_ppl -> 369.618729\n","INFO - 05/09/20 13:16:08 - 0:05:42 - test_Anglais_mlm_acc -> 7.992471\n","INFO - 05/09/20 13:16:08 - 0:05:42 - test_Bulu_mlm_ppl -> 367.520267\n","INFO - 05/09/20 13:16:08 - 0:05:42 - test_Bulu_mlm_acc -> 7.608300\n","INFO - 05/09/20 13:16:08 - 0:05:42 - test_Anglais_Bulu_mlm_ppl -> 335.081847\n","INFO - 05/09/20 13:16:08 - 0:05:42 - test_Anglais_Bulu_mlm_acc -> 10.071103\n","INFO - 05/09/20 13:16:08 - 0:05:42 - test_mlm_ppl -> 368.569498\n","INFO - 05/09/20 13:16:08 - 0:05:42 - test_mlm_acc -> 7.800385\n","INFO - 05/09/20 13:16:08 - 0:05:42 - __log__:{\"epoch\": 4, \"valid_Anglais_mlm_ppl\": 379.764406767673, \"valid_Anglais_mlm_acc\": 7.395403653506188, \"valid_Bulu_mlm_ppl\": 361.6531560418579, \"valid_Bulu_mlm_acc\": 7.220082938388626, \"valid_Anglais_Bulu_mlm_ppl\": 333.20932887217043, \"valid_Anglais_Bulu_mlm_acc\": 9.873934000741565, \"valid_mlm_ppl\": 370.70878140476543, \"valid_mlm_acc\": 7.307743295947407, \"test_Anglais_mlm_ppl\": 369.6187291572325, \"test_Anglais_mlm_acc\": 7.99247086078332, \"test_Bulu_mlm_ppl\": 367.5202671142445, \"test_Bulu_mlm_acc\": 7.608299963596651, \"test_Anglais_Bulu_mlm_ppl\": 335.0818474883549, \"test_Anglais_Bulu_mlm_acc\": 10.071103008204194, \"test_mlm_ppl\": 368.5694981357385, \"test_mlm_acc\": 7.800385412189986}\n","INFO - 05/09/20 13:16:08 - 0:05:42 - New best score for valid_mlm_ppl: 370.708781\n","INFO - 05/09/20 13:16:08 - 0:05:42 - Saving best-valid_mlm_ppl to ./dumped/Anglais_Bulu_mlm_tlm/africa/best-valid_mlm_ppl.pth ...\n","WARNING - 05/09/20 13:16:08 - 0:05:42 - Saving model parameters ...\n","INFO - 05/09/20 13:16:09 - 0:05:43 - New best validation score: 370.708781\n","INFO - 05/09/20 13:16:09 - 0:05:43 - Saving checkpoint to ./dumped/Anglais_Bulu_mlm_tlm/africa/checkpoint.pth ...\n","WARNING - 05/09/20 13:16:09 - 0:05:43 - Saving model parameters ...\n","WARNING - 05/09/20 13:16:09 - 0:05:43 - Saving model optimizer ...\n","INFO - 05/09/20 13:16:18 - 0:05:52 - ============ Starting epoch 5 ... ============\n","INFO - 05/09/20 13:16:27 - 0:06:01 -     155 -    3.38 sent/s -    97.48 words/s - MLM-Anglais:  5.3692 || MLM-Bulu:  5.3578 || MLM-Anglais-Bulu:  5.1333 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:16:36 - 0:06:10 -     160 -   25.77 sent/s -   769.37 words/s - MLM-Anglais:  5.6005 || MLM-Bulu:  5.3516 || MLM-Anglais-Bulu:  5.4169 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:16:45 - 0:06:19 -     165 -   26.13 sent/s -   750.02 words/s - MLM-Anglais:  5.4167 || MLM-Bulu:  5.3155 || MLM-Anglais-Bulu:  5.4523 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:16:54 - 0:06:28 -     170 -   26.50 sent/s -   746.24 words/s - MLM-Anglais:  5.2707 || MLM-Bulu:  5.4908 || MLM-Anglais-Bulu:  5.2409 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:17:04 - 0:06:38 -     175 -   25.69 sent/s -   755.51 words/s - MLM-Anglais:  5.4443 || MLM-Bulu:  5.3732 || MLM-Anglais-Bulu:  5.1713 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:17:13 - 0:06:47 -     180 -   26.17 sent/s -   747.65 words/s - MLM-Anglais:  5.3722 || MLM-Bulu:  5.1827 || MLM-Anglais-Bulu:  4.8408 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:17:13 - 0:06:47 - ============ End of epoch 5 ============\n","INFO - 05/09/20 13:18:05 - 0:07:39 - epoch -> 5.000000\n","INFO - 05/09/20 13:18:05 - 0:07:39 - valid_Anglais_mlm_ppl -> 374.698139\n","INFO - 05/09/20 13:18:05 - 0:07:39 - valid_Anglais_mlm_acc -> 6.393636\n","INFO - 05/09/20 13:18:05 - 0:07:39 - valid_Bulu_mlm_ppl -> 367.053635\n","INFO - 05/09/20 13:18:05 - 0:07:39 - valid_Bulu_mlm_acc -> 3.598934\n","INFO - 05/09/20 13:18:05 - 0:07:39 - valid_Anglais_Bulu_mlm_ppl -> 338.081071\n","INFO - 05/09/20 13:18:05 - 0:07:39 - valid_Anglais_Bulu_mlm_acc -> 7.578791\n","INFO - 05/09/20 13:18:05 - 0:07:39 - valid_mlm_ppl -> 370.875887\n","INFO - 05/09/20 13:18:05 - 0:07:39 - valid_mlm_acc -> 4.996285\n","INFO - 05/09/20 13:18:05 - 0:07:39 - test_Anglais_mlm_ppl -> 367.488235\n","INFO - 05/09/20 13:18:05 - 0:07:39 - test_Anglais_mlm_acc -> 6.327373\n","INFO - 05/09/20 13:18:05 - 0:07:39 - test_Bulu_mlm_ppl -> 377.008577\n","INFO - 05/09/20 13:18:05 - 0:07:39 - test_Bulu_mlm_acc -> 3.363669\n","INFO - 05/09/20 13:18:05 - 0:07:39 - test_Anglais_Bulu_mlm_ppl -> 340.336403\n","INFO - 05/09/20 13:18:05 - 0:07:39 - test_Anglais_Bulu_mlm_acc -> 7.299909\n","INFO - 05/09/20 13:18:05 - 0:07:39 - test_mlm_ppl -> 372.248406\n","INFO - 05/09/20 13:18:05 - 0:07:39 - test_mlm_acc -> 4.845521\n","INFO - 05/09/20 13:18:05 - 0:07:39 - __log__:{\"epoch\": 5, \"valid_Anglais_mlm_ppl\": 374.6981391890643, \"valid_Anglais_mlm_acc\": 6.393635827931644, \"valid_Bulu_mlm_ppl\": 367.0536348006326, \"valid_Bulu_mlm_acc\": 3.5989336492890995, \"valid_Anglais_Bulu_mlm_ppl\": 338.0810709370019, \"valid_Anglais_Bulu_mlm_acc\": 7.578791249536522, \"valid_mlm_ppl\": 370.87588699484843, \"valid_mlm_acc\": 4.996284738610372, \"test_Anglais_mlm_ppl\": 367.4882346020144, \"test_Anglais_mlm_acc\": 6.327372764786795, \"test_Bulu_mlm_ppl\": 377.00857726197825, \"test_Bulu_mlm_acc\": 3.3636694575900985, \"test_Anglais_Bulu_mlm_ppl\": 340.33640261545725, \"test_Anglais_Bulu_mlm_acc\": 7.2999088422971745, \"test_mlm_ppl\": 372.24840593199633, \"test_mlm_acc\": 4.845521111188447}\n","INFO - 05/09/20 13:18:05 - 0:07:39 - Not a better validation score (0 / 10).\n","INFO - 05/09/20 13:18:05 - 0:07:39 - Saving checkpoint to ./dumped/Anglais_Bulu_mlm_tlm/africa/checkpoint.pth ...\n","WARNING - 05/09/20 13:18:05 - 0:07:39 - Saving model parameters ...\n","WARNING - 05/09/20 13:18:05 - 0:07:39 - Saving model optimizer ...\n","INFO - 05/09/20 13:18:10 - 0:07:44 - ============ Starting epoch 6 ... ============\n","INFO - 05/09/20 13:18:19 - 0:07:53 -     185 -    3.64 sent/s -   102.55 words/s - MLM-Anglais:  5.3685 || MLM-Bulu:  5.4644 || MLM-Anglais-Bulu:  5.1567 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:18:28 - 0:08:02 -     190 -   26.73 sent/s -   759.57 words/s - MLM-Anglais:  5.4184 || MLM-Bulu:  5.3913 || MLM-Anglais-Bulu:  5.1867 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:18:37 - 0:08:11 -     195 -   26.55 sent/s -   748.19 words/s - MLM-Anglais:  5.3666 || MLM-Bulu:  5.3686 || MLM-Anglais-Bulu:  5.2627 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:18:46 - 0:08:20 -     200 -   26.48 sent/s -   759.72 words/s - MLM-Anglais:  5.3892 || MLM-Bulu:  5.3028 || MLM-Anglais-Bulu:  5.0603 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:18:55 - 0:08:29 -     205 -   27.05 sent/s -   746.33 words/s - MLM-Anglais:  5.4092 || MLM-Bulu:  5.3003 || MLM-Anglais-Bulu:  5.4617 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:19:04 - 0:08:38 -     210 -   26.37 sent/s -   753.93 words/s - MLM-Anglais:  5.4289 || MLM-Bulu:  5.2677 || MLM-Anglais-Bulu:  5.2915 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:19:04 - 0:08:38 - ============ End of epoch 6 ============\n","INFO - 05/09/20 13:19:56 - 0:09:30 - epoch -> 6.000000\n","INFO - 05/09/20 13:19:56 - 0:09:30 - valid_Anglais_mlm_ppl -> 363.805231\n","INFO - 05/09/20 13:19:56 - 0:09:30 - valid_Anglais_mlm_acc -> 6.585150\n","INFO - 05/09/20 13:19:56 - 0:09:30 - valid_Bulu_mlm_ppl -> 350.923923\n","INFO - 05/09/20 13:19:56 - 0:09:30 - valid_Bulu_mlm_acc -> 7.442239\n","INFO - 05/09/20 13:19:56 - 0:09:30 - valid_Anglais_Bulu_mlm_ppl -> 319.953730\n","INFO - 05/09/20 13:19:56 - 0:09:30 - valid_Anglais_Bulu_mlm_acc -> 8.650352\n","INFO - 05/09/20 13:19:56 - 0:09:30 - valid_mlm_ppl -> 357.364577\n","INFO - 05/09/20 13:19:56 - 0:09:30 - valid_mlm_acc -> 7.013695\n","INFO - 05/09/20 13:19:56 - 0:09:30 - test_Anglais_mlm_ppl -> 355.860721\n","INFO - 05/09/20 13:19:56 - 0:09:30 - test_Anglais_mlm_acc -> 6.790704\n","INFO - 05/09/20 13:19:56 - 0:09:30 - test_Bulu_mlm_ppl -> 359.076434\n","INFO - 05/09/20 13:19:56 - 0:09:30 - test_Bulu_mlm_acc -> 7.819439\n","INFO - 05/09/20 13:19:56 - 0:09:30 - test_Anglais_Bulu_mlm_ppl -> 322.849473\n","INFO - 05/09/20 13:19:56 - 0:09:30 - test_Anglais_Bulu_mlm_acc -> 8.860529\n","INFO - 05/09/20 13:19:56 - 0:09:30 - test_mlm_ppl -> 357.468577\n","INFO - 05/09/20 13:19:56 - 0:09:30 - test_mlm_acc -> 7.305072\n","INFO - 05/09/20 13:19:56 - 0:09:30 - __log__:{\"epoch\": 6, \"valid_Anglais_mlm_ppl\": 363.80523090174705, \"valid_Anglais_mlm_acc\": 6.585150265173836, \"valid_Bulu_mlm_ppl\": 350.92392292752174, \"valid_Bulu_mlm_acc\": 7.442239336492891, \"valid_Anglais_Bulu_mlm_ppl\": 319.9537304886721, \"valid_Anglais_Bulu_mlm_acc\": 8.650352243233222, \"valid_mlm_ppl\": 357.3645769146344, \"valid_mlm_acc\": 7.013694800833363, \"test_Anglais_mlm_ppl\": 355.8607208076732, \"test_Anglais_mlm_acc\": 6.790704408890176, \"test_Bulu_mlm_ppl\": 359.0764339044214, \"test_Bulu_mlm_acc\": 7.819439388423735, \"test_Anglais_Bulu_mlm_ppl\": 322.84947275688097, \"test_Anglais_Bulu_mlm_acc\": 8.86052871467639, \"test_mlm_ppl\": 357.46857735604726, \"test_mlm_acc\": 7.305071898656955}\n","INFO - 05/09/20 13:19:56 - 0:09:30 - New best score for valid_mlm_ppl: 357.364577\n","INFO - 05/09/20 13:19:56 - 0:09:30 - Saving best-valid_mlm_ppl to ./dumped/Anglais_Bulu_mlm_tlm/africa/best-valid_mlm_ppl.pth ...\n","WARNING - 05/09/20 13:19:56 - 0:09:30 - Saving model parameters ...\n","INFO - 05/09/20 13:19:57 - 0:09:31 - New best validation score: 357.364577\n","INFO - 05/09/20 13:19:57 - 0:09:31 - Saving checkpoint to ./dumped/Anglais_Bulu_mlm_tlm/africa/checkpoint.pth ...\n","WARNING - 05/09/20 13:19:57 - 0:09:31 - Saving model parameters ...\n","WARNING - 05/09/20 13:19:57 - 0:09:31 - Saving model optimizer ...\n","INFO - 05/09/20 13:20:06 - 0:09:40 - ============ Starting epoch 7 ... ============\n","INFO - 05/09/20 13:20:15 - 0:09:49 -     215 -    3.39 sent/s -    96.41 words/s - MLM-Anglais:  5.3711 || MLM-Bulu:  5.3460 || MLM-Anglais-Bulu:  5.2423 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:20:24 - 0:09:58 -     220 -   25.87 sent/s -   746.55 words/s - MLM-Anglais:  5.3768 || MLM-Bulu:  5.2776 || MLM-Anglais-Bulu:  5.0513 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:20:33 - 0:10:07 -     225 -   26.39 sent/s -   750.34 words/s - MLM-Anglais:  5.4526 || MLM-Bulu:  5.3132 || MLM-Anglais-Bulu:  5.0911 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:20:42 - 0:10:16 -     230 -   25.65 sent/s -   750.18 words/s - MLM-Anglais:  5.4110 || MLM-Bulu:  5.3938 || MLM-Anglais-Bulu:  5.0620 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:20:48 - 0:10:22 - Creating new training data iterator (pred,Bulu) ...\n","INFO - 05/09/20 13:20:52 - 0:10:26 -     235 -   25.96 sent/s -   746.21 words/s - MLM-Anglais:  5.2966 || MLM-Bulu:  5.3642 || MLM-Anglais-Bulu:  5.1943 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:20:52 - 0:10:26 - Creating new training data iterator (pred,Anglais) ...\n","INFO - 05/09/20 13:21:01 - 0:10:35 -     240 -   26.19 sent/s -   735.64 words/s - MLM-Anglais:  5.4830 || MLM-Bulu:  5.2588 || MLM-Anglais-Bulu:  5.3089 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:21:01 - 0:10:35 - ============ End of epoch 7 ============\n","INFO - 05/09/20 13:21:53 - 0:11:27 - epoch -> 7.000000\n","INFO - 05/09/20 13:21:53 - 0:11:27 - valid_Anglais_mlm_ppl -> 368.299463\n","INFO - 05/09/20 13:21:53 - 0:11:27 - valid_Anglais_mlm_acc -> 6.261049\n","INFO - 05/09/20 13:21:53 - 0:11:27 - valid_Bulu_mlm_ppl -> 348.848296\n","INFO - 05/09/20 13:21:53 - 0:11:27 - valid_Bulu_mlm_acc -> 6.612855\n","INFO - 05/09/20 13:21:53 - 0:11:27 - valid_Anglais_Bulu_mlm_ppl -> 319.438295\n","INFO - 05/09/20 13:21:53 - 0:11:27 - valid_Anglais_Bulu_mlm_acc -> 9.436411\n","INFO - 05/09/20 13:21:53 - 0:11:27 - valid_mlm_ppl -> 358.573879\n","INFO - 05/09/20 13:21:53 - 0:11:27 - valid_mlm_acc -> 6.436952\n","INFO - 05/09/20 13:21:53 - 0:11:27 - test_Anglais_mlm_ppl -> 360.797096\n","INFO - 05/09/20 13:21:53 - 0:11:27 - test_Anglais_mlm_acc -> 6.472164\n","INFO - 05/09/20 13:21:53 - 0:11:27 - test_Bulu_mlm_ppl -> 357.584082\n","INFO - 05/09/20 13:21:53 - 0:11:27 - test_Bulu_mlm_acc -> 6.909356\n","INFO - 05/09/20 13:21:53 - 0:11:27 - test_Anglais_Bulu_mlm_ppl -> 319.402033\n","INFO - 05/09/20 13:21:53 - 0:11:27 - test_Anglais_Bulu_mlm_acc -> 9.462170\n","INFO - 05/09/20 13:21:53 - 0:11:27 - test_mlm_ppl -> 359.190589\n","INFO - 05/09/20 13:21:53 - 0:11:27 - test_mlm_acc -> 6.690760\n","INFO - 05/09/20 13:21:53 - 0:11:27 - __log__:{\"epoch\": 7, \"valid_Anglais_mlm_ppl\": 368.29946280938964, \"valid_Anglais_mlm_acc\": 6.261048909840896, \"valid_Bulu_mlm_ppl\": 348.8482958879158, \"valid_Bulu_mlm_acc\": 6.6128554502369665, \"valid_Anglais_Bulu_mlm_ppl\": 319.43829501428445, \"valid_Anglais_Bulu_mlm_acc\": 9.436410826844643, \"valid_mlm_ppl\": 358.5738793486527, \"valid_mlm_acc\": 6.436952180038931, \"test_Anglais_mlm_ppl\": 360.79709647612674, \"test_Anglais_mlm_acc\": 6.472163903569101, \"test_Bulu_mlm_ppl\": 357.5840818980162, \"test_Bulu_mlm_acc\": 6.909355660720786, \"test_Anglais_Bulu_mlm_ppl\": 319.40203293043714, \"test_Anglais_Bulu_mlm_acc\": 9.462169553327255, \"test_mlm_ppl\": 359.1905891870715, \"test_mlm_acc\": 6.690759782144944}\n","INFO - 05/09/20 13:21:53 - 0:11:27 - Not a better validation score (0 / 10).\n","INFO - 05/09/20 13:21:53 - 0:11:27 - Saving checkpoint to ./dumped/Anglais_Bulu_mlm_tlm/africa/checkpoint.pth ...\n","WARNING - 05/09/20 13:21:53 - 0:11:27 - Saving model parameters ...\n","WARNING - 05/09/20 13:21:53 - 0:11:27 - Saving model optimizer ...\n","INFO - 05/09/20 13:21:57 - 0:11:31 - ============ Starting epoch 8 ... ============\n","INFO - 05/09/20 13:22:06 - 0:11:40 -     245 -    3.66 sent/s -   104.07 words/s - MLM-Anglais:  5.4461 || MLM-Bulu:  5.3418 || MLM-Anglais-Bulu:  5.6501 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:22:15 - 0:11:49 -     250 -   26.54 sent/s -   735.54 words/s - MLM-Anglais:  5.3612 || MLM-Bulu:  5.5587 || MLM-Anglais-Bulu:  5.3156 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:22:24 - 0:11:58 -     255 -   26.36 sent/s -   757.61 words/s - MLM-Anglais:  5.3388 || MLM-Bulu:  5.3936 || MLM-Anglais-Bulu:  5.1857 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:22:33 - 0:12:07 -     260 -   26.57 sent/s -   735.77 words/s - MLM-Anglais:  5.4046 || MLM-Bulu:  5.2979 || MLM-Anglais-Bulu:  5.2068 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:22:43 - 0:12:17 -     265 -   26.38 sent/s -   746.76 words/s - MLM-Anglais:  5.4962 || MLM-Bulu:  5.4100 || MLM-Anglais-Bulu:  5.1298 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:22:52 - 0:12:26 -     270 -   25.22 sent/s -   751.67 words/s - MLM-Anglais:  5.2687 || MLM-Bulu:  5.4336 || MLM-Anglais-Bulu:  5.0874 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:22:52 - 0:12:26 - ============ End of epoch 8 ============\n","INFO - 05/09/20 13:23:44 - 0:13:18 - epoch -> 8.000000\n","INFO - 05/09/20 13:23:44 - 0:13:18 - valid_Anglais_mlm_ppl -> 363.013929\n","INFO - 05/09/20 13:23:44 - 0:13:18 - valid_Anglais_mlm_acc -> 5.922216\n","INFO - 05/09/20 13:23:44 - 0:13:18 - valid_Bulu_mlm_ppl -> 351.797947\n","INFO - 05/09/20 13:23:44 - 0:13:18 - valid_Bulu_mlm_acc -> 7.212678\n","INFO - 05/09/20 13:23:44 - 0:13:18 - valid_Anglais_Bulu_mlm_ppl -> 313.828785\n","INFO - 05/09/20 13:23:44 - 0:13:18 - valid_Anglais_Bulu_mlm_acc -> 9.466073\n","INFO - 05/09/20 13:23:44 - 0:13:18 - valid_mlm_ppl -> 357.405938\n","INFO - 05/09/20 13:23:44 - 0:13:18 - valid_mlm_acc -> 6.567447\n","INFO - 05/09/20 13:23:44 - 0:13:18 - test_Anglais_mlm_ppl -> 358.721884\n","INFO - 05/09/20 13:23:44 - 0:13:18 - test_Anglais_mlm_acc -> 5.567219\n","INFO - 05/09/20 13:23:44 - 0:13:18 - test_Bulu_mlm_ppl -> 357.928081\n","INFO - 05/09/20 13:23:44 - 0:13:18 - test_Bulu_mlm_acc -> 7.608300\n","INFO - 05/09/20 13:23:44 - 0:13:18 - test_Anglais_Bulu_mlm_ppl -> 315.130488\n","INFO - 05/09/20 13:23:44 - 0:13:18 - test_Anglais_Bulu_mlm_acc -> 9.327256\n","INFO - 05/09/20 13:23:44 - 0:13:18 - test_mlm_ppl -> 358.324982\n","INFO - 05/09/20 13:23:44 - 0:13:18 - test_mlm_acc -> 6.587760\n","INFO - 05/09/20 13:23:44 - 0:13:18 - __log__:{\"epoch\": 8, \"valid_Anglais_mlm_ppl\": 363.01392854307466, \"valid_Anglais_mlm_acc\": 5.9222156747200945, \"valid_Bulu_mlm_ppl\": 351.797946887119, \"valid_Bulu_mlm_acc\": 7.212677725118484, \"valid_Anglais_Bulu_mlm_ppl\": 313.82878503576313, \"valid_Anglais_Bulu_mlm_acc\": 9.46607341490545, \"valid_mlm_ppl\": 357.4059377150968, \"valid_mlm_acc\": 6.567446699919289, \"test_Anglais_mlm_ppl\": 358.72188354368893, \"test_Anglais_mlm_acc\": 5.567219286179686, \"test_Bulu_mlm_ppl\": 357.9280809808515, \"test_Bulu_mlm_acc\": 7.608299963596651, \"test_Anglais_Bulu_mlm_ppl\": 315.13048768103664, \"test_Anglais_Bulu_mlm_acc\": 9.32725615314494, \"test_mlm_ppl\": 358.3249822622702, \"test_mlm_acc\": 6.587759624888168}\n","INFO - 05/09/20 13:23:44 - 0:13:18 - Not a better validation score (1 / 10).\n","INFO - 05/09/20 13:23:44 - 0:13:18 - Saving checkpoint to ./dumped/Anglais_Bulu_mlm_tlm/africa/checkpoint.pth ...\n","WARNING - 05/09/20 13:23:44 - 0:13:18 - Saving model parameters ...\n","WARNING - 05/09/20 13:23:44 - 0:13:18 - Saving model optimizer ...\n","INFO - 05/09/20 13:23:49 - 0:13:23 - ============ Starting epoch 9 ... ============\n","INFO - 05/09/20 13:23:58 - 0:13:32 -     275 -    3.64 sent/s -   102.04 words/s - MLM-Anglais:  5.2892 || MLM-Bulu:  5.4068 || MLM-Anglais-Bulu:  5.1693 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:24:07 - 0:13:41 -     280 -   26.14 sent/s -   742.54 words/s - MLM-Anglais:  5.4951 || MLM-Bulu:  5.2989 || MLM-Anglais-Bulu:  5.1682 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:24:17 - 0:13:51 -     285 -   25.71 sent/s -   752.47 words/s - MLM-Anglais:  5.3726 || MLM-Bulu:  5.3811 || MLM-Anglais-Bulu:  5.0294 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:24:26 - 0:14:00 -     290 -   26.30 sent/s -   737.47 words/s - MLM-Anglais:  5.2337 || MLM-Bulu:  5.2906 || MLM-Anglais-Bulu:  5.3826 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:24:35 - 0:14:09 -     295 -   26.30 sent/s -   751.49 words/s - MLM-Anglais:  5.4021 || MLM-Bulu:  5.5422 || MLM-Anglais-Bulu:  5.1475 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:24:44 - 0:14:18 -     300 -   26.13 sent/s -   759.56 words/s - MLM-Anglais:  5.3101 || MLM-Bulu:  5.2829 || MLM-Anglais-Bulu:  5.3246 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:24:44 - 0:14:18 - ============ End of epoch 9 ============\n","INFO - 05/09/20 13:25:36 - 0:15:10 - epoch -> 9.000000\n","INFO - 05/09/20 13:25:36 - 0:15:10 - valid_Anglais_mlm_ppl -> 351.126924\n","INFO - 05/09/20 13:25:36 - 0:15:10 - valid_Anglais_mlm_acc -> 6.187390\n","INFO - 05/09/20 13:25:36 - 0:15:10 - valid_Bulu_mlm_ppl -> 346.169473\n","INFO - 05/09/20 13:25:36 - 0:15:10 - valid_Bulu_mlm_acc -> 6.020438\n","INFO - 05/09/20 13:25:36 - 0:15:10 - valid_Anglais_Bulu_mlm_ppl -> 306.255872\n","INFO - 05/09/20 13:25:36 - 0:15:10 - valid_Anglais_Bulu_mlm_acc -> 10.003708\n","INFO - 05/09/20 13:25:36 - 0:15:10 - valid_mlm_ppl -> 348.648199\n","INFO - 05/09/20 13:25:36 - 0:15:10 - valid_mlm_acc -> 6.103914\n","INFO - 05/09/20 13:25:36 - 0:15:10 - test_Anglais_mlm_ppl -> 345.596364\n","INFO - 05/09/20 13:25:36 - 0:15:10 - test_Anglais_mlm_acc -> 6.117426\n","INFO - 05/09/20 13:25:36 - 0:15:10 - test_Bulu_mlm_ppl -> 356.137673\n","INFO - 05/09/20 13:25:36 - 0:15:10 - test_Bulu_mlm_acc -> 5.802694\n","INFO - 05/09/20 13:25:36 - 0:15:10 - test_Anglais_Bulu_mlm_ppl -> 307.720404\n","INFO - 05/09/20 13:25:36 - 0:15:10 - test_Anglais_Bulu_mlm_acc -> 10.074749\n","INFO - 05/09/20 13:25:36 - 0:15:10 - test_mlm_ppl -> 350.867018\n","INFO - 05/09/20 13:25:36 - 0:15:10 - test_mlm_acc -> 5.960060\n","INFO - 05/09/20 13:25:36 - 0:15:10 - __log__:{\"epoch\": 9, \"valid_Anglais_mlm_ppl\": 351.1269244027812, \"valid_Anglais_mlm_acc\": 6.187389510901591, \"valid_Bulu_mlm_ppl\": 346.16947335560184, \"valid_Bulu_mlm_acc\": 6.0204383886255926, \"valid_Anglais_Bulu_mlm_ppl\": 306.25587153887903, \"valid_Anglais_Bulu_mlm_acc\": 10.0037078235076, \"valid_mlm_ppl\": 348.6481988791915, \"valid_mlm_acc\": 6.103913949763592, \"test_Anglais_mlm_ppl\": 345.59636369043403, \"test_Anglais_mlm_acc\": 6.1174256135524505, \"test_Bulu_mlm_ppl\": 356.137672585701, \"test_Bulu_mlm_acc\": 5.802693847834001, \"test_Anglais_Bulu_mlm_ppl\": 307.7204036858587, \"test_Anglais_Bulu_mlm_acc\": 10.074749316317229, \"test_mlm_ppl\": 350.8670181380675, \"test_mlm_acc\": 5.960059730693226}\n","INFO - 05/09/20 13:25:36 - 0:15:10 - New best score for valid_mlm_ppl: 348.648199\n","INFO - 05/09/20 13:25:36 - 0:15:10 - Saving best-valid_mlm_ppl to ./dumped/Anglais_Bulu_mlm_tlm/africa/best-valid_mlm_ppl.pth ...\n","WARNING - 05/09/20 13:25:36 - 0:15:10 - Saving model parameters ...\n","INFO - 05/09/20 13:25:37 - 0:15:11 - New best validation score: 348.648199\n","INFO - 05/09/20 13:25:37 - 0:15:11 - Saving checkpoint to ./dumped/Anglais_Bulu_mlm_tlm/africa/checkpoint.pth ...\n","WARNING - 05/09/20 13:25:37 - 0:15:11 - Saving model parameters ...\n","WARNING - 05/09/20 13:25:37 - 0:15:11 - Saving model optimizer ...\n","INFO - 05/09/20 13:25:48 - 0:15:20 - ============ Starting epoch 10 ... ============\n","INFO - 05/09/20 13:25:57 - 0:15:31 -     305 -    3.30 sent/s -    91.46 words/s - MLM-Anglais:  5.3229 || MLM-Bulu:  5.3309 || MLM-Anglais-Bulu:  4.9587 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:26:06 - 0:15:40 -     310 -   26.38 sent/s -   747.23 words/s - MLM-Anglais:  5.3785 || MLM-Bulu:  5.3520 || MLM-Anglais-Bulu:  5.2743 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:26:15 - 0:15:49 -     315 -   25.61 sent/s -   751.75 words/s - MLM-Anglais:  5.4087 || MLM-Bulu:  5.3683 || MLM-Anglais-Bulu:  4.9554 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:26:24 - 0:15:58 -     320 -   25.37 sent/s -   751.39 words/s - MLM-Anglais:  5.2719 || MLM-Bulu:  5.3123 || MLM-Anglais-Bulu:  5.1833 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:26:34 - 0:16:08 -     325 -   25.36 sent/s -   742.15 words/s - MLM-Anglais:  5.2914 || MLM-Bulu:  5.3049 || MLM-Anglais-Bulu:  5.3206 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:26:43 - 0:16:17 -     330 -   25.58 sent/s -   745.65 words/s - MLM-Anglais:  5.2288 || MLM-Bulu:  5.2854 || MLM-Anglais-Bulu:  5.0813 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:26:43 - 0:16:17 - ============ End of epoch 10 ============\n","INFO - 05/09/20 13:27:36 - 0:17:10 - epoch -> 10.000000\n","INFO - 05/09/20 13:27:36 - 0:17:10 - valid_Anglais_mlm_ppl -> 358.330549\n","INFO - 05/09/20 13:27:36 - 0:17:10 - valid_Anglais_mlm_acc -> 6.371538\n","INFO - 05/09/20 13:27:36 - 0:17:10 - valid_Bulu_mlm_ppl -> 342.505778\n","INFO - 05/09/20 13:27:36 - 0:17:10 - valid_Bulu_mlm_acc -> 7.249704\n","INFO - 05/09/20 13:27:36 - 0:17:10 - valid_Anglais_Bulu_mlm_ppl -> 297.563552\n","INFO - 05/09/20 13:27:36 - 0:17:10 - valid_Anglais_Bulu_mlm_acc -> 10.826845\n","INFO - 05/09/20 13:27:36 - 0:17:10 - valid_mlm_ppl -> 350.418163\n","INFO - 05/09/20 13:27:36 - 0:17:10 - valid_mlm_acc -> 6.810621\n","INFO - 05/09/20 13:27:36 - 0:17:10 - test_Anglais_mlm_ppl -> 353.511783\n","INFO - 05/09/20 13:27:36 - 0:17:10 - test_Anglais_mlm_acc -> 6.370810\n","INFO - 05/09/20 13:27:36 - 0:17:10 - test_Bulu_mlm_ppl -> 350.402365\n","INFO - 05/09/20 13:27:36 - 0:17:10 - test_Bulu_mlm_acc -> 7.462687\n","INFO - 05/09/20 13:27:36 - 0:17:10 - test_Anglais_Bulu_mlm_ppl -> 298.895384\n","INFO - 05/09/20 13:27:36 - 0:17:10 - test_Anglais_Bulu_mlm_acc -> 10.647220\n","INFO - 05/09/20 13:27:36 - 0:17:10 - test_mlm_ppl -> 351.957074\n","INFO - 05/09/20 13:27:36 - 0:17:10 - test_mlm_acc -> 6.916748\n","INFO - 05/09/20 13:27:36 - 0:17:10 - __log__:{\"epoch\": 10, \"valid_Anglais_mlm_ppl\": 358.3305485236905, \"valid_Anglais_mlm_acc\": 6.3715380082498525, \"valid_Bulu_mlm_ppl\": 342.5057783662399, \"valid_Bulu_mlm_acc\": 7.249703791469194, \"valid_Anglais_Bulu_mlm_ppl\": 297.5635516617325, \"valid_Anglais_Bulu_mlm_acc\": 10.82684464219503, \"valid_mlm_ppl\": 350.4181634449652, \"valid_mlm_acc\": 6.810620899859524, \"test_Anglais_mlm_ppl\": 353.5117827123462, \"test_Anglais_mlm_acc\": 6.370810106421487, \"test_Bulu_mlm_ppl\": 350.40236545330663, \"test_Bulu_mlm_acc\": 7.462686567164179, \"test_Anglais_Bulu_mlm_ppl\": 298.8953837420719, \"test_Anglais_Bulu_mlm_acc\": 10.64721969006381, \"test_mlm_ppl\": 351.9570740828264, \"test_mlm_acc\": 6.916748336792834}\n","INFO - 05/09/20 13:27:36 - 0:17:10 - Not a better validation score (0 / 10).\n","INFO - 05/09/20 13:27:36 - 0:17:10 - Saving checkpoint to ./dumped/Anglais_Bulu_mlm_tlm/africa/checkpoint.pth ...\n","WARNING - 05/09/20 13:27:36 - 0:17:10 - Saving model parameters ...\n","WARNING - 05/09/20 13:27:36 - 0:17:10 - Saving model optimizer ...\n","INFO - 05/09/20 13:27:40 - 0:17:14 - ============ Starting epoch 11 ... ============\n","INFO - 05/09/20 13:27:49 - 0:17:23 -     335 -    3.64 sent/s -   105.66 words/s - MLM-Anglais:  5.3360 || MLM-Bulu:  5.2444 || MLM-Anglais-Bulu:  5.2585 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:27:58 - 0:17:32 -     340 -   26.23 sent/s -   748.23 words/s - MLM-Anglais:  5.2800 || MLM-Bulu:  5.3093 || MLM-Anglais-Bulu:  5.1986 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:28:08 - 0:17:42 -     345 -   26.05 sent/s -   753.40 words/s - MLM-Anglais:  5.4171 || MLM-Bulu:  5.3276 || MLM-Anglais-Bulu:  5.2702 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:28:17 - 0:17:51 -     350 -   25.80 sent/s -   740.83 words/s - MLM-Anglais:  5.1883 || MLM-Bulu:  5.2988 || MLM-Anglais-Bulu:  5.3953 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:28:26 - 0:18:00 -     355 -   25.70 sent/s -   746.33 words/s - MLM-Anglais:  5.2288 || MLM-Bulu:  5.3485 || MLM-Anglais-Bulu:  5.3270 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:28:35 - 0:18:09 -     360 -   26.65 sent/s -   753.53 words/s - MLM-Anglais:  5.3513 || MLM-Bulu:  5.2588 || MLM-Anglais-Bulu:  5.1545 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:28:35 - 0:18:09 - ============ End of epoch 11 ============\n","INFO - 05/09/20 13:29:28 - 0:19:02 - epoch -> 11.000000\n","INFO - 05/09/20 13:29:28 - 0:19:02 - valid_Anglais_mlm_ppl -> 354.443488\n","INFO - 05/09/20 13:29:28 - 0:19:02 - valid_Anglais_mlm_acc -> 6.923984\n","INFO - 05/09/20 13:29:28 - 0:19:02 - valid_Bulu_mlm_ppl -> 345.494163\n","INFO - 05/09/20 13:29:28 - 0:19:02 - valid_Bulu_mlm_acc -> 7.212678\n","INFO - 05/09/20 13:29:28 - 0:19:02 - valid_Anglais_Bulu_mlm_ppl -> 295.970663\n","INFO - 05/09/20 13:29:28 - 0:19:02 - valid_Anglais_Bulu_mlm_acc -> 10.393029\n","INFO - 05/09/20 13:29:28 - 0:19:02 - valid_mlm_ppl -> 349.968826\n","INFO - 05/09/20 13:29:28 - 0:19:02 - valid_mlm_acc -> 7.068331\n","INFO - 05/09/20 13:29:28 - 0:19:02 - test_Anglais_mlm_ppl -> 346.850815\n","INFO - 05/09/20 13:29:28 - 0:19:02 - test_Anglais_mlm_acc -> 7.311953\n","INFO - 05/09/20 13:29:28 - 0:19:02 - test_Bulu_mlm_ppl -> 354.284928\n","INFO - 05/09/20 13:29:28 - 0:19:02 - test_Bulu_mlm_acc -> 7.601019\n","INFO - 05/09/20 13:29:28 - 0:19:02 - test_Anglais_Bulu_mlm_ppl -> 295.817275\n","INFO - 05/09/20 13:29:28 - 0:19:02 - test_Anglais_Bulu_mlm_acc -> 10.712853\n","INFO - 05/09/20 13:29:28 - 0:19:02 - test_mlm_ppl -> 350.567871\n","INFO - 05/09/20 13:29:28 - 0:19:02 - test_mlm_acc -> 7.456486\n","INFO - 05/09/20 13:29:28 - 0:19:02 - __log__:{\"epoch\": 11, \"valid_Anglais_mlm_ppl\": 354.44348794564365, \"valid_Anglais_mlm_acc\": 6.9239835002946375, \"valid_Bulu_mlm_ppl\": 345.4941634923861, \"valid_Bulu_mlm_acc\": 7.212677725118484, \"valid_Anglais_Bulu_mlm_ppl\": 295.97066286396506, \"valid_Anglais_Bulu_mlm_acc\": 10.39302929180571, \"valid_mlm_ppl\": 349.9688257190149, \"valid_mlm_acc\": 7.068330612706561, \"test_Anglais_mlm_ppl\": 346.85081519464904, \"test_Anglais_mlm_acc\": 7.311952508506479, \"test_Bulu_mlm_ppl\": 354.28492768494897, \"test_Bulu_mlm_acc\": 7.601019293775027, \"test_Anglais_Bulu_mlm_ppl\": 295.8172748507884, \"test_Anglais_Bulu_mlm_acc\": 10.71285323609845, \"test_mlm_ppl\": 350.567871439799, \"test_mlm_acc\": 7.456485901140754}\n","INFO - 05/09/20 13:29:28 - 0:19:02 - Not a better validation score (1 / 10).\n","INFO - 05/09/20 13:29:28 - 0:19:02 - Saving checkpoint to ./dumped/Anglais_Bulu_mlm_tlm/africa/checkpoint.pth ...\n","WARNING - 05/09/20 13:29:28 - 0:19:02 - Saving model parameters ...\n","WARNING - 05/09/20 13:29:28 - 0:19:02 - Saving model optimizer ...\n","INFO - 05/09/20 13:29:32 - 0:19:06 - ============ Starting epoch 12 ... ============\n","INFO - 05/09/20 13:29:41 - 0:19:15 -     365 -    3.63 sent/s -   105.25 words/s - MLM-Anglais:  5.1969 || MLM-Bulu:  5.3779 || MLM-Anglais-Bulu:  5.2642 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:29:51 - 0:19:25 -     370 -   25.49 sent/s -   768.14 words/s - MLM-Anglais:  5.2579 || MLM-Bulu:  5.3275 || MLM-Anglais-Bulu:  5.1932 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:30:00 - 0:19:34 -     375 -   26.11 sent/s -   752.68 words/s - MLM-Anglais:  5.3120 || MLM-Bulu:  5.3674 || MLM-Anglais-Bulu:  5.1638 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:30:09 - 0:19:43 -     380 -   25.62 sent/s -   743.85 words/s - MLM-Anglais:  5.2370 || MLM-Bulu:  5.2559 || MLM-Anglais-Bulu:  5.2313 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:30:18 - 0:19:52 -     385 -   26.91 sent/s -   747.38 words/s - MLM-Anglais:  5.3408 || MLM-Bulu:  5.3186 || MLM-Anglais-Bulu:  5.2703 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:30:27 - 0:20:01 -     390 -   26.31 sent/s -   747.41 words/s - MLM-Anglais:  5.3094 || MLM-Bulu:  5.3301 || MLM-Anglais-Bulu:  5.3173 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:30:27 - 0:20:01 - ============ End of epoch 12 ============\n","INFO - 05/09/20 13:31:20 - 0:20:54 - epoch -> 12.000000\n","INFO - 05/09/20 13:31:20 - 0:20:54 - valid_Anglais_mlm_ppl -> 355.599404\n","INFO - 05/09/20 13:31:20 - 0:20:54 - valid_Anglais_mlm_acc -> 6.386270\n","INFO - 05/09/20 13:31:20 - 0:20:54 - valid_Bulu_mlm_ppl -> 366.681605\n","INFO - 05/09/20 13:31:20 - 0:20:54 - valid_Bulu_mlm_acc -> 7.212678\n","INFO - 05/09/20 13:31:20 - 0:20:54 - valid_Anglais_Bulu_mlm_ppl -> 298.487025\n","INFO - 05/09/20 13:31:20 - 0:20:54 - valid_Anglais_Bulu_mlm_acc -> 10.893585\n","INFO - 05/09/20 13:31:20 - 0:20:54 - valid_mlm_ppl -> 361.140505\n","INFO - 05/09/20 13:31:20 - 0:20:54 - valid_mlm_acc -> 6.799474\n","INFO - 05/09/20 13:31:20 - 0:20:54 - test_Anglais_mlm_ppl -> 347.793867\n","INFO - 05/09/20 13:31:20 - 0:20:54 - test_Anglais_mlm_acc -> 6.341852\n","INFO - 05/09/20 13:31:20 - 0:20:54 - test_Bulu_mlm_ppl -> 375.644204\n","INFO - 05/09/20 13:31:20 - 0:20:54 - test_Bulu_mlm_acc -> 7.608300\n","INFO - 05/09/20 13:31:20 - 0:20:54 - test_Anglais_Bulu_mlm_ppl -> 299.754404\n","INFO - 05/09/20 13:31:20 - 0:20:54 - test_Anglais_Bulu_mlm_acc -> 10.625342\n","INFO - 05/09/20 13:31:20 - 0:20:54 - test_mlm_ppl -> 361.719036\n","INFO - 05/09/20 13:31:20 - 0:20:54 - test_mlm_acc -> 6.975076\n","INFO - 05/09/20 13:31:20 - 0:20:54 - __log__:{\"epoch\": 12, \"valid_Anglais_mlm_ppl\": 355.5994044051119, \"valid_Anglais_mlm_acc\": 6.386269888037714, \"valid_Bulu_mlm_ppl\": 366.6816046880553, \"valid_Bulu_mlm_acc\": 7.212677725118484, \"valid_Anglais_Bulu_mlm_ppl\": 298.48702501710045, \"valid_Anglais_Bulu_mlm_acc\": 10.89358546533185, \"valid_mlm_ppl\": 361.1405045465836, \"valid_mlm_acc\": 6.799473806578099, \"test_Anglais_mlm_ppl\": 347.7938673950184, \"test_Anglais_mlm_acc\": 6.341851878665025, \"test_Bulu_mlm_ppl\": 375.64420380274424, \"test_Bulu_mlm_acc\": 7.608299963596651, \"test_Anglais_Bulu_mlm_ppl\": 299.75440433502376, \"test_Anglais_Bulu_mlm_acc\": 10.625341841385596, \"test_mlm_ppl\": 361.7190355988813, \"test_mlm_acc\": 6.975075921130838}\n","INFO - 05/09/20 13:31:20 - 0:20:54 - Not a better validation score (2 / 10).\n","INFO - 05/09/20 13:31:20 - 0:20:54 - Saving checkpoint to ./dumped/Anglais_Bulu_mlm_tlm/africa/checkpoint.pth ...\n","WARNING - 05/09/20 13:31:20 - 0:20:54 - Saving model parameters ...\n","WARNING - 05/09/20 13:31:20 - 0:20:54 - Saving model optimizer ...\n","INFO - 05/09/20 13:31:24 - 0:20:58 - ============ Starting epoch 13 ... ============\n","INFO - 05/09/20 13:31:33 - 0:21:07 -     395 -    3.63 sent/s -   106.95 words/s - MLM-Anglais:  5.3820 || MLM-Bulu:  5.2702 || MLM-Anglais-Bulu:  5.0935 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:31:42 - 0:21:16 -     400 -   26.48 sent/s -   756.99 words/s - MLM-Anglais:  5.3702 || MLM-Bulu:  5.3007 || MLM-Anglais-Bulu:  5.2281 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:31:50 - 0:21:24 - Creating new training data iterator (pred,Bulu) ...\n","INFO - 05/09/20 13:31:52 - 0:21:26 -     405 -   25.81 sent/s -   738.46 words/s - MLM-Anglais:  5.3699 || MLM-Bulu:  5.3010 || MLM-Anglais-Bulu:  5.0248 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:32:01 - 0:21:35 -     410 -   25.26 sent/s -   737.67 words/s - MLM-Anglais:  5.2676 || MLM-Bulu:  5.0996 || MLM-Anglais-Bulu:  5.1128 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:32:09 - 0:21:43 - Creating new training data iterator (pred,Anglais) ...\n","INFO - 05/09/20 13:32:11 - 0:21:45 -     415 -   25.84 sent/s -   764.97 words/s - MLM-Anglais:  5.3040 || MLM-Bulu:  5.3915 || MLM-Anglais-Bulu:  4.9893 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:32:19 - 0:21:53 -     420 -   27.11 sent/s -   750.04 words/s - MLM-Anglais:  5.2302 || MLM-Bulu:  5.2860 || MLM-Anglais-Bulu:  4.7232 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:32:19 - 0:21:53 - ============ End of epoch 13 ============\n","INFO - 05/09/20 13:33:12 - 0:22:46 - epoch -> 13.000000\n","INFO - 05/09/20 13:33:12 - 0:22:46 - valid_Anglais_mlm_ppl -> 357.980293\n","INFO - 05/09/20 13:33:12 - 0:22:46 - valid_Anglais_mlm_acc -> 6.452563\n","INFO - 05/09/20 13:33:12 - 0:22:46 - valid_Bulu_mlm_ppl -> 340.326992\n","INFO - 05/09/20 13:33:12 - 0:22:46 - valid_Bulu_mlm_acc -> 7.316351\n","INFO - 05/09/20 13:33:12 - 0:22:46 - valid_Anglais_Bulu_mlm_ppl -> 287.963230\n","INFO - 05/09/20 13:33:12 - 0:22:46 - valid_Anglais_Bulu_mlm_acc -> 12.232110\n","INFO - 05/09/20 13:33:12 - 0:22:46 - valid_mlm_ppl -> 349.153642\n","INFO - 05/09/20 13:33:12 - 0:22:46 - valid_mlm_acc -> 6.884457\n","INFO - 05/09/20 13:33:12 - 0:22:46 - test_Anglais_mlm_ppl -> 348.960107\n","INFO - 05/09/20 13:33:12 - 0:22:46 - test_Anglais_mlm_acc -> 6.689351\n","INFO - 05/09/20 13:33:12 - 0:22:46 - test_Bulu_mlm_ppl -> 350.167244\n","INFO - 05/09/20 13:33:12 - 0:22:46 - test_Bulu_mlm_acc -> 7.732071\n","INFO - 05/09/20 13:33:12 - 0:22:46 - test_Anglais_Bulu_mlm_ppl -> 289.820566\n","INFO - 05/09/20 13:33:12 - 0:22:46 - test_Anglais_Bulu_mlm_acc -> 12.091158\n","INFO - 05/09/20 13:33:12 - 0:22:46 - test_mlm_ppl -> 349.563675\n","INFO - 05/09/20 13:33:12 - 0:22:46 - test_mlm_acc -> 7.210711\n","INFO - 05/09/20 13:33:12 - 0:22:46 - __log__:{\"epoch\": 13, \"valid_Anglais_mlm_ppl\": 357.98029272766985, \"valid_Anglais_mlm_acc\": 6.452563347083088, \"valid_Bulu_mlm_ppl\": 340.3269922323764, \"valid_Bulu_mlm_acc\": 7.3163507109004735, \"valid_Anglais_Bulu_mlm_ppl\": 287.96323036620925, \"valid_Anglais_Bulu_mlm_acc\": 12.232109751575825, \"valid_mlm_ppl\": 349.1536424800231, \"valid_mlm_acc\": 6.884457028991781, \"test_Anglais_mlm_ppl\": 348.9601067477214, \"test_Anglais_mlm_acc\": 6.689350611742562, \"test_Bulu_mlm_ppl\": 350.16724371751553, \"test_Bulu_mlm_acc\": 7.732071350564252, \"test_Anglais_Bulu_mlm_ppl\": 289.820565699264, \"test_Anglais_Bulu_mlm_acc\": 12.091157702825889, \"test_mlm_ppl\": 349.5636752326185, \"test_mlm_acc\": 7.210710981153406}\n","INFO - 05/09/20 13:33:12 - 0:22:46 - Not a better validation score (3 / 10).\n","INFO - 05/09/20 13:33:12 - 0:22:46 - Saving checkpoint to ./dumped/Anglais_Bulu_mlm_tlm/africa/checkpoint.pth ...\n","WARNING - 05/09/20 13:33:12 - 0:22:46 - Saving model parameters ...\n","WARNING - 05/09/20 13:33:12 - 0:22:46 - Saving model optimizer ...\n","INFO - 05/09/20 13:33:16 - 0:22:50 - ============ Starting epoch 14 ... ============\n","INFO - 05/09/20 13:33:25 - 0:22:59 -     425 -    3.65 sent/s -   103.82 words/s - MLM-Anglais:  5.3317 || MLM-Bulu:  5.2979 || MLM-Anglais-Bulu:  5.0831 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:33:34 - 0:23:08 -     430 -   26.63 sent/s -   743.78 words/s - MLM-Anglais:  5.3081 || MLM-Bulu:  5.3649 || MLM-Anglais-Bulu:  5.3421 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:33:43 - 0:23:17 -     435 -   26.11 sent/s -   735.51 words/s - MLM-Anglais:  5.3690 || MLM-Bulu:  5.2666 || MLM-Anglais-Bulu:  5.1966 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:33:52 - 0:23:26 -     440 -   26.51 sent/s -   747.72 words/s - MLM-Anglais:  5.3677 || MLM-Bulu:  5.4034 || MLM-Anglais-Bulu:  5.0481 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:34:01 - 0:23:35 -     445 -   26.83 sent/s -   746.68 words/s - MLM-Anglais:  5.3747 || MLM-Bulu:  5.2998 || MLM-Anglais-Bulu:  5.1068 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:34:10 - 0:23:44 -     450 -   26.83 sent/s -   737.07 words/s - MLM-Anglais:  5.2814 || MLM-Bulu:  5.3882 || MLM-Anglais-Bulu:  5.2486 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:34:10 - 0:23:44 - ============ End of epoch 14 ============\n","INFO - 05/09/20 13:35:03 - 0:24:37 - epoch -> 14.000000\n","INFO - 05/09/20 13:35:03 - 0:24:37 - valid_Anglais_mlm_ppl -> 363.088775\n","INFO - 05/09/20 13:35:03 - 0:24:37 - valid_Anglais_mlm_acc -> 6.923984\n","INFO - 05/09/20 13:35:03 - 0:24:37 - valid_Bulu_mlm_ppl -> 345.626782\n","INFO - 05/09/20 13:35:03 - 0:24:37 - valid_Bulu_mlm_acc -> 7.301540\n","INFO - 05/09/20 13:35:03 - 0:24:37 - valid_Anglais_Bulu_mlm_ppl -> 292.899341\n","INFO - 05/09/20 13:35:03 - 0:24:37 - valid_Anglais_Bulu_mlm_acc -> 11.116055\n","INFO - 05/09/20 13:35:03 - 0:24:37 - valid_mlm_ppl -> 354.357779\n","INFO - 05/09/20 13:35:03 - 0:24:37 - valid_mlm_acc -> 7.112762\n","INFO - 05/09/20 13:35:03 - 0:24:37 - test_Anglais_mlm_ppl -> 353.525713\n","INFO - 05/09/20 13:35:03 - 0:24:37 - test_Anglais_mlm_acc -> 6.935496\n","INFO - 05/09/20 13:35:03 - 0:24:37 - test_Bulu_mlm_ppl -> 351.346706\n","INFO - 05/09/20 13:35:03 - 0:24:37 - test_Bulu_mlm_acc -> 7.783036\n","INFO - 05/09/20 13:35:03 - 0:24:37 - test_Anglais_Bulu_mlm_ppl -> 292.679064\n","INFO - 05/09/20 13:35:03 - 0:24:37 - test_Anglais_Bulu_mlm_acc -> 11.387420\n","INFO - 05/09/20 13:35:03 - 0:24:37 - test_mlm_ppl -> 352.436210\n","INFO - 05/09/20 13:35:03 - 0:24:37 - test_mlm_acc -> 7.359266\n","INFO - 05/09/20 13:35:03 - 0:24:37 - __log__:{\"epoch\": 14, \"valid_Anglais_mlm_ppl\": 363.088775387118, \"valid_Anglais_mlm_acc\": 6.9239835002946375, \"valid_Bulu_mlm_ppl\": 345.6267821850011, \"valid_Bulu_mlm_acc\": 7.30154028436019, \"valid_Anglais_Bulu_mlm_ppl\": 292.89934054260885, \"valid_Anglais_Bulu_mlm_acc\": 11.116054875787912, \"valid_mlm_ppl\": 354.35777878605955, \"valid_mlm_acc\": 7.112761892327414, \"test_Anglais_mlm_ppl\": 353.5257134604835, \"test_Anglais_mlm_acc\": 6.935495547672483, \"test_Bulu_mlm_ppl\": 351.3467060183681, \"test_Bulu_mlm_acc\": 7.783036039315617, \"test_Anglais_Bulu_mlm_ppl\": 292.6790644699609, \"test_Anglais_Bulu_mlm_acc\": 11.387420237010028, \"test_mlm_ppl\": 352.43620973942575, \"test_mlm_acc\": 7.35926579349405}\n","INFO - 05/09/20 13:35:03 - 0:24:37 - Not a better validation score (4 / 10).\n","INFO - 05/09/20 13:35:03 - 0:24:37 - Saving checkpoint to ./dumped/Anglais_Bulu_mlm_tlm/africa/checkpoint.pth ...\n","WARNING - 05/09/20 13:35:03 - 0:24:37 - Saving model parameters ...\n","WARNING - 05/09/20 13:35:03 - 0:24:37 - Saving model optimizer ...\n","INFO - 05/09/20 13:35:07 - 0:24:41 - ============ Starting epoch 15 ... ============\n","INFO - 05/09/20 13:35:16 - 0:24:50 -     455 -    3.66 sent/s -   104.03 words/s - MLM-Anglais:  5.2228 || MLM-Bulu:  5.3730 || MLM-Anglais-Bulu:  4.9240 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:35:25 - 0:24:59 -     460 -   26.28 sent/s -   753.99 words/s - MLM-Anglais:  5.4691 || MLM-Bulu:  5.2750 || MLM-Anglais-Bulu:  5.1460 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:35:34 - 0:25:08 -     465 -   25.69 sent/s -   739.27 words/s - MLM-Anglais:  5.2009 || MLM-Bulu:  5.2954 || MLM-Anglais-Bulu:  5.0466 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:35:43 - 0:25:17 -     470 -   26.52 sent/s -   750.71 words/s - MLM-Anglais:  5.2979 || MLM-Bulu:  5.4024 || MLM-Anglais-Bulu:  5.0717 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:35:53 - 0:25:27 -     475 -   26.31 sent/s -   741.63 words/s - MLM-Anglais:  5.3420 || MLM-Bulu:  5.3300 || MLM-Anglais-Bulu:  5.0925 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:36:02 - 0:25:36 -     480 -   26.08 sent/s -   748.39 words/s - MLM-Anglais:  5.3788 || MLM-Bulu:  5.3653 || MLM-Anglais-Bulu:  4.8783 -  - model LR: 1.0000e-04\n","INFO - 05/09/20 13:36:02 - 0:25:36 - ============ End of epoch 15 ============\n","INFO - 05/09/20 13:36:54 - 0:26:28 - epoch -> 15.000000\n","INFO - 05/09/20 13:36:54 - 0:26:28 - valid_Anglais_mlm_ppl -> 356.677169\n","INFO - 05/09/20 13:36:54 - 0:26:28 - valid_Anglais_mlm_acc -> 6.408368\n","INFO - 05/09/20 13:36:54 - 0:26:28 - valid_Bulu_mlm_ppl -> 347.156298\n","INFO - 05/09/20 13:36:54 - 0:26:28 - valid_Bulu_mlm_acc -> 5.272512\n","INFO - 05/09/20 13:36:54 - 0:26:28 - valid_Anglais_Bulu_mlm_ppl -> 282.066036\n","INFO - 05/09/20 13:36:54 - 0:26:28 - valid_Anglais_Bulu_mlm_acc -> 11.386726\n","INFO - 05/09/20 13:36:54 - 0:26:28 - valid_mlm_ppl -> 351.916734\n","INFO - 05/09/20 13:36:54 - 0:26:28 - valid_mlm_acc -> 5.840440\n","INFO - 05/09/20 13:36:54 - 0:26:28 - test_Anglais_mlm_ppl -> 349.603750\n","INFO - 05/09/20 13:36:54 - 0:26:28 - test_Anglais_mlm_acc -> 6.378050\n","INFO - 05/09/20 13:36:54 - 0:26:28 - test_Bulu_mlm_ppl -> 353.747327\n","INFO - 05/09/20 13:36:54 - 0:26:28 - test_Bulu_mlm_acc -> 4.950855\n","INFO - 05/09/20 13:36:54 - 0:26:28 - test_Anglais_Bulu_mlm_ppl -> 283.144295\n","INFO - 05/09/20 13:36:54 - 0:26:28 - test_Anglais_Bulu_mlm_acc -> 11.070191\n","INFO - 05/09/20 13:36:54 - 0:26:28 - test_mlm_ppl -> 351.675538\n","INFO - 05/09/20 13:36:54 - 0:26:28 - test_mlm_acc -> 5.664453\n","INFO - 05/09/20 13:36:54 - 0:26:28 - __log__:{\"epoch\": 15, \"valid_Anglais_mlm_ppl\": 356.6771689525403, \"valid_Anglais_mlm_acc\": 6.408367707719505, \"valid_Bulu_mlm_ppl\": 347.1562984275279, \"valid_Bulu_mlm_acc\": 5.2725118483412325, \"valid_Anglais_Bulu_mlm_ppl\": 282.0660355301539, \"valid_Anglais_Bulu_mlm_acc\": 11.386725991842788, \"valid_mlm_ppl\": 351.9167336900341, \"valid_mlm_acc\": 5.840439778030369, \"test_Anglais_mlm_ppl\": 349.6037497653937, \"test_Anglais_mlm_acc\": 6.378049663360603, \"test_Bulu_mlm_ppl\": 353.74732667853056, \"test_Bulu_mlm_acc\": 4.950855478704041, \"test_Anglais_Bulu_mlm_ppl\": 283.14429532481483, \"test_Anglais_Bulu_mlm_acc\": 11.070191431175934, \"test_mlm_ppl\": 351.67553822196214, \"test_mlm_acc\": 5.664452571032322}\n","INFO - 05/09/20 13:36:54 - 0:26:28 - Not a better validation score (5 / 10).\n","INFO - 05/09/20 13:36:54 - 0:26:28 - Saving checkpoint to ./dumped/Anglais_Bulu_mlm_tlm/africa/checkpoint.pth ...\n","WARNING - 05/09/20 13:36:54 - 0:26:28 - Saving model parameters ...\n","WARNING - 05/09/20 13:36:54 - 0:26:28 - Saving model optimizer ...\n","INFO - 05/09/20 13:36:58 - 0:26:32 - ============ Starting epoch 16 ... ============\n","Traceback (most recent call last):\n","  File \"train.py\", line 347, in <module>\n","    main(params)\n","  File \"train.py\", line 280, in main\n","    trainer.mlm_step(lang1, lang2, params.lambda_mlm)\n","  File \"/content/XLM/src/trainer.py\", line 721, in mlm_step\n","    _, loss = model('predict', tensor=tensor, pred_mask=pred_mask, y=y, get_scores=False)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/XLM/src/model/transformer.py\", line 331, in forward\n","    return self.predict(**kwargs)\n","  File \"/content/XLM/src/model/transformer.py\", line 441, in predict\n","    masked_tensor = tensor[pred_mask.unsqueeze(-1).expand_as(tensor)].view(-1, self.dim)\n","KeyboardInterrupt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RZGXIDYXFq_x","colab_type":"code","colab":{}},"source":["#! rm -R dumped/Anglais_Bulu_mlm_tlm"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ivLX0Flc78G_","colab_type":"text"},"source":["**Train on unsupervised MT from a pretrained model**"]},{"cell_type":"code","metadata":{"id":"g-gsqYNL79Mv","colab_type":"code","outputId":"d0bbee14-2b60-4c09-de89-f2b544d29e6a","executionInfo":{"status":"ok","timestamp":1589024247146,"user_tz":-120,"elapsed":3937,"user":{"displayName":"Pascal Notsawo","photoUrl":"","userId":"05128058352342027621"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#%env batch_size=...\n","#%env epoch_size=...\n","\n","%env eval_bleu=true\n","# comme eval_bleu=true\n","%cd /content/XLM\n","! chmod +x src/evaluation/multi-bleu.perl"],"execution_count":0,"outputs":[{"output_type":"stream","text":["env: eval_bleu=true\n","/content/XLM\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2meqmwqW8CJK","colab_type":"code","outputId":"849042bc-520d-4769-d52f-562debfaaf2f","executionInfo":{"status":"ok","timestamp":1589024257135,"user_tz":-120,"elapsed":1727,"user":{"displayName":"Pascal Notsawo","photoUrl":"","userId":"05128058352342027621"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["#%env stopping_criterion=valid_de-fr_mt_bleu,10\n","%env stopping_criterion=valid_Anglais-Bulu_mt_bleu,5\n","%env validation_metrics=valid_Anglais-Bulu_mt_bleu\n","%env reload_model=dumped/Anglais_Bulu_mlm_tlm/africa/best-valid_mlm_ppl.pth,dumped/Anglais_Bulu_mlm_tlm/africa/best-valid_mlm_ppl.pth\n","%env ae_steps=Anglais,Bulu\n","%env bt_steps=Anglais-Bulu-Anglais,Bulu-Anglais-Bulu"],"execution_count":0,"outputs":[{"output_type":"stream","text":["env: stopping_criterion=valid_Anglais-Bulu_mt_bleu,5\n","env: validation_metrics=valid_Anglais-Bulu_mt_bleu\n","env: reload_model=dumped/Anglais_Bulu_mlm_tlm/africa/best-valid_mlm_ppl.pth,dumped/Anglais_Bulu_mlm_tlm/africa/best-valid_mlm_ppl.pth\n","env: ae_steps=Anglais,Bulu\n","env: bt_steps=Anglais-Bulu-Anglais,Bulu-Anglais-Bulu\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gwBJdVPz8_HZ","colab_type":"code","outputId":"4fbd9b5c-9f80-4275-bb01-1f0ff7f835b7","executionInfo":{"status":"ok","timestamp":1589024844153,"user_tz":-120,"elapsed":23272,"user":{"displayName":"Pascal Notsawo","photoUrl":"","userId":"05128058352342027621"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%env max_epoch=2\n","%env batch_size=16\n","%env epoch_size=22000\n","! python train.py --exp_name unsupMT_Anglais_Bulu --dump_path ./dumped/ --reload_model $reload_model --data_path $OUTPATH/Anglais-Bulu --lgs $lgs --ae_steps $ae_steps --bt_steps $bt_steps --word_shuffle 3 --word_dropout 0.1 --word_blank 0.1 --lambda_ae '0:1,100000:0.1,300000:0' --encoder_only false --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout 0.1 --attention_dropout 0.1 --gelu_activation true --tokens_per_batch 2000 --batch_size $batch_size --bptt 256 --optimizer adam_inverse_sqrt,beta1=0.9,beta2=0.98,lr=0.0001 --epoch_size $epoch_size --max_epoch $max_epoch --eval_bleu $eval_bleu --stopping_criterion $stopping_criterion --validation_metrics $validation_metrics --exp_id $exp_id        \n","#%env mt_steps=Anglais-Bulu,Bulu-Anglais           \n","#! python train.py --exp_name unsupMT_Anglais_Bulu --dump_path ./dumped/ --reload_model $reload_model --data_path $OUTPATH/Anglais-Bulu --lgs $lgs --ae_steps $ae_steps --mt_steps $mt_steps --bt_steps $bt_steps --word_shuffle 3 --word_dropout 0.1 --word_blank 0.1 --lambda_ae '0:1,100000:0.1,300000:0' --encoder_only false --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout 0.1 --attention_dropout 0.1 --gelu_activation true --tokens_per_batch 2000 --batch_size $batch_size --bptt 256 --optimizer adam_inverse_sqrt,beta1=0.9,beta2=0.98,lr=0.0001 --epoch_size $epoch_size --max_epoch $max_epoch --eval_bleu $eval_bleu --stopping_criterion $stopping_criterion --validation_metrics $validation_metrics --exp_id $exp_id        "],"execution_count":0,"outputs":[{"output_type":"stream","text":["env: max_epoch=2\n","env: batch_size=16\n","env: epoch_size=22000\n","FAISS library was not found.\n","FAISS not available. Switching to standard nearest neighbors search implementation.\n","SLURM job: False\n","0 - Number of nodes: 1\n","0 - Node ID        : 0\n","0 - Local rank     : 0\n","0 - Global rank    : 0\n","0 - World size     : 1\n","0 - GPUs per node  : 1\n","0 - Master         : True\n","0 - Multi-node     : False\n","0 - Multi-GPU      : False\n","0 - Hostname       : 09297f1b806a\n","INFO - 05/09/20 13:47:06 - 0:00:00 - ============ Initialized logger ============\n","INFO - 05/09/20 13:47:06 - 0:00:00 - accumulate_gradients: 1\n","                                     ae_steps: ['Anglais', 'Bulu']\n","                                     amp: -1\n","                                     asm: False\n","                                     attention_dropout: 0.1\n","                                     batch_size: 16\n","                                     beam_size: 1\n","                                     bptt: 256\n","                                     bt_src_langs: ['Anglais', 'Bulu']\n","                                     bt_steps: [('Anglais', 'Bulu', 'Anglais'), ('Bulu', 'Anglais', 'Bulu')]\n","                                     clip_grad_norm: 5\n","                                     clm_steps: []\n","                                     command: python train.py --exp_name unsupMT_Anglais_Bulu --dump_path './dumped/' --reload_model 'dumped/Anglais_Bulu_mlm_tlm/africa/best-valid_mlm_ppl.pth,dumped/Anglais_Bulu_mlm_tlm/africa/best-valid_mlm_ppl.pth' --data_path 'data/africa/processed/30000/Anglais-Bulu' --lgs 'Anglais-Bulu' --ae_steps 'Anglais,Bulu' --bt_steps 'Anglais-Bulu-Anglais,Bulu-Anglais-Bulu' --word_shuffle 3 --word_dropout '0.1' --word_blank '0.1' --lambda_ae '0:1,100000:0.1,300000:0' --encoder_only false --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --tokens_per_batch 2000 --batch_size 16 --bptt 256 --optimizer 'adam_inverse_sqrt,beta1=0.9,beta2=0.98,lr=0.0001' --epoch_size 22000 --max_epoch 2 --eval_bleu true --stopping_criterion 'valid_Anglais-Bulu_mt_bleu,5' --validation_metrics 'valid_Anglais-Bulu_mt_bleu' --exp_id africa --exp_id \"africa\"\n","                                     context_size: 0\n","                                     data_path: data/africa/processed/30000/Anglais-Bulu\n","                                     debug: False\n","                                     debug_slurm: False\n","                                     debug_train: False\n","                                     dropout: 0.1\n","                                     dump_path: ./dumped/unsupMT_Anglais_Bulu/africa\n","                                     early_stopping: False\n","                                     emb_dim: 1024\n","                                     encoder_only: False\n","                                     epoch_size: 22000\n","                                     eval_bleu: True\n","                                     eval_only: False\n","                                     exp_id: africa\n","                                     exp_name: unsupMT_Anglais_Bulu\n","                                     fp16: False\n","                                     gelu_activation: True\n","                                     global_rank: 0\n","                                     group_by_size: True\n","                                     id2lang: {0: 'Anglais', 1: 'Bulu'}\n","                                     is_master: True\n","                                     is_slurm_job: False\n","                                     lambda_ae: 0:1,100000:0.1,300000:0\n","                                     lambda_bt: 1\n","                                     lambda_clm: 1\n","                                     lambda_mlm: 1\n","                                     lambda_mt: 1\n","                                     lambda_pc: 1\n","                                     lang2id: {'Anglais': 0, 'Bulu': 1}\n","                                     langs: ['Anglais', 'Bulu']\n","                                     length_penalty: 1\n","                                     lg_sampling_factor: -1\n","                                     lgs: Anglais-Bulu\n","                                     local_rank: 0\n","                                     master_port: -1\n","                                     max_batch_size: 0\n","                                     max_epoch: 2\n","                                     max_len: 100\n","                                     max_vocab: -1\n","                                     min_count: 0\n","                                     mlm_steps: []\n","                                     mono_dataset: {'Anglais': {'train': 'data/africa/processed/30000/Anglais-Bulu/train.Anglais.pth', 'valid': 'data/africa/processed/30000/Anglais-Bulu/valid.Anglais.pth', 'test': 'data/africa/processed/30000/Anglais-Bulu/test.Anglais.pth'}, 'Bulu': {'train': 'data/africa/processed/30000/Anglais-Bulu/train.Bulu.pth', 'valid': 'data/africa/processed/30000/Anglais-Bulu/valid.Bulu.pth', 'test': 'data/africa/processed/30000/Anglais-Bulu/test.Bulu.pth'}}\n","                                     mt_steps: []\n","                                     multi_gpu: False\n","                                     multi_node: False\n","                                     n_gpu_per_node: 1\n","                                     n_heads: 8\n","                                     n_langs: 2\n","                                     n_layers: 6\n","                                     n_nodes: 1\n","                                     n_samples: {'train': 0, 'valid': 0, 'test': 0}\n","                                     node_id: 0\n","                                     optimizer: adam_inverse_sqrt,beta1=0.9,beta2=0.98,lr=0.0001\n","                                     para_dataset: {('Anglais', 'Bulu'): {'valid': ('data/africa/processed/30000/Anglais-Bulu/valid.Anglais-Bulu.Anglais.pth', 'data/africa/processed/30000/Anglais-Bulu/valid.Anglais-Bulu.Bulu.pth'), 'test': ('data/africa/processed/30000/Anglais-Bulu/test.Anglais-Bulu.Anglais.pth', 'data/africa/processed/30000/Anglais-Bulu/test.Anglais-Bulu.Bulu.pth')}}\n","                                     pc_steps: []\n","                                     reload_checkpoint: \n","                                     reload_emb: \n","                                     reload_model: dumped/Anglais_Bulu_mlm_tlm/africa/best-valid_mlm_ppl.pth,dumped/Anglais_Bulu_mlm_tlm/africa/best-valid_mlm_ppl.pth\n","                                     remove_long_sentences: {'train': True, 'valid': False, 'test': False}\n","                                     remove_long_sentences_test: False\n","                                     remove_long_sentences_train: True\n","                                     remove_long_sentences_valid: False\n","                                     sample_alpha: 0\n","                                     save_periodic: 0\n","                                     share_inout_emb: True\n","                                     sinusoidal_embeddings: False\n","                                     split_data: False\n","                                     stopping_criterion: valid_Anglais-Bulu_mt_bleu,5\n","                                     test_n_samples: 0\n","                                     tokens_per_batch: 2000\n","                                     train_n_samples: 0\n","                                     use_lang_emb: True\n","                                     use_memory: False\n","                                     valid_n_samples: 0\n","                                     validation_metrics: valid_Anglais-Bulu_mt_bleu\n","                                     word_blank: 0.1\n","                                     word_dropout: 0.1\n","                                     word_keep: 0.1\n","                                     word_mask: 0.8\n","                                     word_mask_keep_rand: 0.8,0.1,0.1\n","                                     word_pred: 0.15\n","                                     word_rand: 0.1\n","                                     word_shuffle: 3.0\n","                                     world_size: 1\n","INFO - 05/09/20 13:47:06 - 0:00:00 - The experiment will be stored in ./dumped/unsupMT_Anglais_Bulu/africa\n","                                     \n","INFO - 05/09/20 13:47:06 - 0:00:00 - Running command: python train.py --exp_name unsupMT_Anglais_Bulu --dump_path './dumped/' --reload_model 'dumped/Anglais_Bulu_mlm_tlm/africa/best-valid_mlm_ppl.pth,dumped/Anglais_Bulu_mlm_tlm/africa/best-valid_mlm_ppl.pth' --data_path 'data/africa/processed/30000/Anglais-Bulu' --lgs 'Anglais-Bulu' --ae_steps 'Anglais,Bulu' --bt_steps 'Anglais-Bulu-Anglais,Bulu-Anglais-Bulu' --word_shuffle 3 --word_dropout '0.1' --word_blank '0.1' --lambda_ae '0:1,100000:0.1,300000:0' --encoder_only false --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --tokens_per_batch 2000 --batch_size 16 --bptt 256 --optimizer 'adam_inverse_sqrt,beta1=0.9,beta2=0.98,lr=0.0001' --epoch_size 22000 --max_epoch 2 --eval_bleu true --stopping_criterion 'valid_Anglais-Bulu_mt_bleu,5' --validation_metrics 'valid_Anglais-Bulu_mt_bleu' --exp_id africa\n","\n","WARNING - 05/09/20 13:47:06 - 0:00:00 - Signal handler installed.\n","INFO - 05/09/20 13:47:06 - 0:00:00 - ============ Monolingual data (Anglais)\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Loading data from data/africa/processed/30000/Anglais-Bulu/train.Anglais.pth ...\n","INFO - 05/09/20 13:47:06 - 0:00:00 - 691905 words (22320 unique) in 22854 sentences. 61 unknown words (61 unique) covering 0.01% of the data.\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Removed 0 empty sentences.\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Removed 1 too long sentences.\n","\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Loading data from data/africa/processed/30000/Anglais-Bulu/valid.Anglais.pth ...\n","INFO - 05/09/20 13:47:06 - 0:00:00 - 86874 words (22320 unique) in 2856 sentences. 744 unknown words (547 unique) covering 0.86% of the data.\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Removed 0 empty sentences.\n","\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Loading data from data/africa/processed/30000/Anglais-Bulu/test.Anglais.pth ...\n","INFO - 05/09/20 13:47:06 - 0:00:00 - 88338 words (22320 unique) in 2856 sentences. 594 unknown words (451 unique) covering 0.67% of the data.\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Removed 0 empty sentences.\n","\n","INFO - 05/09/20 13:47:06 - 0:00:00 - ============ Monolingual data (Bulu)\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Loading data from data/africa/processed/30000/Anglais-Bulu/train.Bulu.pth ...\n","INFO - 05/09/20 13:47:06 - 0:00:00 - 689397 words (22320 unique) in 22854 sentences. 55 unknown words (53 unique) covering 0.01% of the data.\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Removed 0 empty sentences.\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Removed 3 too long sentences.\n","\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Loading data from data/africa/processed/30000/Anglais-Bulu/valid.Bulu.pth ...\n","INFO - 05/09/20 13:47:06 - 0:00:00 - 86292 words (22320 unique) in 2856 sentences. 487 unknown words (365 unique) covering 0.56% of the data.\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Removed 0 empty sentences.\n","\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Loading data from data/africa/processed/30000/Anglais-Bulu/test.Bulu.pth ...\n","INFO - 05/09/20 13:47:06 - 0:00:00 - 87841 words (22320 unique) in 2856 sentences. 465 unknown words (353 unique) covering 0.53% of the data.\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Removed 0 empty sentences.\n","\n","\n","INFO - 05/09/20 13:47:06 - 0:00:00 - ============ Parallel data (Anglais-Bulu)\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Loading data from data/africa/processed/30000/Anglais-Bulu/valid.Anglais-Bulu.Anglais.pth ...\n","INFO - 05/09/20 13:47:06 - 0:00:00 - 86874 words (22320 unique) in 2856 sentences. 744 unknown words (547 unique) covering 0.86% of the data.\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Loading data from data/africa/processed/30000/Anglais-Bulu/valid.Anglais-Bulu.Bulu.pth ...\n","INFO - 05/09/20 13:47:06 - 0:00:00 - 86292 words (22320 unique) in 2856 sentences. 487 unknown words (365 unique) covering 0.56% of the data.\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Removed 0 empty sentences.\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Removed 0 empty sentences.\n","\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Loading data from data/africa/processed/30000/Anglais-Bulu/test.Anglais-Bulu.Anglais.pth ...\n","INFO - 05/09/20 13:47:06 - 0:00:00 - 88338 words (22320 unique) in 2856 sentences. 594 unknown words (451 unique) covering 0.67% of the data.\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Loading data from data/africa/processed/30000/Anglais-Bulu/test.Anglais-Bulu.Bulu.pth ...\n","INFO - 05/09/20 13:47:06 - 0:00:00 - 87841 words (22320 unique) in 2856 sentences. 465 unknown words (353 unique) covering 0.53% of the data.\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Removed 0 empty sentences.\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Removed 0 empty sentences.\n","\n","\n","INFO - 05/09/20 13:47:06 - 0:00:00 - ============ Data summary\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Monolingual data   - train -      Anglais:     22854\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Monolingual data   - valid -      Anglais:      2856\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Monolingual data   -  test -      Anglais:      2856\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Monolingual data   - train -         Bulu:     22854\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Monolingual data   - valid -         Bulu:      2856\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Monolingual data   -  test -         Bulu:      2856\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Parallel data      - valid - Anglais-Bulu:      2856\n","INFO - 05/09/20 13:47:06 - 0:00:00 - Parallel data      -  test - Anglais-Bulu:      2856\n","\n","INFO - 05/09/20 13:47:09 - 0:00:03 - Reloading encoder from dumped/Anglais_Bulu_mlm_tlm/africa/best-valid_mlm_ppl.pth ...\n","INFO - 05/09/20 13:47:12 - 0:00:06 - Reloading decoder from dumped/Anglais_Bulu_mlm_tlm/africa/best-valid_mlm_ppl.pth ...\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter layer_norm15.0.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter layer_norm15.0.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.0.q_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.0.q_lin.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.0.k_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.0.k_lin.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.0.v_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.0.v_lin.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.0.out_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.0.out_lin.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter layer_norm15.1.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter layer_norm15.1.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.1.q_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.1.q_lin.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.1.k_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.1.k_lin.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.1.v_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.1.v_lin.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.1.out_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.1.out_lin.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter layer_norm15.2.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter layer_norm15.2.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.2.q_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.2.q_lin.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.2.k_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.2.k_lin.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.2.v_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.2.v_lin.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.2.out_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.2.out_lin.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter layer_norm15.3.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter layer_norm15.3.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.3.q_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.3.q_lin.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.3.k_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.3.k_lin.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.3.v_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.3.v_lin.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.3.out_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.3.out_lin.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter layer_norm15.4.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter layer_norm15.4.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.4.q_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.4.q_lin.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.4.k_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.4.k_lin.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.4.v_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.4.v_lin.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.4.out_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.4.out_lin.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter layer_norm15.5.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter layer_norm15.5.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.5.q_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.5.q_lin.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.5.k_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.5.k_lin.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.5.v_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.5.v_lin.bias not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.5.out_lin.weight not found.\n","WARNING - 05/09/20 13:47:12 - 0:00:07 - Parameter encoder_attn.5.out_lin.bias not found.\n","INFO - 05/09/20 13:47:12 - 0:00:07 - Number of parameters (encoder): 98983728\n","INFO - 05/09/20 13:47:12 - 0:00:07 - Number of parameters (decoder): 124186416\n","INFO - 05/09/20 13:47:13 - 0:00:07 - Found 0 memories.\n","INFO - 05/09/20 13:47:13 - 0:00:07 - Found 12 FFN.\n","INFO - 05/09/20 13:47:13 - 0:00:07 - Found 264 parameters in model.\n","INFO - 05/09/20 13:47:13 - 0:00:07 - Optimizers: model\n","INFO - 05/09/20 13:47:14 - 0:00:08 - ============ Starting epoch 0 ... ============\n","INFO - 05/09/20 13:47:14 - 0:00:08 - Creating new training data iterator (ae,Bulu) ...\n","/pytorch/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n","/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha)\n","INFO - 05/09/20 13:47:15 - 0:00:09 - Creating new training data iterator (ae,Anglais) ...\n","INFO - 05/09/20 13:47:16 - 0:00:10 - Creating new training data iterator (bt,Bulu) ...\n","INFO - 05/09/20 13:47:17 - 0:00:11 - Creating new training data iterator (bt,Anglais) ...\n","Traceback (most recent call last):\n","  File \"train.py\", line 347, in <module>\n","    main(params)\n","  File \"train.py\", line 288, in main\n","    trainer.mt_step(lang, lang, params.lambda_ae)\n","  File \"/content/XLM/src/trainer.py\", line 864, in mt_step\n","    self.optimize(loss)\n","  File \"/content/XLM/src/trainer.py\", line 213, in optimize\n","    loss.backward()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/tensor.py\", line 198, in backward\n","    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\", line 100, in backward\n","    allow_unreachable=True)  # allow_unreachable flag\n","RuntimeError: CUDA out of memory. Tried to allocate 160.00 MiB (GPU 0; 7.43 GiB total capacity; 6.45 GiB already allocated; 54.94 MiB free; 6.86 GiB reserved in total by PyTorch) (malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:289)\n","frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f71aa3bd536 in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10.so)\n","frame #1: <unknown function> + 0x1cf1e (0x7f71aa606f1e in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10_cuda.so)\n","frame #2: <unknown function> + 0x1df9e (0x7f71aa607f9e in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10_cuda.so)\n","frame #3: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x135 (0x7f71ad1b3fd5 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\n","frame #4: <unknown function> + 0xf9310b (0x7f71ab7ac10b in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\n","frame #5: <unknown function> + 0xfdc9f7 (0x7f71ab7f59f7 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\n","frame #6: <unknown function> + 0x1075389 (0x7f71e3140389 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\n","frame #7: <unknown function> + 0x10756c7 (0x7f71e31406c7 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\n","frame #8: <unknown function> + 0xe2165e (0x7f71e2eec65e in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\n","frame #9: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x9e0 (0x7f71e2ef2f50 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\n","frame #10: <unknown function> + 0x1134321 (0x7f71e31ff321 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\n","frame #11: <unknown function> + 0x1187623 (0x7f71e3252623 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\n","frame #12: <unknown function> + 0x28c7d12 (0x7f71ad0e0d12 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\n","frame #13: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xb9 (0x7f71ad0f5729 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\n","frame #14: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x99 (0x7f71ad0e14a9 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\n","frame #15: <unknown function> + 0xf9dd90 (0x7f71ab7b6d90 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\n","frame #16: <unknown function> + 0x10c5ad6 (0x7f71e3190ad6 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\n","frame #17: <unknown function> + 0x2ca99fc (0x7f71e4d749fc in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\n","frame #18: <unknown function> + 0x10c5ad6 (0x7f71e3190ad6 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\n","frame #19: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1c9 (0x7f71e4970869 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\n","frame #20: <unknown function> + 0x2d89c05 (0x7f71e4e54c05 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\n","frame #21: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7f71e4e51f03 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\n","frame #22: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f71e4e52ce2 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\n","frame #23: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f71e4e4b359 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\n","frame #24: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f71f158a378 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_python.so)\n","frame #25: <unknown function> + 0xbd6df (0x7f71f468c6df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n","frame #26: <unknown function> + 0x76db (0x7f71f576e6db in /lib/x86_64-linux-gnu/libpthread.so.0)\n","frame #27: clone + 0x3f (0x7f71f5aa788f in /lib/x86_64-linux-gnu/libc.so.6)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OxU5J1LEFTaB","colab_type":"code","colab":{}},"source":["#! rm -R dumped/unsupMT_Anglais_Bulu"],"execution_count":0,"outputs":[]}]}