{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CbnXTTGkf90V"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1313,
     "status": "ok",
     "timestamp": 1589794253526,
     "user": {
      "displayName": "Pascal Tikeng",
      "photoUrl": "",
      "userId": "15074930698580545771"
     },
     "user_tz": -120
    },
    "id": "Vv2NskRCqrpH",
    "outputId": "405a5930-01b1-4c71-b8c9-40c3eace9e79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(bookmark:HOME) -> /home/jupyter/meta_XLM/XLM\n",
      "/home/jupyter/meta_XLM/XLM\n"
     ]
    }
   ],
   "source": [
    "%bookmark HOME \"/home/jupyter/meta_XLM/XLM\" \n",
    "%cd -b HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6584,
     "status": "ok",
     "timestamp": 1589794300789,
     "user": {
      "displayName": "Pascal Tikeng",
      "photoUrl": "",
      "userId": "15074930698580545771"
     },
     "user_tz": -120
    },
    "id": "qnaDtJ76f8zt",
    "outputId": "e3026f4d-ef37-4808-80d3-d92916228114"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: csv_path=/home/jupyter/csvs\n",
      "env: output_dir=/home/jupyter/data\n",
      "env: data_type=para\n",
      "env: languages=Limbum,Ngiemboon\n",
      "Limbum - Ngiemboon\n",
      "======= Read 7950 totals samples\n",
      "======= Delete 50 samples\n",
      "======= Save 7900 samples\n"
     ]
    }
   ],
   "source": [
    "%env csv_path=/home/jupyter\n",
    "%env output_dir=/home/jupyter/data\n",
    "%env data_type=para\n",
    "%env languages=Limbum,Ngiemboon\n",
    "! python ../bible.py --csv_path $csv_path --output_dir $output_dir --data_type $data_type --languages $languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10391,
     "status": "ok",
     "timestamp": 1589794429482,
     "user": {
      "displayName": "Pascal Tikeng",
      "photoUrl": "",
      "userId": "15074930698580545771"
     },
     "user_tz": -120
    },
    "id": "M0IN3i6npWRn",
    "outputId": "48dd5e9a-6697-4904-b327-f4e470c78dc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PARA=True\n",
      "env: MONO=True\n",
      "env: PARA_PATH=/home/jupyter/data/para/Limbum-Ngiemboon\n",
      "env: MONO_PATH=\"\"\n",
      "env: SAME_VOCAB=True\n",
      "env: nCodes=10000\n",
      "env: shuf_n_samples=1000000\n",
      "env: threads_for_tokenizer=16\n",
      "env: test_size=10\n",
      "env: val_size=10\n",
      "env: TOKENIZE=tools/tokenizer_our.sh\n",
      "env: LOWER_REMOVE_ACCENT=tools/lowercase_and_remove_accent.py\n",
      "env: FASTBPE=tools/fastBPE/fast\n",
      "env: OUTPATH=/home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed\n",
      "env: n_samples=-1\n",
      "env: sub_task=Limbum-Ngiemboon:-1\n"
     ]
    }
   ],
   "source": [
    "%env PARA=True          \n",
    "%env MONO=True       \n",
    "                   \n",
    "%env PARA_PATH=/home/jupyter/data/para/Limbum-Ngiemboon     \n",
    "%env MONO_PATH=\"\"  \n",
    "%env SAME_VOCAB=True    \n",
    "%env nCodes=10000             \n",
    "%env shuf_n_samples=1000000   \n",
    "%env threads_for_tokenizer=16 \n",
    "%env test_size=10             \n",
    "%env val_size=10              \n",
    "\n",
    "# tools paths\n",
    "%env TOKENIZE=tools/tokenizer_our.sh\n",
    "%env LOWER_REMOVE_ACCENT=tools/lowercase_and_remove_accent.py\n",
    "%env FASTBPE=tools/fastBPE/fast\n",
    "\n",
    "\n",
    "%env OUTPATH=/home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed\n",
    "# create output path\n",
    "! mkdir -p $OUTPATH\n",
    "\n",
    "! chmod +x $FASTBPE\n",
    "! chmod +x ../build_meta_data.sh\n",
    "! chmod +x tools/mosesdecoder/scripts/tokenizer/*.perl\n",
    "\n",
    "%env n_samples=-1\n",
    "\n",
    "%env sub_task=Limbum-Ngiemboon:-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 88374,
     "status": "ok",
     "timestamp": 1589794557337,
     "user": {
      "displayName": "Pascal Tikeng",
      "photoUrl": "",
      "userId": "15074930698580545771"
     },
     "user_tz": -120
    },
    "id": "1iLoHBXQvwna",
    "outputId": "bf45512c-8058-42c8-9f2e-ccd6ec38d11e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: nCodes=7000\n",
      "env: add_para_data_to_mono_data=False\n",
      "params ok !\n",
      "*** Cleaning and tokenizing Limbum-Ngiemboon data ... ***\n",
      "Tokenizer Version 1.1\n",
      "Language: Limbum\n",
      "Number of threads: 8\n",
      "WARNING: No known abbreviations for language 'Limbum', attempting fall-back to English version...\n",
      "*** Tokenized (+ lowercase + accent-removal) Limbum-Ngiemboon.Limbum data to /home/jupyter/data/para/Limbum-Ngiemboon/? ***\n",
      "Tokenizer Version 1.1\n",
      "Language: Ngiemboon\n",
      "Number of threads: 8\n",
      "WARNING: No known abbreviations for language 'Ngiemboon', attempting fall-back to English version...\n",
      "*** Tokenized (+ lowercase + accent-removal) Limbum-Ngiemboon.Ngiemboon data to /home/jupyter/data/para/Limbum-Ngiemboon/? ***\n",
      "\n",
      "\n",
      "*** split into train / valid / test ***\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "\n",
      "\n",
      "\n",
      "***build the training set for BPE tokenization (7000 codes)***\n",
      "\n",
      "\n",
      "***shuf ... Generating 1000000 random permutations of training data and store result in /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/Limbum-Ngiemboon/bpe.train***\n",
      "\n",
      "\n",
      "***Learn the BPE vocabulary on the training set : /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/bpe.train ...***\n",
      "Loading vocabulary from /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/bpe.train ...\n",
      "Read 72839588 words (13972 unique) from text file.\n",
      "***Learn 7000 BPE code on the bpe.train file***\n",
      "\n",
      "\n",
      "***Get the post-BPE vocab***\n",
      "Loading codes from /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/codes ...\n",
      "Read 7000 codes from the codes file.\n",
      "Loading vocabulary from /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/bpe.train ...\n",
      "Read 72839588 words (13972 unique) from text file.\n",
      "Applying BPE to /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/bpe.train ...\n",
      "Modified 72839588 words from text file.\n",
      "Read 75885693 words (6653 unique) from text file.\n",
      "\n",
      "\n",
      "***Apply BPE tokenization on the corpora.***\n",
      "Loading codes from /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/codes ...\n",
      "Read 7000 codes from the codes file.\n",
      "Loading vocabulary from /home/jupyter/data/para/Limbum-Ngiemboon/Limbum-Ngiemboon.Limbum.train ...\n",
      "Read 256164 words (2715 unique) from text file.\n",
      "Applying BPE to /home/jupyter/data/para/Limbum-Ngiemboon/Limbum-Ngiemboon.Limbum.train ...\n",
      "Modified 256164 words from text file.\n",
      "Loading codes from /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/codes ...\n",
      "Read 7000 codes from the codes file.\n",
      "Loading vocabulary from /home/jupyter/data/para/Limbum-Ngiemboon/Limbum-Ngiemboon.Limbum.valid ...\n",
      "Read 32662 words (1326 unique) from text file.\n",
      "Applying BPE to /home/jupyter/data/para/Limbum-Ngiemboon/Limbum-Ngiemboon.Limbum.valid ...\n",
      "Modified 32662 words from text file.\n",
      "Loading codes from /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/codes ...\n",
      "Read 7000 codes from the codes file.\n",
      "Loading vocabulary from /home/jupyter/data/para/Limbum-Ngiemboon/Limbum-Ngiemboon.Limbum.test ...\n",
      "Read 31883 words (1274 unique) from text file.\n",
      "Applying BPE to /home/jupyter/data/para/Limbum-Ngiemboon/Limbum-Ngiemboon.Limbum.test ...\n",
      "Modified 31883 words from text file.\n",
      "Loading codes from /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/codes ...\n",
      "Read 7000 codes from the codes file.\n",
      "Loading vocabulary from /home/jupyter/data/para/Limbum-Ngiemboon/Limbum-Ngiemboon.Ngiemboon.train ...\n",
      "Read 204169 words (11311 unique) from text file.\n",
      "Applying BPE to /home/jupyter/data/para/Limbum-Ngiemboon/Limbum-Ngiemboon.Ngiemboon.train ...\n",
      "Modified 204169 words from text file.\n",
      "Loading codes from /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/codes ...\n",
      "Read 7000 codes from the codes file.\n",
      "Loading vocabulary from /home/jupyter/data/para/Limbum-Ngiemboon/Limbum-Ngiemboon.Ngiemboon.valid ...\n",
      "Read 25917 words (3519 unique) from text file.\n",
      "Applying BPE to /home/jupyter/data/para/Limbum-Ngiemboon/Limbum-Ngiemboon.Ngiemboon.valid ...\n",
      "Modified 25917 words from text file.\n",
      "Loading codes from /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/codes ...\n",
      "Read 7000 codes from the codes file.\n",
      "Loading vocabulary from /home/jupyter/data/para/Limbum-Ngiemboon/Limbum-Ngiemboon.Ngiemboon.test ...\n",
      "Read 25579 words (3471 unique) from text file.\n",
      "Applying BPE to /home/jupyter/data/para/Limbum-Ngiemboon/Limbum-Ngiemboon.Ngiemboon.test ...\n",
      "Modified 25579 words from text file.\n",
      "\n",
      "\n",
      "***Build fine_tune data***\n",
      "\n",
      "\n",
      "***Binarize everything using preprocess.py.***\n",
      "INFO - 05/20/20 09:50:12 - 0:00:00 - Read 6667 words from the vocabulary file.\n",
      "\n",
      "Saving the data to /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/Limbum-Ngiemboon.Limbum.train.pth ...\n",
      "INFO - 05/20/20 09:50:12 - 0:00:00 - 259414 words (6667 unique) in 6321 sentences.\n",
      "INFO - 05/20/20 09:50:13 - 0:00:00 - Read 6667 words from the vocabulary file.\n",
      "\n",
      "Saving the data to /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/Limbum-Ngiemboon.Limbum.valid.pth ...\n",
      "INFO - 05/20/20 09:50:13 - 0:00:00 - 33215 words (6667 unique) in 790 sentences.\n",
      "INFO - 05/20/20 09:50:13 - 0:00:00 - 13 unknown words (10 unique), covering 0.04% of the data.\n",
      "INFO - 05/20/20 09:50:13 - 0:00:00 - uem: 2\n",
      "INFO - 05/20/20 09:50:13 - 0:00:00 - pni: 2\n",
      "INFO - 05/20/20 09:50:13 - 0:00:00 - fas@@: 2\n",
      "INFO - 05/20/20 09:50:13 - 0:00:00 - fuu@@: 1\n",
      "INFO - 05/20/20 09:50:13 - 0:00:00 - jaea@@: 1\n",
      "INFO - 05/20/20 09:50:13 - 0:00:00 - uela@@: 1\n",
      "INFO - 05/20/20 09:50:13 - 0:00:00 - ncoep-baa@@: 1\n",
      "INFO - 05/20/20 09:50:13 - 0:00:00 - nsh@@: 1\n",
      "INFO - 05/20/20 09:50:13 - 0:00:00 - bta@@: 1\n",
      "INFO - 05/20/20 09:50:13 - 0:00:00 - isiiyae: 1\n",
      "INFO - 05/20/20 09:50:14 - 0:00:00 - Read 6667 words from the vocabulary file.\n",
      "\n",
      "Saving the data to /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/Limbum-Ngiemboon.Limbum.test.pth ...\n",
      "INFO - 05/20/20 09:50:14 - 0:00:00 - 32382 words (6667 unique) in 790 sentences.\n",
      "INFO - 05/20/20 09:50:14 - 0:00:00 - 5 unknown words (4 unique), covering 0.02% of the data.\n",
      "INFO - 05/20/20 09:50:14 - 0:00:00 - muen: 2\n",
      "INFO - 05/20/20 09:50:14 - 0:00:00 - ns: 1\n",
      "INFO - 05/20/20 09:50:14 - 0:00:00 - cii@@: 1\n",
      "INFO - 05/20/20 09:50:14 - 0:00:00 - gwe@@: 1\n",
      "INFO - 05/20/20 09:50:15 - 0:00:00 - Read 6667 words from the vocabulary file.\n",
      "\n",
      "Saving the data to /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/Limbum-Ngiemboon.Ngiemboon.train.pth ...\n",
      "INFO - 05/20/20 09:50:15 - 0:00:00 - 220240 words (6667 unique) in 6321 sentences.\n",
      "INFO - 05/20/20 09:50:15 - 0:00:00 - Read 6667 words from the vocabulary file.\n",
      "\n",
      "Saving the data to /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/Limbum-Ngiemboon.Ngiemboon.valid.pth ...\n",
      "INFO - 05/20/20 09:50:15 - 0:00:00 - 28350 words (6667 unique) in 790 sentences.\n",
      "INFO - 05/20/20 09:50:15 - 0:00:00 - 21 unknown words (16 unique), covering 0.07% of the data.\n",
      "INFO - 05/20/20 09:50:15 - 0:00:00 - xueenenaꞌ: 3\n",
      "INFO - 05/20/20 09:50:15 - 0:00:00 - um: 2\n",
      "INFO - 05/20/20 09:50:15 - 0:00:00 - samari@@: 2\n",
      "INFO - 05/20/20 09:50:15 - 0:00:00 - matsꞌi@@: 2\n",
      "INFO - 05/20/20 09:50:15 - 0:00:00 - tseiꞌts@@: 1\n",
      "INFO - 05/20/20 09:50:15 - 0:00:00 - naaⁿꞌaⁿ: 1\n",
      "INFO - 05/20/20 09:50:15 - 0:00:00 - gri@@: 1\n",
      "INFO - 05/20/20 09:50:15 - 0:00:00 - canch@@: 1\n",
      "INFO - 05/20/20 09:50:15 - 0:00:00 - efes@@: 1\n",
      "INFO - 05/20/20 09:50:15 - 0:00:00 - tjoomꞌ@@: 1\n",
      "INFO - 05/20/20 09:50:15 - 0:00:00 - una: 1\n",
      "INFO - 05/20/20 09:50:15 - 0:00:00 - cire@@: 1\n",
      "INFO - 05/20/20 09:50:15 - 0:00:00 - barrab@@: 1\n",
      "INFO - 05/20/20 09:50:15 - 0:00:00 - oliv@@: 1\n",
      "INFO - 05/20/20 09:50:15 - 0:00:00 - scu: 1\n",
      "INFO - 05/20/20 09:50:15 - 0:00:00 - xua: 1\n",
      "INFO - 05/20/20 09:50:16 - 0:00:00 - Read 6667 words from the vocabulary file.\n",
      "\n",
      "Saving the data to /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/Limbum-Ngiemboon.Ngiemboon.test.pth ...\n",
      "INFO - 05/20/20 09:50:16 - 0:00:00 - 27928 words (6667 unique) in 790 sentences.\n",
      "INFO - 05/20/20 09:50:16 - 0:00:00 - 19 unknown words (14 unique), covering 0.07% of the data.\n",
      "INFO - 05/20/20 09:50:16 - 0:00:00 - canch@@: 3\n",
      "INFO - 05/20/20 09:50:16 - 0:00:00 - aqui@@: 2\n",
      "INFO - 05/20/20 09:50:16 - 0:00:00 - ¡: 2\n",
      "INFO - 05/20/20 09:50:16 - 0:00:00 - he@@: 2\n",
      "INFO - 05/20/20 09:50:16 - 0:00:00 - las: 1\n",
      "INFO - 05/20/20 09:50:16 - 0:00:00 - pro@@: 1\n",
      "INFO - 05/20/20 09:50:16 - 0:00:00 - xueenenaꞌ: 1\n",
      "INFO - 05/20/20 09:50:16 - 0:00:00 - sala@@: 1\n",
      "INFO - 05/20/20 09:50:16 - 0:00:00 - juꞌ: 1\n",
      "INFO - 05/20/20 09:50:16 - 0:00:00 - uena: 1\n",
      "INFO - 05/20/20 09:50:16 - 0:00:00 - bla@@: 1\n",
      "INFO - 05/20/20 09:50:16 - 0:00:00 - nne@@: 1\n",
      "INFO - 05/20/20 09:50:16 - 0:00:00 - x: 1\n",
      "INFO - 05/20/20 09:50:16 - 0:00:00 - ꞌndy@@: 1\n",
      "\n",
      "\n",
      "***Using parallel data to construct monolingual data***\n",
      "\n",
      "\n",
      "***Creat the file to train the XLM model with MLM+TLM objective***\n",
      "\n",
      "\n",
      "*** build data with succes : dir /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed ***\n"
     ]
    }
   ],
   "source": [
    "# moins de codes que les autres, sinon \"fast: fastBPE/fastBPE.hpp:458: void fastBPE::readCodes(const char* ...).Assertion `codes.find(pair) == codes.end()' failed.\"\n",
    "%env nCodes=7000 \n",
    "%env add_para_data_to_mono_data=False\n",
    "! ../build_meta_data.sh $sub_task $n_samples $add_para_data_to_mono_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 912,
     "status": "ok",
     "timestamp": 1589794594190,
     "user": {
      "displayName": "Pascal Tikeng",
      "photoUrl": "",
      "userId": "15074930698580545771"
     },
     "user_tz": -120
    },
    "id": "Oqvj2wmXxVYv",
    "outputId": "8122a69c-06a5-4201-f446-accb89496e4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OUTPATH=/home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed\n",
      "env: exp_id=maml\n",
      "env: remove_long_sentences_train=True\n",
      "env: remove_long_sentences_valid=True\n",
      "env: remove_long_sentences_test=True\n"
     ]
    }
   ],
   "source": [
    "%env OUTPATH=/home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed\n",
    "%env exp_id=maml\n",
    "# If you don't have enough RAM or swap memory, leave these three parameters to True, otherwise you may get an error like this when evaluating \n",
    "# RuntimeError: copy_if failed to synchronize: cudaErrorAssert: device-side assert triggered\n",
    "%env remove_long_sentences_train=True\n",
    "%env remove_long_sentences_valid=True\n",
    "%env remove_long_sentences_test=True\n",
    "#--remove_long_sentences_train $remove_long_sentences_train --remove_long_sentences_valid $remove_long_sentences_valid --remove_long_sentences_test $remove_long_sentences_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wh7JBy9Vxl-r"
   },
   "outputs": [],
   "source": [
    "# le plus grand fichier à tensor_len phrases, on cherche le multiple de \"batch_size\" le plus proche de ce \n",
    "# nombre par valeur supérieur : epoch_size doit etre un multiple non nul de ce nombre (pour ne pas gaspiller) \n",
    "\n",
    "def getEpochSize(tensor_len, batch_size):\n",
    "    i = tensor_len\n",
    "    while True :\n",
    "        if i%batch_size == 0 :\n",
    "            return i//batch_size\n",
    "        i = i + 1\n",
    "\n",
    "import io\n",
    "\n",
    "def n_lines(file_path):\n",
    "    return len(io.open(file_path, encoding='UTF-8').read().split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 948,
     "status": "ok",
     "timestamp": 1589794609688,
     "user": {
      "displayName": "Pascal Tikeng",
      "photoUrl": "",
      "userId": "15074930698580545771"
     },
     "user_tz": -120
    },
    "id": "AihBQi8Jx9gP",
    "outputId": "5acc86b6-eb57-445e-d42e-4396aab5eb61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_len = 6322\n"
     ]
    }
   ],
   "source": [
    "tensor_len = n_lines(file_path = \"/home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/Limbum-Ngiemboon.Limbum.train\")\n",
    "print(\"tensor_len = \" + str(tensor_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1662,
     "status": "ok",
     "timestamp": 1589794617247,
     "user": {
      "displayName": "Pascal Tikeng",
      "photoUrl": "",
      "userId": "15074930698580545771"
     },
     "user_tz": -120
    },
    "id": "xBxqdlfwyQ_l",
    "outputId": "18c8167c-2f7d-46d2-a501-16ace7fe1a0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: epoch_size=6322\n",
      "env: lgs=Limbum-Ngiemboon\n",
      "env: train_n_samples=-1\n",
      "env: valid_n_samples=-1\n",
      "env: test_n_samples=-1\n",
      "env: stopping_criterion=_valid_mlm_ppl,10\n",
      "env: eval_bleu=false\n"
     ]
    }
   ],
   "source": [
    "%env epoch_size=6322\n",
    "\n",
    "%env lgs=Limbum-Ngiemboon\n",
    "\n",
    "# limit the number of examples (-1 by default for non limitation)\n",
    "%env train_n_samples=-1\n",
    "%env valid_n_samples=-1\n",
    "%env test_n_samples=-1\n",
    "#--train_n_samples $train_n_samples --valid_n_samples $valid_n_samples --test_n_samples $test_n_samples\n",
    "\n",
    "# stopping criterion (if criterion does not improve 10 times)\n",
    "%env stopping_criterion=_valid_mlm_ppl,10\n",
    "%env eval_bleu false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3453921,
     "status": "ok",
     "timestamp": 1589810942252,
     "user": {
      "displayName": "Pascal Tikeng",
      "photoUrl": "",
      "userId": "15074930698580545771"
     },
     "user_tz": -120
    },
    "id": "YK7oveg7ykkM",
    "outputId": "6819c44f-056b-44ce-f609-6e37d970e8fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: mlm_steps=Limbum,Ngiemboon,Limbum-Ngiemboon\n",
      "env: batch_size=8\n",
      "env: max_epoch=100\n",
      "env: dump_path=/home/jupyter/models/africa/cluster3\n",
      "FAISS library was not found.\n",
      "FAISS not available. Switching to standard nearest neighbors search implementation.\n",
      "SLURM job: False\n",
      "0 - Number of nodes: 1\n",
      "0 - Node ID        : 0\n",
      "0 - Local rank     : 0\n",
      "0 - Global rank    : 0\n",
      "0 - World size     : 1\n",
      "0 - GPUs per node  : 1\n",
      "0 - Master         : True\n",
      "0 - Multi-node     : False\n",
      "0 - Multi-GPU      : False\n",
      "0 - Hostname       : african-translator-vm-bis-vm\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - accumulate_gradients: 1\n",
      "                                     ae_steps: []\n",
      "                                     amp: -1\n",
      "                                     asm: False\n",
      "                                     attention_dropout: 0.1\n",
      "                                     batch_size: 8\n",
      "                                     beam_size: 1\n",
      "                                     bptt: 256\n",
      "                                     bt_src_langs: []\n",
      "                                     bt_steps: []\n",
      "                                     clip_grad_norm: 5\n",
      "                                     clm_steps: []\n",
      "                                     command: python train.py --exp_name mlm_tlm_LimbumNgiemboon --exp_id maml --dump_path '/home/jupyter/models/africa/cluster3' --data_path '/home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed' --lgs 'Limbum-Ngiemboon' --clm_steps '' --mlm_steps 'Limbum,Ngiemboon,Limbum-Ngiemboon' --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 8 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 6322 --max_epoch 100 --validation_metrics _valid_mlm_ppl --stopping_criterion '_valid_mlm_ppl,10' --eval_bleu false --remove_long_sentences_train True --remove_long_sentences_valid True --remove_long_sentences_test True --train_n_samples '-1' --valid_n_samples '-1' --test_n_samples '-1' --exp_id \"maml\"\n",
      "                                     context_size: 0\n",
      "                                     data_path: /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed\n",
      "                                     debug: False\n",
      "                                     debug_slurm: False\n",
      "                                     debug_train: False\n",
      "                                     dropout: 0.1\n",
      "                                     dump_path: /home/jupyter/models/africa/cluster3/mlm_tlm_LimbumNgiemboon/maml\n",
      "                                     early_stopping: False\n",
      "                                     emb_dim: 1024\n",
      "                                     encoder_only: True\n",
      "                                     epoch_size: 6322\n",
      "                                     eval_bleu: False\n",
      "                                     eval_only: False\n",
      "                                     exp_id: maml\n",
      "                                     exp_name: mlm_tlm_LimbumNgiemboon\n",
      "                                     fp16: False\n",
      "                                     gelu_activation: True\n",
      "                                     global_rank: 0\n",
      "                                     group_by_size: True\n",
      "                                     id2lang: {0: 'Limbum', 1: 'Ngiemboon'}\n",
      "                                     is_master: True\n",
      "                                     is_slurm_job: False\n",
      "                                     lambda_ae: 1\n",
      "                                     lambda_bt: 1\n",
      "                                     lambda_clm: 1\n",
      "                                     lambda_mlm: 1\n",
      "                                     lambda_mt: 1\n",
      "                                     lambda_pc: 1\n",
      "                                     lang2id: {'Limbum': 0, 'Ngiemboon': 1}\n",
      "                                     langs: ['Limbum', 'Ngiemboon']\n",
      "                                     length_penalty: 1\n",
      "                                     lg_sampling_factor: -1\n",
      "                                     lgs: ['Limbum-Ngiemboon']\n",
      "                                     local_rank: 0\n",
      "                                     master_port: -1\n",
      "                                     max_batch_size: 0\n",
      "                                     max_epoch: 100\n",
      "                                     max_len: 100\n",
      "                                     max_vocab: -1\n",
      "                                     meta_learning: False\n",
      "                                     meta_params: ...\n",
      "                                     min_count: 0\n",
      "                                     mlm_steps: [('Limbum', None), ('Ngiemboon', None), ('Limbum', 'Ngiemboon')]\n",
      "                                     mono_dataset: {'Limbum': {'train': '/home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/train.Limbum.pth', 'valid': '/home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/valid.Limbum.pth', 'test': '/home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/test.Limbum.pth'}, 'Ngiemboon': {'train': '/home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/train.Ngiemboon.pth', 'valid': '/home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/valid.Ngiemboon.pth', 'test': '/home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/test.Ngiemboon.pth'}}\n",
      "                                     mt_steps: []\n",
      "                                     multi_gpu: False\n",
      "                                     multi_node: False\n",
      "                                     n_gpu_per_node: 1\n",
      "                                     n_heads: 8\n",
      "                                     n_langs: 2\n",
      "                                     n_layers: 6\n",
      "                                     n_nodes: 1\n",
      "                                     n_samples: {'train': -1, 'valid': -1, 'test': -1}\n",
      "                                     n_task: 1\n",
      "                                     node_id: 0\n",
      "                                     optimizer: adam,lr=0.0001\n",
      "                                     para_dataset: {('Limbum', 'Ngiemboon'): {'train': ('/home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/train.Limbum-Ngiemboon.Limbum.pth', '/home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/train.Limbum-Ngiemboon.Ngiemboon.pth'), 'valid': ('/home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/valid.Limbum-Ngiemboon.Limbum.pth', '/home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/valid.Limbum-Ngiemboon.Ngiemboon.pth'), 'test': ('/home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/test.Limbum-Ngiemboon.Limbum.pth', '/home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/test.Limbum-Ngiemboon.Ngiemboon.pth')}}\n",
      "                                     pc_steps: []\n",
      "                                     reload_checkpoint: \n",
      "                                     reload_emb: \n",
      "                                     reload_model: \n",
      "                                     remove_long_sentences: {'train': True, 'valid': True, 'test': True}\n",
      "                                     remove_long_sentences_test: True\n",
      "                                     remove_long_sentences_train: True\n",
      "                                     remove_long_sentences_valid: True\n",
      "                                     sample_alpha: 0\n",
      "                                     save_periodic: 0\n",
      "                                     share_inout_emb: True\n",
      "                                     sinusoidal_embeddings: False\n",
      "                                     split_data: False\n",
      "                                     stopping_criterion: _valid_mlm_ppl,10\n",
      "                                     test_n_samples: -1\n",
      "                                     tokens_per_batch: -1\n",
      "                                     train_n_samples: -1\n",
      "                                     use_lang_emb: True\n",
      "                                     use_memory: False\n",
      "                                     valid_n_samples: -1\n",
      "                                     validation_metrics: _valid_mlm_ppl\n",
      "                                     word_blank: 0\n",
      "                                     word_dropout: 0\n",
      "                                     word_keep: 0.1\n",
      "                                     word_mask: 0.8\n",
      "                                     word_mask_keep_rand: 0.8,0.1,0.1\n",
      "                                     word_pred: 0.15\n",
      "                                     word_rand: 0.1\n",
      "                                     word_shuffle: 0\n",
      "                                     world_size: 1\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - The experiment will be stored in /home/jupyter/models/africa/cluster3/mlm_tlm_LimbumNgiemboon/maml\n",
      "                                     \n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Running command: python train.py --exp_name mlm_tlm_LimbumNgiemboon --exp_id maml --dump_path '/home/jupyter/models/africa/cluster3' --data_path '/home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed' --lgs 'Limbum-Ngiemboon' --clm_steps '' --mlm_steps 'Limbum,Ngiemboon,Limbum-Ngiemboon' --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 8 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 6322 --max_epoch 100 --validation_metrics _valid_mlm_ppl --stopping_criterion '_valid_mlm_ppl,10' --eval_bleu false --remove_long_sentences_train True --remove_long_sentences_valid True --remove_long_sentences_test True --train_n_samples '-1' --valid_n_samples '-1' --test_n_samples '-1'\n",
      "\n",
      "WARNING - 05/20/20 09:54:32 - 0:00:00 - Signal handler installed.\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - ============ langs: Limbum, Ngiemboon\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - ============ Monolingual data (Limbum)\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Loading data from /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/train.Limbum.pth ...\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - 259414 words (6667 unique) in 6321 sentences. 0 unknown words (0 unique) covering 0.00% of the data.\n",
      "\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Loading data from /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/valid.Limbum.pth ...\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - 33215 words (6667 unique) in 790 sentences. 13 unknown words (10 unique) covering 0.04% of the data.\n",
      "\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Loading data from /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/test.Limbum.pth ...\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - 32382 words (6667 unique) in 790 sentences. 5 unknown words (4 unique) covering 0.02% of the data.\n",
      "\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - ============ Monolingual data (Ngiemboon)\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Loading data from /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/train.Ngiemboon.pth ...\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - 220240 words (6667 unique) in 6321 sentences. 0 unknown words (0 unique) covering 0.00% of the data.\n",
      "\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Loading data from /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/valid.Ngiemboon.pth ...\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - 28350 words (6667 unique) in 790 sentences. 21 unknown words (16 unique) covering 0.07% of the data.\n",
      "\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Loading data from /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/test.Ngiemboon.pth ...\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - 27928 words (6667 unique) in 790 sentences. 19 unknown words (14 unique) covering 0.07% of the data.\n",
      "\n",
      "\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - ============ Parallel data (Limbum-Ngiemboon)\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Loading data from /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/train.Limbum-Ngiemboon.Limbum.pth ...\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - 259414 words (6667 unique) in 6321 sentences. 0 unknown words (0 unique) covering 0.00% of the data.\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Loading data from /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/train.Limbum-Ngiemboon.Ngiemboon.pth ...\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - 220240 words (6667 unique) in 6321 sentences. 0 unknown words (0 unique) covering 0.00% of the data.\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Removed 45 too long sentences.\n",
      "\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Loading data from /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/valid.Limbum-Ngiemboon.Limbum.pth ...\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - 33215 words (6667 unique) in 790 sentences. 13 unknown words (10 unique) covering 0.04% of the data.\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Loading data from /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/valid.Limbum-Ngiemboon.Ngiemboon.pth ...\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - 28350 words (6667 unique) in 790 sentences. 21 unknown words (16 unique) covering 0.07% of the data.\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Removed 4 too long sentences.\n",
      "\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Loading data from /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/test.Limbum-Ngiemboon.Limbum.pth ...\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - 32382 words (6667 unique) in 790 sentences. 5 unknown words (4 unique) covering 0.02% of the data.\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Loading data from /home/jupyter/models/africa/cluster3/data/Limbum_Ngiemboon/processed/test.Limbum-Ngiemboon.Ngiemboon.pth ...\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - 27928 words (6667 unique) in 790 sentences. 19 unknown words (14 unique) covering 0.07% of the data.\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Removed 2 too long sentences.\n",
      "\n",
      "\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - ============ Data summary\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Monolingual data   - train -       Limbum:      6321\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Monolingual data   - valid -       Limbum:       790\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Monolingual data   -  test -       Limbum:       790\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Monolingual data   - train -    Ngiemboon:      6321\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Monolingual data   - valid -    Ngiemboon:       790\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Monolingual data   -  test -    Ngiemboon:       790\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Parallel data      - train - Limbum-Ngiemboon:      6276\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Parallel data      - valid - Limbum-Ngiemboon:       786\n",
      "INFO - 05/20/20 09:54:32 - 0:00:00 - Parallel data      -  test - Limbum-Ngiemboon:       788\n",
      "\n",
      "INFO - 05/20/20 09:54:33 - 0:00:01 - Model: TransformerModel(\n",
      "                                       (position_embeddings): Embedding(512, 1024)\n",
      "                                       (lang_embeddings): Embedding(2, 1024)\n",
      "                                       (embeddings): Embedding(6667, 1024, padding_idx=2)\n",
      "                                       (layer_norm_emb): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                       (attentions): ModuleList(\n",
      "                                         (0): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (1): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (2): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (3): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (4): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (5): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                       )\n",
      "                                       (layer_norm1): ModuleList(\n",
      "                                         (0): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (2): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (3): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (4): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (5): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                       )\n",
      "                                       (ffns): ModuleList(\n",
      "                                         (0): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (1): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (2): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (3): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (4): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (5): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                       )\n",
      "                                       (layer_norm2): ModuleList(\n",
      "                                         (0): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (2): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (3): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (4): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (5): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                       )\n",
      "                                       (memories): ModuleDict()\n",
      "                                       (pred_layer): PredLayer(\n",
      "                                         (proj): Linear(in_features=1024, out_features=6667, bias=True)\n",
      "                                       )\n",
      "                                     )\n",
      "INFO - 05/20/20 09:54:33 - 0:00:01 - Number of parameters (model): 82939403\n",
      "INFO - 05/20/20 09:54:41 - 0:00:09 - Found 0 memories.\n",
      "INFO - 05/20/20 09:54:41 - 0:00:09 - Found 6 FFN.\n",
      "INFO - 05/20/20 09:54:41 - 0:00:09 - Found 102 parameters in model.\n",
      "INFO - 05/20/20 09:54:41 - 0:00:09 - Optimizers: model\n",
      "INFO - 05/20/20 09:54:41 - 0:00:10 - ============ Starting epoch 0 ... ============\n",
      "INFO - 05/20/20 09:54:41 - 0:00:10 - Creating new training data iterator (pred,Limbum) ...\n",
      "INFO - 05/20/20 09:54:44 - 0:00:13 - Creating new training data iterator (pred,Limbum,Ngiemboon) ...\n",
      "INFO - 05/20/20 09:54:45 - 0:00:13 - Creating new training data iterator (pred,Ngiemboon) ...\n",
      "INFO - 05/20/20 09:54:56 - 0:00:24 -       5 -    8.20 sent/s -   248.18 words/s - MLM-Limbum:  8.9018 || MLM-Ngiemboon:  7.2074 || MLM-Limbum-Ngiemboon:  6.7885 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 09:55:06 - 0:00:34 -      10 -   11.91 sent/s -   714.75 words/s - MLM-Limbum:  6.1979 || MLM-Ngiemboon:  6.7285 || MLM-Limbum-Ngiemboon:  6.1012 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 09:55:20 - 0:00:48 -      15 -    8.66 sent/s -   775.71 words/s - MLM-Limbum:  5.4711 || MLM-Ngiemboon:  6.1318 || MLM-Limbum-Ngiemboon:  5.6020 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 09:55:34 - 0:01:02 -      20 -    8.55 sent/s -  1028.58 words/s - MLM-Limbum:  5.1858 || MLM-Ngiemboon:  6.0362 || MLM-Limbum-Ngiemboon:  5.4532 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 09:55:47 - 0:01:16 -      25 -    8.63 sent/s -  1289.84 words/s - MLM-Limbum:  5.0105 || MLM-Ngiemboon:  6.2043 || MLM-Limbum-Ngiemboon:  5.2315 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 09:56:01 - 0:01:30 -      30 -    8.65 sent/s -  1549.74 words/s - MLM-Limbum:  5.3000 || MLM-Ngiemboon:  5.8627 || MLM-Limbum-Ngiemboon:  5.3355 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 09:56:15 - 0:01:43 -      35 -    8.79 sent/s -  1822.59 words/s - MLM-Limbum:  4.9302 || MLM-Ngiemboon:  5.9059 || MLM-Limbum-Ngiemboon:  5.4386 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 09:56:29 - 0:01:57 -      40 -    8.69 sent/s -  2054.97 words/s - MLM-Limbum:  4.9221 || MLM-Ngiemboon:  5.6550 || MLM-Limbum-Ngiemboon:  5.3173 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 09:56:42 - 0:02:10 -      45 -    8.95 sent/s -  2379.59 words/s - MLM-Limbum:  4.8954 || MLM-Ngiemboon:  5.6539 || MLM-Limbum-Ngiemboon:  4.9879 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 09:56:52 - 0:02:20 -      50 -   12.86 sent/s -  3797.67 words/s - MLM-Limbum:  4.8087 || MLM-Ngiemboon:  5.6356 || MLM-Limbum-Ngiemboon:  5.1927 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 09:57:05 - 0:02:34 -      55 -    8.68 sent/s -  2833.07 words/s - MLM-Limbum:  4.8652 || MLM-Ngiemboon:  5.5161 || MLM-Limbum-Ngiemboon:  5.0360 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 09:57:19 - 0:02:47 -      60 -    8.66 sent/s -  3078.49 words/s - MLM-Limbum:  4.8084 || MLM-Ngiemboon:  5.8616 || MLM-Limbum-Ngiemboon:  5.0450 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 09:57:33 - 0:03:02 -      65 -    8.49 sent/s -  3271.51 words/s - MLM-Limbum:  4.7524 || MLM-Ngiemboon:  5.8682 || MLM-Limbum-Ngiemboon:  5.0976 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 09:57:47 - 0:03:15 -      70 -    8.67 sent/s -  3602.18 words/s - MLM-Limbum:  4.7280 || MLM-Ngiemboon:  5.7447 || MLM-Limbum-Ngiemboon:  5.2620 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 09:58:01 - 0:03:29 -      75 -    8.84 sent/s -  3922.35 words/s - MLM-Limbum:  4.7163 || MLM-Ngiemboon:  5.8214 || MLM-Limbum-Ngiemboon:  5.0820 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 09:58:15 - 0:03:43 -      80 -    8.65 sent/s -  4088.10 words/s - MLM-Limbum:  4.7056 || MLM-Ngiemboon:  5.8933 || MLM-Limbum-Ngiemboon:  5.1978 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 09:58:28 - 0:03:57 -      85 -    8.66 sent/s -  4340.93 words/s - MLM-Limbum:  4.7442 || MLM-Ngiemboon:  5.7313 || MLM-Limbum-Ngiemboon:  5.2030 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 09:58:42 - 0:04:10 -      90 -    8.73 sent/s -  4621.45 words/s - MLM-Limbum:  4.8792 || MLM-Ngiemboon:  5.7017 || MLM-Limbum-Ngiemboon:  5.1665 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 09:58:56 - 0:04:24 -      95 -    8.73 sent/s -  4875.06 words/s - MLM-Limbum:  4.7971 || MLM-Ngiemboon:  5.7201 || MLM-Limbum-Ngiemboon:  5.0968 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 09:59:10 - 0:04:38 -     100 -    8.63 sent/s -  5072.79 words/s - MLM-Limbum:  4.6693 || MLM-Ngiemboon:  5.7548 || MLM-Limbum-Ngiemboon:  5.3590 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 09:59:24 - 0:04:52 -     105 -    8.76 sent/s -  5401.50 words/s - MLM-Limbum:  4.7100 || MLM-Ngiemboon:  5.5376 || MLM-Limbum-Ngiemboon:  4.8917 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 09:59:38 - 0:05:06 -     110 -    8.58 sent/s -  5550.37 words/s - MLM-Limbum:  4.6273 || MLM-Ngiemboon:  5.9610 || MLM-Limbum-Ngiemboon:  5.3048 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 09:59:51 - 0:05:19 -     115 -    8.77 sent/s -  5928.26 words/s - MLM-Limbum:  4.6998 || MLM-Ngiemboon:  5.7531 || MLM-Limbum-Ngiemboon:  5.0932 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 09:59:54 - 0:05:22 - Creating new training data iterator (pred,Ngiemboon) ...\n",
      "INFO - 05/20/20 10:00:05 - 0:05:33 -     120 -    8.78 sent/s -  6190.43 words/s - MLM-Limbum:  4.5919 || MLM-Ngiemboon:  5.6749 || MLM-Limbum-Ngiemboon:  5.0750 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:00:19 - 0:05:47 -     125 -    8.67 sent/s -  6369.02 words/s - MLM-Limbum:  4.5303 || MLM-Ngiemboon:  5.6531 || MLM-Limbum-Ngiemboon:  5.0096 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:00:22 - 0:05:51 - Creating new training data iterator (pred,Limbum) ...\n",
      "INFO - 05/20/20 10:00:33 - 0:06:01 -     130 -    8.61 sent/s -  6566.72 words/s - MLM-Limbum:  4.7521 || MLM-Ngiemboon:  5.6453 || MLM-Limbum-Ngiemboon:  4.7535 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:00:47 - 0:06:15 -     135 -    8.62 sent/s -  6838.47 words/s - MLM-Limbum:  4.6771 || MLM-Ngiemboon:  5.7441 || MLM-Limbum-Ngiemboon:  5.0574 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:01:01 - 0:06:29 -     140 -    8.50 sent/s -  6999.62 words/s - MLM-Limbum:  4.5732 || MLM-Ngiemboon:  5.5938 || MLM-Limbum-Ngiemboon:  4.9860 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:01:14 - 0:06:43 -     145 -    8.74 sent/s -  7450.94 words/s - MLM-Limbum:  4.7175 || MLM-Ngiemboon:  5.7890 || MLM-Limbum-Ngiemboon:  4.8084 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:01:28 - 0:06:57 -     150 -    8.65 sent/s -  7620.98 words/s - MLM-Limbum:  4.6967 || MLM-Ngiemboon:  5.6265 || MLM-Limbum-Ngiemboon:  5.1480 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:01:42 - 0:07:11 -     155 -    8.55 sent/s -  7791.37 words/s - MLM-Limbum:  4.7307 || MLM-Ngiemboon:  5.6654 || MLM-Limbum-Ngiemboon:  5.2102 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:01:56 - 0:07:25 -     160 -    8.46 sent/s -  8026.11 words/s - MLM-Limbum:  4.6382 || MLM-Ngiemboon:  5.6739 || MLM-Limbum-Ngiemboon:  5.0926 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:02:10 - 0:07:38 -     165 -    8.69 sent/s -  8432.20 words/s - MLM-Limbum:  4.7460 || MLM-Ngiemboon:  5.5388 || MLM-Limbum-Ngiemboon:  5.1732 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:02:24 - 0:07:53 -     170 -    8.53 sent/s -  8537.05 words/s - MLM-Limbum:  4.7478 || MLM-Ngiemboon:  5.7219 || MLM-Limbum-Ngiemboon:  4.9809 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:02:38 - 0:08:06 -     175 -    8.62 sent/s -  8876.51 words/s - MLM-Limbum:  4.6113 || MLM-Ngiemboon:  5.7030 || MLM-Limbum-Ngiemboon:  4.8854 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:02:52 - 0:08:21 -     180 -    8.50 sent/s -  9003.59 words/s - MLM-Limbum:  4.7597 || MLM-Ngiemboon:  5.6778 || MLM-Limbum-Ngiemboon:  4.9584 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:03:06 - 0:08:34 -     185 -    8.81 sent/s -  9589.58 words/s - MLM-Limbum:  4.5765 || MLM-Ngiemboon:  5.5599 || MLM-Limbum-Ngiemboon:  5.1994 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:03:20 - 0:08:48 -     190 -    8.71 sent/s -  9726.17 words/s - MLM-Limbum:  4.7224 || MLM-Ngiemboon:  5.6629 || MLM-Limbum-Ngiemboon:  5.0079 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:03:34 - 0:09:02 -     195 -    8.71 sent/s -  9989.12 words/s - MLM-Limbum:  4.6508 || MLM-Ngiemboon:  5.5713 || MLM-Limbum-Ngiemboon:  4.9093 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:03:47 - 0:09:16 -     200 -    8.60 sent/s - 10126.92 words/s - MLM-Limbum:  4.6640 || MLM-Ngiemboon:  5.6780 || MLM-Limbum-Ngiemboon:  4.9075 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:04:01 - 0:09:29 -     205 -    8.77 sent/s - 10580.09 words/s - MLM-Limbum:  4.6849 || MLM-Ngiemboon:  5.6345 || MLM-Limbum-Ngiemboon:  4.7293 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:04:15 - 0:09:43 -     210 -    8.52 sent/s - 10526.42 words/s - MLM-Limbum:  4.6682 || MLM-Ngiemboon:  5.4425 || MLM-Limbum-Ngiemboon:  5.1146 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:04:29 - 0:09:57 -     215 -    8.64 sent/s - 10934.21 words/s - MLM-Limbum:  4.5898 || MLM-Ngiemboon:  5.8659 || MLM-Limbum-Ngiemboon:  5.0536 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:04:43 - 0:10:11 -     220 -    8.60 sent/s - 11136.85 words/s - MLM-Limbum:  4.7308 || MLM-Ngiemboon:  5.5814 || MLM-Limbum-Ngiemboon:  4.9136 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:04:57 - 0:10:26 -     225 -    8.39 sent/s - 11118.75 words/s - MLM-Limbum:  4.6602 || MLM-Ngiemboon:  5.5854 || MLM-Limbum-Ngiemboon:  5.1713 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:05:03 - 0:10:31 - Creating new training data iterator (pred,Ngiemboon) ...\n",
      "INFO - 05/20/20 10:05:11 - 0:10:39 -     230 -    8.81 sent/s - 11927.83 words/s - MLM-Limbum:  4.4390 || MLM-Ngiemboon:  5.7644 || MLM-Limbum-Ngiemboon:  5.1641 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:05:25 - 0:10:53 -     235 -    8.62 sent/s - 11937.71 words/s - MLM-Limbum:  4.6547 || MLM-Ngiemboon:  5.6742 || MLM-Limbum-Ngiemboon:  5.1003 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:05:39 - 0:11:07 -     240 -    8.59 sent/s - 12146.60 words/s - MLM-Limbum:  4.6910 || MLM-Ngiemboon:  5.7503 || MLM-Limbum-Ngiemboon:  5.1369 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:05:53 - 0:11:21 -     245 -    8.46 sent/s - 12237.28 words/s - MLM-Limbum:  4.5242 || MLM-Ngiemboon:  5.6963 || MLM-Limbum-Ngiemboon:  5.0601 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:06:07 - 0:11:35 -     250 -    8.86 sent/s - 13059.39 words/s - MLM-Limbum:  4.6299 || MLM-Ngiemboon:  5.6145 || MLM-Limbum-Ngiemboon:  4.8810 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:06:07 - 0:11:35 - Creating new training data iterator (pred,Limbum) ...\n",
      "INFO - 05/20/20 10:06:20 - 0:11:49 -     255 -    8.70 sent/s - 13071.61 words/s - MLM-Limbum:  4.6189 || MLM-Ngiemboon:  5.7827 || MLM-Limbum-Ngiemboon:  4.9021 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:06:34 - 0:12:02 -     260 -    8.77 sent/s - 13435.26 words/s - MLM-Limbum:  4.7137 || MLM-Ngiemboon:  5.6321 || MLM-Limbum-Ngiemboon:  4.9814 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:06:45 - 0:12:13 - ============ End of epoch 0 ============\n",
      "INFO - 05/20/20 10:06:50 - 0:12:18 - epoch -> 0.000000\n",
      "INFO - 05/20/20 10:06:50 - 0:12:18 - valid_Limbum_mlm_ppl -> 141.725575\n",
      "INFO - 05/20/20 10:06:50 - 0:12:18 - valid_Limbum_mlm_acc -> 9.326425\n",
      "INFO - 05/20/20 10:06:50 - 0:12:18 - valid_Ngiemboon_mlm_ppl -> 363.885430\n",
      "INFO - 05/20/20 10:06:50 - 0:12:18 - valid_Ngiemboon_mlm_acc -> 9.844560\n",
      "INFO - 05/20/20 10:06:50 - 0:12:18 - valid_Limbum_Ngiemboon_mlm_ppl -> 200.994598\n",
      "INFO - 05/20/20 10:06:50 - 0:12:18 - valid_Limbum_Ngiemboon_mlm_acc -> 10.690423\n",
      "INFO - 05/20/20 10:06:50 - 0:12:18 - valid_mlm_ppl -> 252.805503\n",
      "INFO - 05/20/20 10:06:50 - 0:12:18 - valid_mlm_acc -> 9.585492\n",
      "INFO - 05/20/20 10:06:50 - 0:12:18 - test_Limbum_mlm_ppl -> 158.161105\n",
      "INFO - 05/20/20 10:06:50 - 0:12:18 - test_Limbum_mlm_acc -> 7.253886\n",
      "INFO - 05/20/20 10:06:50 - 0:12:18 - test_Ngiemboon_mlm_ppl -> 335.767851\n",
      "INFO - 05/20/20 10:06:50 - 0:12:18 - test_Ngiemboon_mlm_acc -> 15.803109\n",
      "INFO - 05/20/20 10:06:50 - 0:12:18 - test_Limbum_Ngiemboon_mlm_ppl -> 229.965964\n",
      "INFO - 05/20/20 10:06:50 - 0:12:18 - test_Limbum_Ngiemboon_mlm_acc -> 10.657596\n",
      "INFO - 05/20/20 10:06:50 - 0:12:18 - test_mlm_ppl -> 246.964478\n",
      "INFO - 05/20/20 10:06:50 - 0:12:18 - test_mlm_acc -> 11.528497\n",
      "INFO - 05/20/20 10:06:50 - 0:12:18 - __log__:{\"epoch\": 0, \"valid_Limbum_mlm_ppl\": 141.725575216261, \"valid_Limbum_mlm_acc\": 9.32642487046632, \"valid_Ngiemboon_mlm_ppl\": 363.8854299675535, \"valid_Ngiemboon_mlm_acc\": 9.844559585492227, \"valid_Limbum_Ngiemboon_mlm_ppl\": 200.99459841529665, \"valid_Limbum_Ngiemboon_mlm_acc\": 10.690423162583519, \"valid_mlm_ppl\": 252.80550259190724, \"valid_mlm_acc\": 9.585492227979273, \"test_Limbum_mlm_ppl\": 158.16110486960534, \"test_Limbum_mlm_acc\": 7.253886010362694, \"test_Ngiemboon_mlm_ppl\": 335.76785084693245, \"test_Ngiemboon_mlm_acc\": 15.803108808290155, \"test_Limbum_Ngiemboon_mlm_ppl\": 229.96596413917186, \"test_Limbum_Ngiemboon_mlm_acc\": 10.657596371882086, \"test_mlm_ppl\": 246.96447785826888, \"test_mlm_acc\": 11.528497409326425}\n",
      "INFO - 05/20/20 10:06:50 - 0:12:18 - New best score for valid_mlm_ppl: 252.805503\n",
      "INFO - 05/20/20 10:06:50 - 0:12:18 - Saving best-valid_mlm_ppl to /home/jupyter/models/africa/cluster3/mlm_tlm_LimbumNgiemboon/maml/best-valid_mlm_ppl.pth ...\n",
      "WARNING - 05/20/20 10:06:50 - 0:12:18 - Saving model parameters ...\n",
      "INFO - 05/20/20 10:06:50 - 0:12:18 - New best validation score: 252.805503\n",
      "INFO - 05/20/20 10:06:50 - 0:12:18 - Saving checkpoint to /home/jupyter/models/africa/cluster3/mlm_tlm_LimbumNgiemboon/maml/checkpoint.pth ...\n",
      "WARNING - 05/20/20 10:06:50 - 0:12:18 - Saving model parameters ...\n",
      "WARNING - 05/20/20 10:06:50 - 0:12:18 - Saving model optimizer ...\n",
      "INFO - 05/20/20 10:06:51 - 0:12:19 - ============ garbage collector collecting 0 ...\n",
      "INFO - 05/20/20 10:06:51 - 0:12:19 - ============ Starting epoch 1 ... ============\n",
      "INFO - 05/20/20 10:06:54 - 0:12:22 -     265 -    6.15 sent/s -  9610.60 words/s - MLM-Limbum:  4.6028 || MLM-Ngiemboon:  5.5195 || MLM-Limbum-Ngiemboon:  5.0280 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:07:07 - 0:12:35 -     270 -    8.85 sent/s - 14073.83 words/s - MLM-Limbum:  4.6196 || MLM-Ngiemboon:  5.6026 || MLM-Limbum-Ngiemboon:  5.0211 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:07:18 - 0:12:46 -     275 -   11.34 sent/s - 18369.22 words/s - MLM-Limbum:  4.6979 || MLM-Ngiemboon:  5.4257 || MLM-Limbum-Ngiemboon:  4.9536 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:07:32 - 0:12:58 -     280 -   10.07 sent/s - 16598.38 words/s - MLM-Limbum:  4.6424 || MLM-Ngiemboon:  5.6180 || MLM-Limbum-Ngiemboon:  5.0230 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:07:46 - 0:13:14 -     285 -    7.43 sent/s - 12475.05 words/s - MLM-Limbum:  4.7381 || MLM-Ngiemboon:  5.5439 || MLM-Limbum-Ngiemboon:  5.0416 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:08:13 - 0:13:42 -     295 -    8.59 sent/s - 14931.88 words/s - MLM-Limbum:  4.7226 || MLM-Ngiemboon:  5.6148 || MLM-Limbum-Ngiemboon:  4.8328 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:08:27 - 0:13:55 -     300 -    8.78 sent/s - 15513.97 words/s - MLM-Limbum:  4.7327 || MLM-Ngiemboon:  5.6711 || MLM-Limbum-Ngiemboon:  5.1752 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:08:41 - 0:14:09 -     305 -    8.88 sent/s - 15940.56 words/s - MLM-Limbum:  4.7323 || MLM-Ngiemboon:  5.6003 || MLM-Limbum-Ngiemboon:  4.8483 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:08:55 - 0:14:23 -     310 -    8.61 sent/s - 15722.50 words/s - MLM-Limbum:  4.6957 || MLM-Ngiemboon:  5.4238 || MLM-Limbum-Ngiemboon:  5.0481 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:09:05 - 0:14:33 -     315 -   11.61 sent/s - 21533.48 words/s - MLM-Limbum:  4.6344 || MLM-Ngiemboon:  5.5341 || MLM-Limbum-Ngiemboon:  5.0255 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:09:18 - 0:14:46 -     320 -    9.37 sent/s - 17658.88 words/s - MLM-Limbum:  4.7398 || MLM-Ngiemboon:  5.4746 || MLM-Limbum-Ngiemboon:  4.9094 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:09:31 - 0:15:00 -     325 -    8.72 sent/s - 16684.66 words/s - MLM-Limbum:  4.7358 || MLM-Ngiemboon:  5.6054 || MLM-Limbum-Ngiemboon:  4.9505 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:09:45 - 0:15:13 -     330 -    8.80 sent/s - 17099.90 words/s - MLM-Limbum:  4.6501 || MLM-Ngiemboon:  5.5607 || MLM-Limbum-Ngiemboon:  5.1400 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:09:59 - 0:15:27 -     335 -    8.73 sent/s - 17205.33 words/s - MLM-Limbum:  4.5545 || MLM-Ngiemboon:  5.5182 || MLM-Limbum-Ngiemboon:  5.0611 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:10:03 - 0:15:31 - Creating new training data iterator (pred,Ngiemboon) ...\n",
      "INFO - 05/20/20 10:10:12 - 0:15:41 -     340 -    8.80 sent/s - 17589.41 words/s - MLM-Limbum:  4.6367 || MLM-Ngiemboon:  5.7290 || MLM-Limbum-Ngiemboon:  5.0346 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:10:26 - 0:15:55 -     345 -    8.70 sent/s - 17643.36 words/s - MLM-Limbum:  4.6144 || MLM-Ngiemboon:  5.6246 || MLM-Limbum-Ngiemboon:  5.1002 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:10:40 - 0:16:08 -     350 -    8.60 sent/s - 17698.44 words/s - MLM-Limbum:  4.5763 || MLM-Ngiemboon:  5.5152 || MLM-Limbum-Ngiemboon:  4.9746 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:10:54 - 0:16:22 -     355 -    8.85 sent/s - 18481.59 words/s - MLM-Limbum:  4.6754 || MLM-Ngiemboon:  5.3262 || MLM-Limbum-Ngiemboon:  4.9482 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:11:08 - 0:16:36 -     360 -    8.63 sent/s - 18288.09 words/s - MLM-Limbum:  4.6033 || MLM-Ngiemboon:  5.6780 || MLM-Limbum-Ngiemboon:  5.0628 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:11:21 - 0:16:50 -     365 -    8.80 sent/s - 18907.97 words/s - MLM-Limbum:  4.7091 || MLM-Ngiemboon:  5.5161 || MLM-Limbum-Ngiemboon:  5.0376 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:11:35 - 0:17:03 -     370 -    8.92 sent/s - 19416.86 words/s - MLM-Limbum:  4.6010 || MLM-Ngiemboon:  5.7622 || MLM-Limbum-Ngiemboon:  4.7460 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:11:48 - 0:17:17 -     375 -    8.77 sent/s - 19336.44 words/s - MLM-Limbum:  4.6560 || MLM-Ngiemboon:  5.6573 || MLM-Limbum-Ngiemboon:  4.8034 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:12:02 - 0:17:30 -     380 -    8.95 sent/s - 19969.98 words/s - MLM-Limbum:  4.6625 || MLM-Ngiemboon:  5.6794 || MLM-Limbum-Ngiemboon:  4.6977 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:12:16 - 0:17:44 -     385 -    8.70 sent/s - 19688.97 words/s - MLM-Limbum:  4.6707 || MLM-Ngiemboon:  5.6169 || MLM-Limbum-Ngiemboon:  5.0993 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:12:30 - 0:17:58 -     390 -    8.68 sent/s - 19905.52 words/s - MLM-Limbum:  4.6525 || MLM-Ngiemboon:  5.3300 || MLM-Limbum-Ngiemboon:  4.8026 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:12:35 - 0:18:03 - Creating new training data iterator (pred,Limbum) ...\n",
      "INFO - 05/20/20 10:12:43 - 0:18:12 -     395 -    8.63 sent/s - 20039.12 words/s - MLM-Limbum:  4.5237 || MLM-Ngiemboon:  5.6817 || MLM-Limbum-Ngiemboon:  5.1802 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:12:57 - 0:18:25 -     400 -    8.72 sent/s - 20516.55 words/s - MLM-Limbum:  4.6460 || MLM-Ngiemboon:  5.2060 || MLM-Limbum-Ngiemboon:  4.9301 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:13:11 - 0:18:39 -     405 -    8.54 sent/s - 20344.85 words/s - MLM-Limbum:  4.5495 || MLM-Ngiemboon:  5.7703 || MLM-Limbum-Ngiemboon:  5.0291 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:13:25 - 0:18:53 -     410 -    8.82 sent/s - 21263.35 words/s - MLM-Limbum:  4.7312 || MLM-Ngiemboon:  5.4259 || MLM-Limbum-Ngiemboon:  4.7903 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:13:38 - 0:19:07 -     415 -    8.86 sent/s - 21613.50 words/s - MLM-Limbum:  4.6689 || MLM-Ngiemboon:  5.6428 || MLM-Limbum-Ngiemboon:  4.8266 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:13:52 - 0:19:20 -     420 -    8.73 sent/s - 21556.90 words/s - MLM-Limbum:  4.6215 || MLM-Ngiemboon:  5.6480 || MLM-Limbum-Ngiemboon:  4.9056 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:14:06 - 0:19:34 -     425 -    8.59 sent/s - 21465.64 words/s - MLM-Limbum:  4.5071 || MLM-Ngiemboon:  5.6421 || MLM-Limbum-Ngiemboon:  5.1575 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:14:20 - 0:19:48 -     430 -    8.76 sent/s - 22142.96 words/s - MLM-Limbum:  4.6593 || MLM-Ngiemboon:  5.6362 || MLM-Limbum-Ngiemboon:  4.8473 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:14:34 - 0:20:02 -     435 -    8.36 sent/s - 21579.67 words/s - MLM-Limbum:  4.7223 || MLM-Ngiemboon:  5.5789 || MLM-Limbum-Ngiemboon:  4.8784 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:14:48 - 0:20:16 -     440 -    8.62 sent/s - 22318.83 words/s - MLM-Limbum:  4.6439 || MLM-Ngiemboon:  5.7104 || MLM-Limbum-Ngiemboon:  4.8431 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:15:02 - 0:20:30 -     445 -    8.63 sent/s - 22605.34 words/s - MLM-Limbum:  4.5993 || MLM-Ngiemboon:  5.6102 || MLM-Limbum-Ngiemboon:  4.9118 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:15:03 - 0:20:31 - Creating new training data iterator (pred,Ngiemboon) ...\n",
      "INFO - 05/20/20 10:15:16 - 0:20:44 -     450 -    8.52 sent/s - 22549.76 words/s - MLM-Limbum:  4.8250 || MLM-Ngiemboon:  5.5883 || MLM-Limbum-Ngiemboon:  5.0665 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:15:30 - 0:20:58 -     455 -    8.76 sent/s - 23469.52 words/s - MLM-Limbum:  4.5920 || MLM-Ngiemboon:  5.6275 || MLM-Limbum-Ngiemboon:  5.1058 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:15:43 - 0:21:12 -     460 -    8.79 sent/s - 23804.92 words/s - MLM-Limbum:  4.5817 || MLM-Ngiemboon:  5.5298 || MLM-Limbum-Ngiemboon:  4.9575 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:15:57 - 0:21:26 -     465 -    8.57 sent/s - 23435.94 words/s - MLM-Limbum:  4.6321 || MLM-Ngiemboon:  5.6423 || MLM-Limbum-Ngiemboon:  5.0901 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:16:11 - 0:21:39 -     470 -    8.76 sent/s - 24231.10 words/s - MLM-Limbum:  4.6132 || MLM-Ngiemboon:  5.6607 || MLM-Limbum-Ngiemboon:  4.8792 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:16:25 - 0:21:53 -     475 -    8.67 sent/s - 24228.16 words/s - MLM-Limbum:  4.5747 || MLM-Ngiemboon:  5.5080 || MLM-Limbum-Ngiemboon:  4.7138 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:16:39 - 0:22:07 -     480 -    8.53 sent/s - 24094.92 words/s - MLM-Limbum:  4.6469 || MLM-Ngiemboon:  5.5521 || MLM-Limbum-Ngiemboon:  5.1482 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:16:53 - 0:22:21 -     485 -    8.44 sent/s - 24096.76 words/s - MLM-Limbum:  4.5472 || MLM-Ngiemboon:  5.6622 || MLM-Limbum-Ngiemboon:  5.1106 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:17:07 - 0:22:35 -     490 -    8.95 sent/s - 25803.31 words/s - MLM-Limbum:  4.5938 || MLM-Ngiemboon:  5.5975 || MLM-Limbum-Ngiemboon:  5.0763 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:17:20 - 0:22:48 -     495 -    8.77 sent/s - 25534.50 words/s - MLM-Limbum:  4.6516 || MLM-Ngiemboon:  5.6033 || MLM-Limbum-Ngiemboon:  4.8466 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:17:34 - 0:23:02 -     500 -    8.63 sent/s - 25405.49 words/s - MLM-Limbum:  4.6582 || MLM-Ngiemboon:  5.4873 || MLM-Limbum-Ngiemboon:  5.0510 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:17:48 - 0:23:16 -     505 -    8.85 sent/s - 26288.42 words/s - MLM-Limbum:  4.6584 || MLM-Ngiemboon:  5.5200 || MLM-Limbum-Ngiemboon:  5.2744 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:18:02 - 0:23:30 -     510 -    8.66 sent/s - 25984.52 words/s - MLM-Limbum:  4.5530 || MLM-Ngiemboon:  5.4330 || MLM-Limbum-Ngiemboon:  5.0264 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:18:16 - 0:23:44 -     515 -    8.28 sent/s - 25326.40 words/s - MLM-Limbum:  4.6586 || MLM-Ngiemboon:  5.5730 || MLM-Limbum-Ngiemboon:  4.9409 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:18:30 - 0:23:58 -     520 -    8.70 sent/s - 26653.01 words/s - MLM-Limbum:  4.5735 || MLM-Ngiemboon:  5.6762 || MLM-Limbum-Ngiemboon:  4.9964 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:18:36 - 0:24:04 - Creating new training data iterator (pred,Limbum) ...\n",
      "INFO - 05/20/20 10:18:43 - 0:24:12 -     525 -    8.70 sent/s - 26896.82 words/s - MLM-Limbum:  4.5489 || MLM-Ngiemboon:  5.7531 || MLM-Limbum-Ngiemboon:  4.9614 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:18:52 - 0:24:20 - ============ End of epoch 1 ============\n",
      "INFO - 05/20/20 10:18:56 - 0:24:25 - epoch -> 1.000000\n",
      "INFO - 05/20/20 10:18:56 - 0:24:25 - valid_Limbum_mlm_ppl -> 144.156992\n",
      "INFO - 05/20/20 10:18:56 - 0:24:25 - valid_Limbum_mlm_acc -> 9.326425\n",
      "INFO - 05/20/20 10:18:56 - 0:24:25 - valid_Ngiemboon_mlm_ppl -> 357.494901\n",
      "INFO - 05/20/20 10:18:56 - 0:24:25 - valid_Ngiemboon_mlm_acc -> 10.103627\n",
      "INFO - 05/20/20 10:18:56 - 0:24:25 - valid_Limbum_Ngiemboon_mlm_ppl -> 196.945856\n",
      "INFO - 05/20/20 10:18:56 - 0:24:25 - valid_Limbum_Ngiemboon_mlm_acc -> 10.913140\n",
      "INFO - 05/20/20 10:18:56 - 0:24:25 - valid_mlm_ppl -> 250.825946\n",
      "INFO - 05/20/20 10:18:56 - 0:24:25 - valid_mlm_acc -> 9.715026\n",
      "INFO - 05/20/20 10:18:56 - 0:24:25 - test_Limbum_mlm_ppl -> 145.431200\n",
      "INFO - 05/20/20 10:18:56 - 0:24:25 - test_Limbum_mlm_acc -> 7.253886\n",
      "INFO - 05/20/20 10:18:56 - 0:24:25 - test_Ngiemboon_mlm_ppl -> 335.601247\n",
      "INFO - 05/20/20 10:18:56 - 0:24:25 - test_Ngiemboon_mlm_acc -> 15.025907\n",
      "INFO - 05/20/20 10:18:56 - 0:24:25 - test_Limbum_Ngiemboon_mlm_ppl -> 200.866478\n",
      "INFO - 05/20/20 10:18:56 - 0:24:25 - test_Limbum_Ngiemboon_mlm_acc -> 11.791383\n",
      "INFO - 05/20/20 10:18:56 - 0:24:25 - test_mlm_ppl -> 240.516224\n",
      "INFO - 05/20/20 10:18:56 - 0:24:25 - test_mlm_acc -> 11.139896\n",
      "INFO - 05/20/20 10:18:56 - 0:24:25 - __log__:{\"epoch\": 1, \"valid_Limbum_mlm_ppl\": 144.15699206905546, \"valid_Limbum_mlm_acc\": 9.32642487046632, \"valid_Ngiemboon_mlm_ppl\": 357.4949007849248, \"valid_Ngiemboon_mlm_acc\": 10.103626943005182, \"valid_Limbum_Ngiemboon_mlm_ppl\": 196.9458555288999, \"valid_Limbum_Ngiemboon_mlm_acc\": 10.913140311804009, \"valid_mlm_ppl\": 250.82594642699013, \"valid_mlm_acc\": 9.71502590673575, \"test_Limbum_mlm_ppl\": 145.43120034797397, \"test_Limbum_mlm_acc\": 7.253886010362694, \"test_Ngiemboon_mlm_ppl\": 335.60124736728204, \"test_Ngiemboon_mlm_acc\": 15.025906735751295, \"test_Limbum_Ngiemboon_mlm_ppl\": 200.8664778611272, \"test_Limbum_Ngiemboon_mlm_acc\": 11.791383219954648, \"test_mlm_ppl\": 240.516223857628, \"test_mlm_acc\": 11.139896373056995}\n",
      "INFO - 05/20/20 10:18:56 - 0:24:25 - New best score for valid_mlm_ppl: 250.825946\n",
      "INFO - 05/20/20 10:18:56 - 0:24:25 - Saving best-valid_mlm_ppl to /home/jupyter/models/africa/cluster3/mlm_tlm_LimbumNgiemboon/maml/best-valid_mlm_ppl.pth ...\n",
      "WARNING - 05/20/20 10:18:56 - 0:24:25 - Saving model parameters ...\n",
      "INFO - 05/20/20 10:18:57 - 0:24:25 - New best validation score: 250.825946\n",
      "INFO - 05/20/20 10:18:57 - 0:24:25 - Saving checkpoint to /home/jupyter/models/africa/cluster3/mlm_tlm_LimbumNgiemboon/maml/checkpoint.pth ...\n",
      "WARNING - 05/20/20 10:18:57 - 0:24:25 - Saving model parameters ...\n",
      "WARNING - 05/20/20 10:18:57 - 0:24:25 - Saving model optimizer ...\n",
      "INFO - 05/20/20 10:19:05 - 0:24:33 - ============ garbage collector collecting 0 ...\n",
      "INFO - 05/20/20 10:19:05 - 0:24:33 - ============ Starting epoch 2 ... ============\n",
      "INFO - 05/20/20 10:19:11 - 0:24:39 -     530 -    4.43 sent/s - 13839.77 words/s - MLM-Limbum:  4.6714 || MLM-Ngiemboon:  5.4480 || MLM-Limbum-Ngiemboon:  4.9103 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:19:24 - 0:24:52 -     535 -    9.07 sent/s - 28576.81 words/s - MLM-Limbum:  4.4906 || MLM-Ngiemboon:  5.5258 || MLM-Limbum-Ngiemboon:  4.9823 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:19:34 - 0:25:03 -     540 -   11.27 sent/s - 35834.81 words/s - MLM-Limbum:  4.5412 || MLM-Ngiemboon:  5.7936 || MLM-Limbum-Ngiemboon:  5.1076 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:19:49 - 0:25:17 -     545 -    8.47 sent/s - 27180.41 words/s - MLM-Limbum:  4.5301 || MLM-Ngiemboon:  5.4028 || MLM-Limbum-Ngiemboon:  5.0143 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:20:02 - 0:25:30 -     550 -    8.94 sent/s - 28930.84 words/s - MLM-Limbum:  4.6702 || MLM-Ngiemboon:  5.7748 || MLM-Limbum-Ngiemboon:  4.6478 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:20:03 - 0:25:31 - Creating new training data iterator (pred,Ngiemboon) ...\n",
      "INFO - 05/20/20 10:20:16 - 0:25:44 -     555 -    8.66 sent/s - 28292.46 words/s - MLM-Limbum:  4.5688 || MLM-Ngiemboon:  5.6635 || MLM-Limbum-Ngiemboon:  4.7612 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:20:29 - 0:25:58 -     560 -    8.87 sent/s - 29235.65 words/s - MLM-Limbum:  4.7093 || MLM-Ngiemboon:  5.6717 || MLM-Limbum-Ngiemboon:  4.9447 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:20:43 - 0:26:11 -     565 -    8.84 sent/s - 29390.52 words/s - MLM-Limbum:  4.5862 || MLM-Ngiemboon:  5.5958 || MLM-Limbum-Ngiemboon:  4.8532 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:20:57 - 0:26:25 -     570 -    8.78 sent/s - 29447.32 words/s - MLM-Limbum:  4.5765 || MLM-Ngiemboon:  5.6615 || MLM-Limbum-Ngiemboon:  4.9637 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:21:10 - 0:26:38 -     575 -    9.19 sent/s - 31088.14 words/s - MLM-Limbum:  4.6546 || MLM-Ngiemboon:  5.5293 || MLM-Limbum-Ngiemboon:  5.0122 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:21:19 - 0:26:47 -     580 -   13.24 sent/s - 45189.09 words/s - MLM-Limbum:  4.6373 || MLM-Ngiemboon:  5.5778 || MLM-Limbum-Ngiemboon:  4.9984 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:21:33 - 0:27:01 -     585 -    8.67 sent/s - 29858.61 words/s - MLM-Limbum:  4.4797 || MLM-Ngiemboon:  5.5834 || MLM-Limbum-Ngiemboon:  5.0365 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:21:47 - 0:27:15 -     590 -    8.40 sent/s - 29186.18 words/s - MLM-Limbum:  4.6023 || MLM-Ngiemboon:  5.4942 || MLM-Limbum-Ngiemboon:  5.1449 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:22:00 - 0:27:29 -     595 -    8.88 sent/s - 31114.31 words/s - MLM-Limbum:  4.5117 || MLM-Ngiemboon:  5.5433 || MLM-Limbum-Ngiemboon:  4.9025 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:22:14 - 0:27:42 -     600 -    8.79 sent/s - 31044.21 words/s - MLM-Limbum:  4.6436 || MLM-Ngiemboon:  5.7410 || MLM-Limbum-Ngiemboon:  5.1424 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:22:28 - 0:27:56 -     605 -    8.52 sent/s - 30371.98 words/s - MLM-Limbum:  4.4866 || MLM-Ngiemboon:  5.3895 || MLM-Limbum-Ngiemboon:  5.0479 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:22:42 - 0:28:10 -     610 -    8.55 sent/s - 30725.11 words/s - MLM-Limbum:  4.5976 || MLM-Ngiemboon:  5.6911 || MLM-Limbum-Ngiemboon:  5.0148 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:22:56 - 0:28:24 -     615 -    8.59 sent/s - 31122.90 words/s - MLM-Limbum:  4.6688 || MLM-Ngiemboon:  5.5566 || MLM-Limbum-Ngiemboon:  4.8142 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:23:10 - 0:28:38 -     620 -    8.83 sent/s - 32229.37 words/s - MLM-Limbum:  4.5074 || MLM-Ngiemboon:  5.6412 || MLM-Limbum-Ngiemboon:  4.7342 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:23:23 - 0:28:51 -     625 -    8.90 sent/s - 32730.25 words/s - MLM-Limbum:  4.7175 || MLM-Ngiemboon:  5.6673 || MLM-Limbum-Ngiemboon:  4.8637 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:23:37 - 0:29:05 -     630 -    8.69 sent/s - 32231.76 words/s - MLM-Limbum:  4.6241 || MLM-Ngiemboon:  5.4814 || MLM-Limbum-Ngiemboon:  4.7018 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:23:51 - 0:29:19 -     635 -    8.69 sent/s - 32486.34 words/s - MLM-Limbum:  4.6539 || MLM-Ngiemboon:  5.6352 || MLM-Limbum-Ngiemboon:  4.9001 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:24:05 - 0:29:33 -     640 -    8.73 sent/s - 32891.07 words/s - MLM-Limbum:  4.4814 || MLM-Ngiemboon:  5.5461 || MLM-Limbum-Ngiemboon:  4.8367 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:24:18 - 0:29:46 -     645 -    8.82 sent/s - 33493.50 words/s - MLM-Limbum:  4.7917 || MLM-Ngiemboon:  5.5134 || MLM-Limbum-Ngiemboon:  5.0449 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:24:26 - 0:29:55 - Creating new training data iterator (pred,Ngiemboon) ...\n",
      "INFO - 05/20/20 10:24:32 - 0:30:00 -     650 -    8.62 sent/s - 32998.36 words/s - MLM-Limbum:  4.6174 || MLM-Ngiemboon:  5.5577 || MLM-Limbum-Ngiemboon:  4.9836 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:24:46 - 0:30:14 -     655 -    8.67 sent/s - 33440.71 words/s - MLM-Limbum:  4.5831 || MLM-Ngiemboon:  5.5594 || MLM-Limbum-Ngiemboon:  4.9127 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:24:59 - 0:30:28 -     660 -    8.94 sent/s - 34743.55 words/s - MLM-Limbum:  4.5663 || MLM-Ngiemboon:  5.5947 || MLM-Limbum-Ngiemboon:  4.8701 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:25:13 - 0:30:41 -     665 -    8.71 sent/s - 34080.03 words/s - MLM-Limbum:  4.5746 || MLM-Ngiemboon:  5.6875 || MLM-Limbum-Ngiemboon:  4.9586 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:25:27 - 0:30:55 -     670 -    8.68 sent/s - 34248.28 words/s - MLM-Limbum:  4.5298 || MLM-Ngiemboon:  5.4940 || MLM-Limbum-Ngiemboon:  4.9846 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:25:39 - 0:31:08 - Creating new training data iterator (pred,Limbum) ...\n",
      "INFO - 05/20/20 10:25:41 - 0:31:09 -     675 -    8.48 sent/s - 33712.84 words/s - MLM-Limbum:  4.5418 || MLM-Ngiemboon:  5.6408 || MLM-Limbum-Ngiemboon:  4.9312 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:25:55 - 0:31:23 -     680 -    8.90 sent/s - 35611.06 words/s - MLM-Limbum:  4.4602 || MLM-Ngiemboon:  5.5617 || MLM-Limbum-Ngiemboon:  4.7445 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:26:08 - 0:31:36 -     685 -    8.86 sent/s - 35701.98 words/s - MLM-Limbum:  4.6895 || MLM-Ngiemboon:  5.5222 || MLM-Limbum-Ngiemboon:  5.0969 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:26:22 - 0:31:50 -     690 -    8.76 sent/s - 35549.27 words/s - MLM-Limbum:  4.7560 || MLM-Ngiemboon:  5.5594 || MLM-Limbum-Ngiemboon:  4.9565 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:26:36 - 0:32:04 -     695 -    8.66 sent/s - 35431.18 words/s - MLM-Limbum:  4.5824 || MLM-Ngiemboon:  5.6004 || MLM-Limbum-Ngiemboon:  4.8889 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:26:50 - 0:32:18 -     700 -    8.67 sent/s - 35706.56 words/s - MLM-Limbum:  4.5409 || MLM-Ngiemboon:  5.6379 || MLM-Limbum-Ngiemboon:  4.8015 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:27:03 - 0:32:32 -     705 -    8.68 sent/s - 36017.27 words/s - MLM-Limbum:  4.7269 || MLM-Ngiemboon:  5.6634 || MLM-Limbum-Ngiemboon:  5.2470 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:27:18 - 0:32:46 -     710 -    8.47 sent/s - 35407.52 words/s - MLM-Limbum:  4.6052 || MLM-Ngiemboon:  5.6048 || MLM-Limbum-Ngiemboon:  5.0543 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:27:31 - 0:33:00 -     715 -    8.66 sent/s - 36435.57 words/s - MLM-Limbum:  4.6545 || MLM-Ngiemboon:  5.4557 || MLM-Limbum-Ngiemboon:  5.1716 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:27:45 - 0:33:13 -     720 -    8.76 sent/s - 37120.83 words/s - MLM-Limbum:  4.5634 || MLM-Ngiemboon:  5.4462 || MLM-Limbum-Ngiemboon:  5.2467 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:27:59 - 0:33:28 -     725 -    8.29 sent/s - 35689.96 words/s - MLM-Limbum:  4.6341 || MLM-Ngiemboon:  5.6789 || MLM-Limbum-Ngiemboon:  4.9334 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:28:13 - 0:33:42 -     730 -    8.62 sent/s - 37062.80 words/s - MLM-Limbum:  4.5867 || MLM-Ngiemboon:  5.5902 || MLM-Limbum-Ngiemboon:  4.7403 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:28:27 - 0:33:55 -     735 -    8.79 sent/s - 38051.38 words/s - MLM-Limbum:  4.5501 || MLM-Ngiemboon:  5.4931 || MLM-Limbum-Ngiemboon:  5.0332 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:28:41 - 0:34:09 -     740 -    8.66 sent/s - 37735.87 words/s - MLM-Limbum:  4.6784 || MLM-Ngiemboon:  5.6120 || MLM-Limbum-Ngiemboon:  4.8310 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:28:55 - 0:34:23 -     745 -    8.63 sent/s - 37841.80 words/s - MLM-Limbum:  4.6741 || MLM-Ngiemboon:  5.5179 || MLM-Limbum-Ngiemboon:  4.7008 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:29:08 - 0:34:37 -     750 -    8.76 sent/s - 38689.75 words/s - MLM-Limbum:  4.6928 || MLM-Ngiemboon:  5.6591 || MLM-Limbum-Ngiemboon:  4.9806 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:29:22 - 0:34:51 -     755 -    8.64 sent/s - 38411.61 words/s - MLM-Limbum:  4.6340 || MLM-Ngiemboon:  5.5560 || MLM-Limbum-Ngiemboon:  4.8839 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:29:22 - 0:34:51 - Creating new training data iterator (pred,Ngiemboon) ...\n",
      "INFO - 05/20/20 10:29:36 - 0:35:05 -     760 -    8.60 sent/s - 38478.81 words/s - MLM-Limbum:  4.4454 || MLM-Ngiemboon:  5.4877 || MLM-Limbum-Ngiemboon:  4.8359 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:29:50 - 0:35:18 -     765 -    8.68 sent/s - 39049.23 words/s - MLM-Limbum:  4.6268 || MLM-Ngiemboon:  5.6479 || MLM-Limbum-Ngiemboon:  5.1023 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:30:04 - 0:35:32 -     770 -    8.61 sent/s - 39001.39 words/s - MLM-Limbum:  4.5278 || MLM-Ngiemboon:  5.4342 || MLM-Limbum-Ngiemboon:  4.9990 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:30:18 - 0:35:46 -     775 -    8.80 sent/s - 40105.50 words/s - MLM-Limbum:  4.5718 || MLM-Ngiemboon:  5.5907 || MLM-Limbum-Ngiemboon:  4.9325 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:30:31 - 0:36:00 -     780 -    8.84 sent/s - 40548.56 words/s - MLM-Limbum:  4.5171 || MLM-Ngiemboon:  5.6158 || MLM-Limbum-Ngiemboon:  4.6300 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:30:45 - 0:36:13 -     785 -    8.80 sent/s - 40654.09 words/s - MLM-Limbum:  4.6399 || MLM-Ngiemboon:  5.4636 || MLM-Limbum-Ngiemboon:  4.7739 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:30:47 - 0:36:15 - Creating new training data iterator (pred,Limbum,Ngiemboon) ...\n",
      "INFO - 05/20/20 10:30:59 - 0:36:27 -     790 -    8.56 sent/s - 39758.77 words/s - MLM-Limbum:  4.4728 || MLM-Ngiemboon:  5.6602 || MLM-Limbum-Ngiemboon:  5.0256 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:31:04 - 0:36:33 - ============ End of epoch 2 ============\n",
      "INFO - 05/20/20 10:31:09 - 0:36:37 - epoch -> 2.000000\n",
      "INFO - 05/20/20 10:31:09 - 0:36:37 - valid_Limbum_mlm_ppl -> 138.745882\n",
      "INFO - 05/20/20 10:31:09 - 0:36:37 - valid_Limbum_mlm_acc -> 3.108808\n",
      "INFO - 05/20/20 10:31:09 - 0:36:37 - valid_Ngiemboon_mlm_ppl -> 358.025440\n",
      "INFO - 05/20/20 10:31:09 - 0:36:37 - valid_Ngiemboon_mlm_acc -> 9.326425\n",
      "INFO - 05/20/20 10:31:09 - 0:36:37 - valid_Limbum_Ngiemboon_mlm_ppl -> 172.896808\n",
      "INFO - 05/20/20 10:31:09 - 0:36:37 - valid_Limbum_Ngiemboon_mlm_acc -> 14.253898\n",
      "INFO - 05/20/20 10:31:09 - 0:36:37 - valid_mlm_ppl -> 248.385661\n",
      "INFO - 05/20/20 10:31:09 - 0:36:37 - valid_mlm_acc -> 6.217617\n",
      "INFO - 05/20/20 10:31:09 - 0:36:37 - test_Limbum_mlm_ppl -> 149.492862\n",
      "INFO - 05/20/20 10:31:09 - 0:36:37 - test_Limbum_mlm_acc -> 3.626943\n",
      "INFO - 05/20/20 10:31:09 - 0:36:37 - test_Ngiemboon_mlm_ppl -> 330.408820\n",
      "INFO - 05/20/20 10:31:09 - 0:36:37 - test_Ngiemboon_mlm_acc -> 16.839378\n",
      "INFO - 05/20/20 10:31:09 - 0:36:37 - test_Limbum_Ngiemboon_mlm_ppl -> 185.694571\n",
      "INFO - 05/20/20 10:31:09 - 0:36:37 - test_Limbum_Ngiemboon_mlm_acc -> 14.965986\n",
      "INFO - 05/20/20 10:31:09 - 0:36:37 - test_mlm_ppl -> 239.950841\n",
      "INFO - 05/20/20 10:31:09 - 0:36:37 - test_mlm_acc -> 10.233161\n",
      "INFO - 05/20/20 10:31:09 - 0:36:37 - __log__:{\"epoch\": 2, \"valid_Limbum_mlm_ppl\": 138.74588169921694, \"valid_Limbum_mlm_acc\": 3.1088082901554404, \"valid_Ngiemboon_mlm_ppl\": 358.025439796855, \"valid_Ngiemboon_mlm_acc\": 9.32642487046632, \"valid_Limbum_Ngiemboon_mlm_ppl\": 172.8968079131483, \"valid_Limbum_Ngiemboon_mlm_acc\": 14.25389755011136, \"valid_mlm_ppl\": 248.38566074803595, \"valid_mlm_acc\": 6.217616580310881, \"test_Limbum_mlm_ppl\": 149.49286223932708, \"test_Limbum_mlm_acc\": 3.626943005181347, \"test_Ngiemboon_mlm_ppl\": 330.408819783335, \"test_Ngiemboon_mlm_acc\": 16.83937823834197, \"test_Limbum_Ngiemboon_mlm_ppl\": 185.6945707536151, \"test_Limbum_Ngiemboon_mlm_acc\": 14.965986394557824, \"test_mlm_ppl\": 239.95084101133102, \"test_mlm_acc\": 10.233160621761657}\n",
      "INFO - 05/20/20 10:31:09 - 0:36:37 - New best score for valid_mlm_ppl: 248.385661\n",
      "INFO - 05/20/20 10:31:09 - 0:36:37 - Saving best-valid_mlm_ppl to /home/jupyter/models/africa/cluster3/mlm_tlm_LimbumNgiemboon/maml/best-valid_mlm_ppl.pth ...\n",
      "WARNING - 05/20/20 10:31:09 - 0:36:37 - Saving model parameters ...\n",
      "INFO - 05/20/20 10:31:10 - 0:36:38 - New best validation score: 248.385661\n",
      "INFO - 05/20/20 10:31:10 - 0:36:38 - Saving checkpoint to /home/jupyter/models/africa/cluster3/mlm_tlm_LimbumNgiemboon/maml/checkpoint.pth ...\n",
      "WARNING - 05/20/20 10:31:10 - 0:36:38 - Saving model parameters ...\n",
      "WARNING - 05/20/20 10:31:10 - 0:36:38 - Saving model optimizer ...\n",
      "INFO - 05/20/20 10:31:18 - 0:36:46 - ============ garbage collector collecting 0 ...\n",
      "INFO - 05/20/20 10:31:18 - 0:36:46 - ============ Starting epoch 3 ... ============\n",
      "INFO - 05/20/20 10:31:26 - 0:36:54 -     795 -    4.51 sent/s - 21097.38 words/s - MLM-Limbum:  4.6339 || MLM-Ngiemboon:  5.7025 || MLM-Limbum-Ngiemboon:  4.8033 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:31:38 - 0:37:06 -     800 -    9.70 sent/s - 45642.50 words/s - MLM-Limbum:  4.6343 || MLM-Ngiemboon:  5.7614 || MLM-Limbum-Ngiemboon:  4.8557 -  - model LR: 1.0000e-04\n",
      "INFO - 05/20/20 10:31:46 - 0:37:14 - Creating new training data iterator (pred,Limbum) ...\n",
      "INFO - 05/20/20 10:31:49 - 0:37:17 -     805 -   11.04 sent/s - 52274.95 words/s - MLM-Limbum:  4.5796 || MLM-Ngiemboon:  5.6821 || MLM-Limbum-Ngiemboon:  5.1316 -  - model LR: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "%env mlm_steps=Limbum,Ngiemboon,Limbum-Ngiemboon\n",
    "%env batch_size=8\n",
    "%env max_epoch=100\n",
    "%env dump_path=/home/jupyter/models/africa/cluster3\n",
    "! python train.py --exp_name mlm_tlm_LimbumNgiemboon --exp_id $exp_id --dump_path $dump_path --data_path $OUTPATH --lgs $lgs --clm_steps '' --mlm_steps $mlm_steps --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout 0.1 --attention_dropout 0.1 --gelu_activation true --batch_size $batch_size --bptt 256 --optimizer adam,lr=0.0001 --epoch_size $epoch_size --max_epoch $max_epoch --validation_metrics _valid_mlm_ppl --stopping_criterion $stopping_criterion --eval_bleu $eval_bleu --remove_long_sentences_train $remove_long_sentences_train --remove_long_sentences_valid $remove_long_sentences_valid --remove_long_sentences_test $remove_long_sentences_test --train_n_samples $train_n_samples --valid_n_samples $valid_n_samples --test_n_samples $test_n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rsync -av --progress /content/meta_XLM/XLM/dumped/mlm_tlm_BafiaBulu  /content/drive/\"My Drive\"/African_Translator/models/africa/cluster1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aH0YCR7PAESk"
   },
   "source": [
    "**Train a (unsupervised/supervised) MT from a pretrained meta-model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 892,
     "status": "ok",
     "timestamp": 1589811056244,
     "user": {
      "displayName": "Pascal Tikeng",
      "photoUrl": "",
      "userId": "15074930698580545771"
     },
     "user_tz": -120
    },
    "id": "KHicypbkAopS",
    "outputId": "e05a7a2a-faa9-4c44-a111-27b5dea619b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: epoch_size=6360\n",
      "env: lgs=Bafia-Bulu\n"
     ]
    }
   ],
   "source": [
    "%env epoch_size=6360\n",
    "%env lgs=Bafia-Bulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5698,
     "status": "ok",
     "timestamp": 1589811063934,
     "user": {
      "displayName": "Pascal Tikeng",
      "photoUrl": "",
      "userId": "15074930698580545771"
     },
     "user_tz": -120
    },
    "id": "2ms98EL7Ak6y",
    "outputId": "15cffce9-2bbc-44b0-e47e-2501ec99f983"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: train_n_samples=-1\n",
      "env: valid_n_samples=-1\n",
      "env: test_n_samples=-1\n",
      "env: eval_bleu=true\n"
     ]
    }
   ],
   "source": [
    "# limit the number of examples (-1 by default for non limitation)\n",
    "%env train_n_samples=-1\n",
    "%env valid_n_samples=-1\n",
    "%env test_n_samples=-1\n",
    "#--train_n_samples $train_n_samples --valid_n_samples $valid_n_samples --test_n_samples $test_n_samples\n",
    "\n",
    "%env eval_bleu=true\n",
    "! chmod +x src/evaluation/multi-bleu.perl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1179,
     "status": "ok",
     "timestamp": 1589811188557,
     "user": {
      "displayName": "Pascal Tikeng",
      "photoUrl": "",
      "userId": "15074930698580545771"
     },
     "user_tz": -120
    },
    "id": "YfA23sjzAj7U",
    "outputId": "4828f016-e6f1-4b71-e437-fe13f189c50c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: stopping_criterion=valid_mt_bleu,10\n",
      "env: validation_metrics=valid_mt_bleu\n",
      "env: reload_model=dumped/mlm_tlm_BafiaBulu/maml/best-valid_mlm_ppl.pth,dumped/mlm_tlm_BafiaBulu/maml/best-valid_mlm_ppl.pth\n",
      "env: ae_steps=Bafia,Bulu\n",
      "env: bt_steps=Bafia-Bulu-Bafia,Bulu-Bafia-Bulu\n"
     ]
    }
   ],
   "source": [
    "%env stopping_criterion=valid_mt_bleu,10\n",
    "%env validation_metrics=valid_mt_bleu\n",
    "%env reload_model=dumped/mlm_tlm_BafiaBulu/maml/best-valid_mlm_ppl.pth,dumped/mlm_tlm_BafiaBulu/maml/best-valid_mlm_ppl.pth\n",
    "%env ae_steps=Bafia,Bulu\n",
    "%env bt_steps=Bafia-Bulu-Bafia,Bulu-Bafia-Bulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env train_n_samples=-1\n",
    "%env valid_n_samples=-1\n",
    "%env test_n_samples=-1\n",
    "\n",
    "%env max_epoch=100\n",
    "\n",
    "# unsupervised MT\n",
    "! python train.py --exp_name UnSupMT_BafiaBulu --exp_id $exp_id --dump_path ./dumped/ --reload_model $reload_model --data_path $OUTPATH --lgs $lgs --ae_steps $ae_steps --bt_steps $bt_steps --word_shuffle 3 --word_dropout 0.1 --word_blank 0.1 --lambda_ae '0:1,100000:0.1,300000:0' --encoder_only false --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout 0.1 --attention_dropout 0.1 --gelu_activation true --tokens_per_batch 2000 --batch_size $batch_size --bptt 256 --optimizer adam_inverse_sqrt,beta1=0.9,beta2=0.98,lr=0.0001 --epoch_size $epoch_size --max_epoch $max_epoch --eval_bleu $eval_bleu --stopping_criterion $stopping_criterion --validation_metrics $validation_metrics --train_n_samples $train_n_samples --valid_n_samples $valid_n_samples --test_n_samples $test_n_samples --remove_long_sentences_train $remove_long_sentences_train --remove_long_sentences_valid $remove_long_sentences_valid --remove_long_sentences_test $remove_long_sentences_test    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qL4MlHgsIo4R"
   },
   "outputs": [],
   "source": [
    "#! rsync -av --progress /content/meta_XLM/XLM/dumped/mlm_tlm_BafiaBulu  /content/drive/\"My Drive\"/African_Translator/models/africa/cluster1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env train_n_samples=-1\n",
    "%env valid_n_samples=-1\n",
    "%env test_n_samples=-1\n",
    "\n",
    "%env max_epoch=100\n",
    "%env batch_size=1\n",
    "# supervised MT\n",
    "%env mt_steps=Bafia-Bulu,Bulu-Bafia          \n",
    "! python train.py --exp_name MT_BafiaBulu --exp_id $exp_id  --dump_path ./dumped/ --reload_model $reload_model --data_path $OUTPATH --lgs $lgs --ae_steps $ae_steps --mt_steps $mt_steps --bt_steps $bt_steps --word_shuffle 3 --word_dropout 0.1 --word_blank 0.1 --lambda_ae '0:1,100000:0.1,300000:0' --encoder_only false --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout 0.1 --attention_dropout 0.1 --gelu_activation true --tokens_per_batch 2000 --batch_size $batch_size --bptt 256 --optimizer adam_inverse_sqrt,beta1=0.9,beta2=0.98,lr=0.0001 --epoch_size $epoch_size --max_epoch $max_epoch --eval_bleu $eval_bleu --stopping_criterion $stopping_criterion --validation_metrics $validation_metrics --train_n_samples $train_n_samples --valid_n_samples $valid_n_samples --test_n_samples $test_n_samples --remove_long_sentences_train $remove_long_sentences_train --remove_long_sentences_valid $remove_long_sentences_valid --remove_long_sentences_test $remove_long_sentences_test    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0KOUuN4Irt4"
   },
   "outputs": [],
   "source": [
    "#! rsync -av --progress /content/meta_XLM/XLM/dumped/mlm_tlm_BafiaBulu  /content/drive/\"My Drive\"/African_Translator/models/africa/cluster1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWVXFKOuMNw6"
   },
   "outputs": [],
   "source": [
    "d=[]\n",
    "while(1):\n",
    "  d.append(d)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMtOrPD/+LoOAI+NDcKA4Iw",
   "collapsed_sections": [],
   "name": "XLM_Bafia_Bulu.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
