{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(bookmark:HOME) -> /home/jupyter/meta_XLM/XLM\n",
      "/home/jupyter/meta_XLM/XLM\n"
     ]
    }
   ],
   "source": [
    "%bookmark HOME \"/home/jupyter/meta_XLM/XLM\" \n",
    "%cd -b HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: languages=Guidar,Guiziga\n",
      "Guid-Guiz:-1\n",
      "Guidar - Guiziga\n",
      "======= Read 7950 totals samples\n",
      "======= Delete 35 samples\n",
      "======= Save 7915 samples\n",
      "Guiziga\n",
      "======= Read 31297 totals samples\n",
      "======= Delete 213 samples\n",
      "======= Save 31084 samples\n",
      "Guidar - Guiziga\n",
      "======= Read 7950 totals samples\n",
      "======= Delete 35 samples\n",
      "======= Save 7915 samples\n",
      "Guiziga\n",
      "======= Read 31297 totals samples\n",
      "======= Delete 213 samples\n",
      "======= Save 31084 samples\n",
      "params ok !\n",
      "*** Cleaning and tokenizing Guid-Guiz data ... ***\n",
      "file /home/jupyter/data/xlm_cluster4/Guid-Guiz/Guid-Guiz.Guid.all already exists\n",
      "file /home/jupyter/data/xlm_cluster4/Guid-Guiz/Guid-Guiz.Guiz.all already exists\n",
      "file /home/jupyter/data/xlm_cluster4/Guid.all already exists\n",
      "file /home/jupyter/data/xlm_cluster4/Guiz.all already exists\n",
      "\n",
      "\n",
      "*** split into train / valid / test ***\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "\n",
      "\n",
      "\n",
      "***build the training set for BPE tokenization (200 codes)***\n",
      "\n",
      "\n",
      "***shuf ... Generating 1000 random permutations of training data and store result in /home/jupyter/models/africa/cluster4/data/XLM_all/processed/Guid-Guiz/bpe.train***\n",
      "\n",
      "\n",
      "***Learn the BPE vocabulary on the training set : /home/jupyter/models/africa/cluster4/data/XLM_all/processed/bpe.train ...***\n",
      "Loading vocabulary from /home/jupyter/models/africa/cluster4/data/XLM_all/processed/bpe.train ...\n",
      "Read 113009 words (9406 unique) from text file.\n",
      "***Learn 200 BPE code on the bpe.train file***\n",
      "\n",
      "\n",
      "***Get the post-BPE vocab***\n",
      "Loading codes from /home/jupyter/models/africa/cluster4/data/XLM_all/processed/codes ...\n",
      "Read 200 codes from the codes file.\n",
      "Loading vocabulary from /home/jupyter/models/africa/cluster4/data/XLM_all/processed/bpe.train ...\n",
      "Read 113009 words (9406 unique) from text file.\n",
      "Applying BPE to /home/jupyter/models/africa/cluster4/data/XLM_all/processed/bpe.train ...\n",
      "Modified 113009 words from text file.\n",
      "Read 229169 words (284 unique) from text file.\n",
      "\n",
      "\n",
      "***Apply BPE tokenization on the corpora.***\n",
      "Loading codes from /home/jupyter/models/africa/cluster4/data/XLM_all/processed/codes ...\n",
      "Read 200 codes from the codes file.\n",
      "Loading vocabulary from /home/jupyter/data/xlm_cluster4/Guid-Guiz/Guid-Guiz.Guid.train ...\n",
      "Read 150583 words (11774 unique) from text file.\n",
      "Applying BPE to /home/jupyter/data/xlm_cluster4/Guid-Guiz/Guid-Guiz.Guid.train ...\n",
      "Modified 150583 words from text file.\n",
      "Loading codes from /home/jupyter/models/africa/cluster4/data/XLM_all/processed/codes ...\n",
      "Read 200 codes from the codes file.\n",
      "Loading vocabulary from /home/jupyter/data/xlm_cluster4/Guid-Guiz/Guid-Guiz.Guid.valid ...\n",
      "Read 19457 words (3572 unique) from text file.\n",
      "Applying BPE to /home/jupyter/data/xlm_cluster4/Guid-Guiz/Guid-Guiz.Guid.valid ...\n",
      "Modified 19457 words from text file.\n",
      "Loading codes from /home/jupyter/models/africa/cluster4/data/XLM_all/processed/codes ...\n",
      "Read 200 codes from the codes file.\n",
      "Loading vocabulary from /home/jupyter/data/xlm_cluster4/Guid-Guiz/Guid-Guiz.Guid.test ...\n",
      "Read 18865 words (3526 unique) from text file.\n",
      "Applying BPE to /home/jupyter/data/xlm_cluster4/Guid-Guiz/Guid-Guiz.Guid.test ...\n",
      "Modified 18865 words from text file.\n",
      "Loading codes from /home/jupyter/models/africa/cluster4/data/XLM_all/processed/codes ...\n",
      "Read 200 codes from the codes file.\n",
      "Loading vocabulary from /home/jupyter/data/xlm_cluster4/Guid-Guiz/Guid-Guiz.Guiz.train ...\n",
      "Read 204144 words (5419 unique) from text file.\n",
      "Applying BPE to /home/jupyter/data/xlm_cluster4/Guid-Guiz/Guid-Guiz.Guiz.train ...\n",
      "Modified 204144 words from text file.\n",
      "Loading codes from /home/jupyter/models/africa/cluster4/data/XLM_all/processed/codes ...\n",
      "Read 200 codes from the codes file.\n",
      "Loading vocabulary from /home/jupyter/data/xlm_cluster4/Guid-Guiz/Guid-Guiz.Guiz.valid ...\n",
      "Read 26082 words (2226 unique) from text file.\n",
      "Applying BPE to /home/jupyter/data/xlm_cluster4/Guid-Guiz/Guid-Guiz.Guiz.valid ...\n",
      "Modified 26082 words from text file.\n",
      "Loading codes from /home/jupyter/models/africa/cluster4/data/XLM_all/processed/codes ...\n",
      "Read 200 codes from the codes file.\n",
      "Loading vocabulary from /home/jupyter/data/xlm_cluster4/Guid-Guiz/Guid-Guiz.Guiz.test ...\n",
      "Read 25547 words (2159 unique) from text file.\n",
      "Applying BPE to /home/jupyter/data/xlm_cluster4/Guid-Guiz/Guid-Guiz.Guiz.test ...\n",
      "Modified 25547 words from text file.\n",
      "Loading codes from /home/jupyter/models/africa/cluster4/data/XLM_all/processed/codes ...\n",
      "Read 200 codes from the codes file.\n",
      "Loading vocabulary from /home/jupyter/data/xlm_cluster4/Guid.train ...\n",
      "Read 150583 words (11774 unique) from text file.\n",
      "Applying BPE to /home/jupyter/data/xlm_cluster4/Guid.train ...\n",
      "Modified 150583 words from text file.\n",
      "Loading codes from /home/jupyter/models/africa/cluster4/data/XLM_all/processed/codes ...\n",
      "Read 200 codes from the codes file.\n",
      "Loading vocabulary from /home/jupyter/data/xlm_cluster4/Guid.valid ...\n",
      "Read 19457 words (3572 unique) from text file.\n",
      "Applying BPE to /home/jupyter/data/xlm_cluster4/Guid.valid ...\n",
      "Modified 19457 words from text file.\n",
      "Loading codes from /home/jupyter/models/africa/cluster4/data/XLM_all/processed/codes ...\n",
      "Read 200 codes from the codes file.\n",
      "Loading vocabulary from /home/jupyter/data/xlm_cluster4/Guid.test ...\n",
      "Read 18865 words (3526 unique) from text file.\n",
      "Applying BPE to /home/jupyter/data/xlm_cluster4/Guid.test ...\n",
      "Modified 18865 words from text file.\n",
      "Loading codes from /home/jupyter/models/africa/cluster4/data/XLM_all/processed/codes ...\n",
      "Read 200 codes from the codes file.\n",
      "Loading vocabulary from /home/jupyter/data/xlm_cluster4/Guiz.train ...\n",
      "Read 829701 words (14389 unique) from text file.\n",
      "Applying BPE to /home/jupyter/data/xlm_cluster4/Guiz.train ...\n",
      "Modified 829701 words from text file.\n",
      "Loading codes from /home/jupyter/models/africa/cluster4/data/XLM_all/processed/codes ...\n",
      "Read 200 codes from the codes file.\n",
      "Loading vocabulary from /home/jupyter/data/xlm_cluster4/Guiz.valid ...\n",
      "Read 104980 words (5662 unique) from text file.\n",
      "Applying BPE to /home/jupyter/data/xlm_cluster4/Guiz.valid ...\n",
      "Modified 104980 words from text file.\n",
      "Loading codes from /home/jupyter/models/africa/cluster4/data/XLM_all/processed/codes ...\n",
      "Read 200 codes from the codes file.\n",
      "Loading vocabulary from /home/jupyter/data/xlm_cluster4/Guiz.test ...\n",
      "Read 102849 words (5715 unique) from text file.\n",
      "Applying BPE to /home/jupyter/data/xlm_cluster4/Guiz.test ...\n",
      "Modified 102849 words from text file.\n",
      "\n",
      "\n",
      "***Build fine_tune data***\n",
      "\n",
      "\n",
      "***Binarize everything using preprocess.py.***\n",
      "INFO - 06/28/20 14:32:42 - 0:00:00 - Read 298 words from the vocabulary file.\n",
      "\n",
      "Saving the data to /home/jupyter/models/africa/cluster4/data/XLM_all/processed/Guid-Guiz.Guid.train.pth ...\n",
      "INFO - 06/28/20 14:32:42 - 0:00:00 - 349276 words (298 unique) in 6334 sentences.\n",
      "INFO - 06/28/20 14:32:42 - 0:00:00 - 5 unknown words (3 unique), covering 0.00% of the data.\n",
      "INFO - 06/28/20 14:32:42 - 0:00:00 - 2@@: 3\n",
      "INFO - 06/28/20 14:32:42 - 0:00:00 - 1@@: 1\n",
      "INFO - 06/28/20 14:32:42 - 0:00:00 - 7@@: 1\n",
      "INFO - 06/28/20 14:32:43 - 0:00:00 - Read 298 words from the vocabulary file.\n",
      "\n",
      "Saving the data to /home/jupyter/models/africa/cluster4/data/XLM_all/processed/Guid-Guiz.Guid.valid.pth ...\n",
      "INFO - 06/28/20 14:32:43 - 0:00:00 - 45018 words (298 unique) in 791 sentences.\n",
      "INFO - 06/28/20 14:32:43 - 0:00:00 - 3 unknown words (2 unique), covering 0.01% of the data.\n",
      "INFO - 06/28/20 14:32:43 - 0:00:00 - 2@@: 2\n",
      "INFO - 06/28/20 14:32:43 - 0:00:00 - 7@@: 1\n",
      "INFO - 06/28/20 14:32:44 - 0:00:00 - Read 298 words from the vocabulary file.\n",
      "\n",
      "Saving the data to /home/jupyter/models/africa/cluster4/data/XLM_all/processed/Guid-Guiz.Guid.test.pth ...\n",
      "INFO - 06/28/20 14:32:44 - 0:00:00 - 43849 words (298 unique) in 791 sentences.\n",
      "INFO - 06/28/20 14:32:44 - 0:00:00 - Read 298 words from the vocabulary file.\n",
      "\n",
      "Saving the data to /home/jupyter/models/africa/cluster4/data/XLM_all/processed/Guid-Guiz.Guiz.train.pth ...\n",
      "INFO - 06/28/20 14:32:44 - 0:00:00 - 362563 words (298 unique) in 6334 sentences.\n",
      "INFO - 06/28/20 14:32:45 - 0:00:00 - Read 298 words from the vocabulary file.\n",
      "\n",
      "Saving the data to /home/jupyter/models/africa/cluster4/data/XLM_all/processed/Guid-Guiz.Guiz.valid.pth ...\n",
      "INFO - 06/28/20 14:32:45 - 0:00:00 - 46566 words (298 unique) in 791 sentences.\n",
      "INFO - 06/28/20 14:32:46 - 0:00:00 - Read 298 words from the vocabulary file.\n",
      "\n",
      "Saving the data to /home/jupyter/models/africa/cluster4/data/XLM_all/processed/Guid-Guiz.Guiz.test.pth ...\n",
      "INFO - 06/28/20 14:32:46 - 0:00:00 - 45092 words (298 unique) in 791 sentences.\n",
      "INFO - 06/28/20 14:32:46 - 0:00:00 - Read 298 words from the vocabulary file.\n",
      "\n",
      "Saving the data to /home/jupyter/models/africa/cluster4/data/XLM_all/processed/train.Guid.pth ...\n",
      "INFO - 06/28/20 14:32:47 - 0:00:00 - 349276 words (298 unique) in 6334 sentences.\n",
      "INFO - 06/28/20 14:32:47 - 0:00:00 - 5 unknown words (3 unique), covering 0.00% of the data.\n",
      "INFO - 06/28/20 14:32:47 - 0:00:00 - 2@@: 3\n",
      "INFO - 06/28/20 14:32:47 - 0:00:00 - 1@@: 1\n",
      "INFO - 06/28/20 14:32:47 - 0:00:00 - 7@@: 1\n",
      "INFO - 06/28/20 14:32:47 - 0:00:00 - Read 298 words from the vocabulary file.\n",
      "\n",
      "Saving the data to /home/jupyter/models/africa/cluster4/data/XLM_all/processed/valid.Guid.pth ...\n",
      "INFO - 06/28/20 14:32:47 - 0:00:00 - 45018 words (298 unique) in 791 sentences.\n",
      "INFO - 06/28/20 14:32:47 - 0:00:00 - 3 unknown words (2 unique), covering 0.01% of the data.\n",
      "INFO - 06/28/20 14:32:47 - 0:00:00 - 2@@: 2\n",
      "INFO - 06/28/20 14:32:47 - 0:00:00 - 7@@: 1\n",
      "INFO - 06/28/20 14:32:48 - 0:00:00 - Read 298 words from the vocabulary file.\n",
      "\n",
      "Saving the data to /home/jupyter/models/africa/cluster4/data/XLM_all/processed/test.Guid.pth ...\n",
      "INFO - 06/28/20 14:32:48 - 0:00:00 - 43849 words (298 unique) in 791 sentences.\n",
      "INFO - 06/28/20 14:32:49 - 0:00:00 - Read 298 words from the vocabulary file.\n",
      "\n",
      "Saving the data to /home/jupyter/models/africa/cluster4/data/XLM_all/processed/train.Guiz.pth ...\n",
      "INFO - 06/28/20 14:32:50 - 0:00:01 - 1532959 words (298 unique) in 24869 sentences.\n",
      "INFO - 06/28/20 14:32:50 - 0:00:01 - 12 unknown words (7 unique), covering 0.00% of the data.\n",
      "INFO - 06/28/20 14:32:50 - 0:00:01 - 1@@: 4\n",
      "INFO - 06/28/20 14:32:50 - 0:00:01 - 2@@: 2\n",
      "INFO - 06/28/20 14:32:50 - 0:00:01 - 9: 2\n",
      "INFO - 06/28/20 14:32:50 - 0:00:01 - ǝ: 1\n",
      "INFO - 06/28/20 14:32:50 - 0:00:01 - 1: 1\n",
      "INFO - 06/28/20 14:32:50 - 0:00:01 - 7@@: 1\n",
      "INFO - 06/28/20 14:32:50 - 0:00:01 - 5: 1\n",
      "INFO - 06/28/20 14:32:50 - 0:00:00 - Read 298 words from the vocabulary file.\n",
      "\n",
      "Saving the data to /home/jupyter/models/africa/cluster4/data/XLM_all/processed/valid.Guiz.pth ...\n",
      "INFO - 06/28/20 14:32:50 - 0:00:00 - 194455 words (298 unique) in 3108 sentences.\n",
      "INFO - 06/28/20 14:32:51 - 0:00:00 - Read 298 words from the vocabulary file.\n",
      "\n",
      "Saving the data to /home/jupyter/models/africa/cluster4/data/XLM_all/processed/test.Guiz.pth ...\n",
      "INFO - 06/28/20 14:32:51 - 0:00:00 - 190669 words (298 unique) in 3108 sentences.\n",
      "\n",
      "\n",
      "***Creat the file to train the XLM model with MLM+TLM objective***\n",
      "\n",
      "\n",
      "*** build data with succes : dir /home/jupyter/models/africa/cluster4/data/XLM_all/processed ***\n"
     ]
    }
   ],
   "source": [
    "%env languages=Guidar,Guiziga\n",
    "#,Kapsiki_DC,Mofa,Mofu_Gudur\n",
    "! chmod +x ../data.sh \n",
    "! ../data.sh $languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: config_file=/home/jupyter/meta_XLM/notebooks/africa/cluster4/mlm_config.json\n",
      "FAISS library was not found.\n",
      "FAISS not available. Switching to standard nearest neighbors search implementation.\n",
      "False\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 630, in <module>\n",
      "    check_data_params(params)\n",
      "  File \"/home/jupyter/meta_XLM/XLM/src/data/loader.py\", line 355, in check_data_params\n",
      "    assert params.eval_bleu is False or len(params.mt_steps + params.bt_steps) > 0\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "%env config_file=/home/jupyter/meta_XLM/notebooks/africa/cluster4/mlm_config.json\n",
    "! python train.py --config_file $config_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
