{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fUL1x0CGt6IE"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UwIvdQlpADmj"
   },
   "source": [
    "**Référence :** https://github.com/facebookresearch/XLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zacxcSS9HbDd"
   },
   "source": [
    "# **Applications: Supervised / Unsupervised MT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 992,
     "status": "ok",
     "timestamp": 1588653837138,
     "user": {
      "displayName": "Pascal Notsawo",
      "photoUrl": "",
      "userId": "05128058352342027621"
     },
     "user_tz": -120
    },
    "id": "5HR8cardIHFJ",
    "outputId": "93cfd5bc-d63e-4ac1-8f05-2bc292f4853b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(bookmark:HOME) -> /home/jupyter/meta_XLM/XLM\n",
      "/home/jupyter/meta_XLM/XLM\n",
      "env: OUTPATH=/home/XLM/data/30000/es-fr\n"
     ]
    }
   ],
   "source": [
    "%bookmark HOME \"/home/jupyter/meta_XLM/XLM\" \n",
    "%cd -b HOME\n",
    "%env OUTPATH /home/XLM/data/30000/es-fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1237,
     "status": "ok",
     "timestamp": 1588653868380,
     "user": {
      "displayName": "Pascal Notsawo",
      "photoUrl": "",
      "userId": "05128058352342027621"
     },
     "user_tz": -120
    },
    "id": "8mrQhqzNLWQ9",
    "outputId": "ea069a08-d334-4828-a960-e8bb6ca61dc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: exp_id=hypothesis\n",
      "env: batch_size=16\n",
      "env: lgs=es-fr\n",
      "env: max_len=100\n"
     ]
    }
   ],
   "source": [
    "%env exp_id=hypothesis\n",
    "#%env batch_size=32\n",
    "%env batch_size=16\n",
    "%env lgs=es-fr\n",
    "# Maximum length of sentences (after BPE)\n",
    "%env max_len=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 672,
     "status": "error",
     "timestamp": 1588653874834,
     "user": {
      "displayName": "Pascal Notsawo",
      "photoUrl": "",
      "userId": "05128058352342027621"
     },
     "user_tz": -120
    },
    "id": "5gOEASh1dsYz",
    "outputId": "3256bee3-4620-4275-877f-dce28d96d7fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_len = 38067593\n"
     ]
    }
   ],
   "source": [
    "# le plus grand fichier à tensor_len phrases, on cherche le multiple de \"batch_size\" le plus proche de ce \n",
    "# nombre par valeur supérieur : epoch_size doit etre un multiple non nul de ce nombre (pour ne pas gaspiller) \n",
    "\n",
    "main_path = \"/home/XLM/data/30000/\"\n",
    "\n",
    "import io\n",
    "\n",
    "def n_lines(file_path):\n",
    "    i = 0\n",
    "    with open(file_path, mode = \"r\", encoding='UTF-8') as myfile :\n",
    "        for _ in myfile.readlines() :\n",
    "            i = i + 1\n",
    "    return i\n",
    "\n",
    "tensor_len = n_lines(file_path = main_path + \"es-fr/es-fr.es.train\")\n",
    "print(\"tensor_len = \" + str(tensor_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_size = 2379225\n"
     ]
    }
   ],
   "source": [
    "tensor_len = 38067593\n",
    "batch_size = 16\n",
    "\n",
    "def getEpochSize(tensor_len, batch_size):\n",
    "    i = tensor_len\n",
    "    while True :\n",
    "        if i%batch_size == 0 :\n",
    "            return i//batch_size\n",
    "        i = i + 1\n",
    "\n",
    "    \n",
    "epoch_size = getEpochSize(tensor_len = tensor_len, batch_size = batch_size)\n",
    "print(\"epoch_size = \" + str(epoch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VqJWeWSRdvDm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: epoch_size=2379225\n"
     ]
    }
   ],
   "source": [
    "# Et deduire epoch_size (evaluation frequency, -1 for parallel data size)\n",
    "%env epoch_size=2379225\n",
    "#%env epoch_size=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: remove_long_sentences_train=True\n",
      "env: remove_long_sentences_valid=True\n",
      "env: remove_long_sentences_test=True\n"
     ]
    }
   ],
   "source": [
    "%env remove_long_sentences_train=True\n",
    "%env remove_long_sentences_valid=True\n",
    "%env remove_long_sentences_test=True\n",
    "#--remove_long_sentences_train $remove_long_sentences_train --remove_long_sentences_valid $remove_long_sentences_valid --remove_long_sentences_test $remove_long_sentences_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: train_n_samples=-1\n",
      "env: valid_n_samples=-1\n",
      "env: test_n_samples=-1\n"
     ]
    }
   ],
   "source": [
    "# limit the number of examples (-1 by default for non limitation)\n",
    "%env train_n_samples=-1\n",
    "%env valid_n_samples=-1\n",
    "%env test_n_samples=-1\n",
    "#--train_n_samples $train_n_samples --valid_n_samples $valid_n_samples --test_n_samples $test_n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7CmgkltWJgS7"
   },
   "source": [
    "**Pretrain a language model (MLM+TLM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OXmsZLmdeyL0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_epoch = 27255\n",
      "nb_hour = 1362\n"
     ]
    }
   ],
   "source": [
    "def get_max_epoch(tensor_len):\n",
    "    return int(100*(tensor_len/139670)) # par expérience\n",
    "\n",
    "def get_nb_hour(max_epoch, nb_gpu = 1):\n",
    "    return int(5*(max_epoch/100)) * nb_gpu\n",
    "\n",
    "max_epoch = get_max_epoch(tensor_len)\n",
    "print(\"max_epoch = \"+ str(max_epoch))\n",
    "print(\"nb_hour = \" + str(get_nb_hour(max_epoch, nb_gpu = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hOfP9eVEd5rY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: max_epoch=27255\n"
     ]
    }
   ],
   "source": [
    "%env max_epoch=27255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "01dQhpsfeH6y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: stopping_criterion=_valid_mlm_ppl,10\n",
      "env: eval_bleu=false\n",
      "env: lgs=es-fr\n",
      "env: mlm_steps=es,fr,es-fr\n"
     ]
    }
   ],
   "source": [
    "# stopping criterion (if criterion does not improve 10 times)\n",
    "%env stopping_criterion=_valid_mlm_ppl,10\n",
    "%env eval_bleu false\n",
    "%env lgs=es-fr\n",
    "%env mlm_steps=es,fr,es-fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eoACYa8IeZIY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: max_epoch=1\n",
      "env: use_memory=True\n",
      "env: mem_enc_positions=7,10+\n",
      "env: mem_dec_positions=7,10+\n",
      "FAISS library was not found.\n",
      "FAISS not available. Switching to standard nearest neighbors search implementation.\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 344, in <module>\n",
      "    check_model_params(params)\n",
      "  File \"/home/jupyter/meta_XLM/XLM/src/model/__init__.py\", line 72, in check_model_params\n",
      "    assert len(params.mem_enc_positions) == 0 or 0 <= min([x[0] for x in params.mem_enc_positions]) <= max([x[0] for x in params.mem_enc_positions]) <= params.n_layers - 1\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "%env max_epoch=1\n",
    "\n",
    "%env use_memory=True\n",
    "%env mem_enc_positions=0\n",
    "%env mem_dec_positions=0\n",
    "#--use_memory $use_memory --mem_enc_positions $mem_enc_positions --mem_dec_positions $mem_dec_positions\n",
    "\n",
    "! python train.py --exp_name esfr_mlm_tlm --dump_path ./dumped/ --data_path $OUTPATH --lgs $lgs --clm_steps '' --mlm_steps $mlm_steps --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout 0.1 --attention_dropout 0.1 --gelu_activation true --batch_size $batch_size --bptt 256 --optimizer adam,lr=0.0001 --epoch_size $epoch_size --max_epoch $max_epoch --validation_metrics _valid_mlm_ppl --stopping_criterion $stopping_criterion --eval_bleu $eval_bleu --exp_id $exp_id --remove_long_sentences_train $remove_long_sentences_train --remove_long_sentences_valid $remove_long_sentences_valid --remove_long_sentences_test $remove_long_sentences_test --train_n_samples $train_n_samples --valid_n_samples $valid_n_samples --test_n_samples $test_n_samples --use_memory $use_memory --mem_enc_positions $mem_enc_positions --mem_dec_positions $mem_dec_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWr_m3Y2et7A"
   },
   "outputs": [],
   "source": [
    "# Si l'entrainement echoue\n",
    "#! rm -R dumped/esfr_mlm_tlm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_5ozfc5qvYh5"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UNkD_5htPpAQ"
   },
   "source": [
    "**Train on unsupervised MT from a pretrained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AEVNOQW0neJE"
   },
   "outputs": [],
   "source": [
    "#%env batch_size=...\n",
    "#%env epoch_size=...\n",
    "\n",
    "%env eval_bleu=true\n",
    "# comme eval_bleu=true\n",
    "%cd /home/jupyter/meta_XLM/XLM\n",
    "! chmod +x src/evaluation/multi-bleu.perl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hiMo7NqTfi8O"
   },
   "outputs": [],
   "source": [
    "#%env stopping_criterion=valid_es-fr_mt_bleu,10\n",
    "%env stopping_criterion=valid_es-fr_mt_bleu,2\n",
    "%env validation_metrics=valid_es-fr_mt_bleu\n",
    "# reload encoder and decoder from dumped/esfr_mlm_tlm/hypothesis/best-valid_mlm_ppl.pth\n",
    "%env reload_model=dumped/esfr_mlm_tlm/hypothesis/best-valid_mlm_ppl.pth,dumped/esfr_mlm_tlm/hypothesis/best-valid_mlm_ppl.pth\n",
    "%env ae_steps=es,fr\n",
    "%env bt_steps=es-fr-es,fr-es-fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oRw4RN5Ufo6s"
   },
   "outputs": [],
   "source": [
    "#! python train.py --exp_name unsupMT_esfr --dump_path ./dumped/ --reload_model $reload_model --data_path $OUTPATH --lgs $lgs --ae_steps $ae_steps --bt_steps $bt_steps --word_shuffle 3 --word_dropout 0.1 --word_blank 0.1 --lambda_ae '0:1,100000:0.1,300000:0' --encoder_only false --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout 0.1 --attention_dropout 0.1 --gelu_activation true --tokens_per_batch 2000 --batch_size $batch_size --bptt 256 --optimizer adam_inverse_sqrt,beta1=0.9,beta2=0.98,lr=0.0001 --epoch_size $epoch_size --max_epoch $max_epoch --eval_bleu $eval_bleu --stopping_criterion $stopping_criterion --validation_metrics $validation_metrics --exp_id $exp_id  \n",
    "%env mt_steps=es-fr,fr-es\n",
    "! python train.py --exp_name unsupMT_esfr --dump_path ./dumped/ --reload_model $reload_model --data_path $OUTPATH --lgs $lgs --ae_steps $ae_steps --mt_steps $mt_steps --bt_steps $bt_steps --word_shuffle 3 --word_dropout 0.1 --word_blank 0.1 --lambda_ae '0:1,100000:0.1,300000:0' --encoder_only false --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout 0.1 --attention_dropout 0.1 --gelu_activation true --tokens_per_batch 2000 --batch_size $batch_size --bptt 256 --optimizer adam_inverse_sqrt,beta1=0.9,beta2=0.98,lr=0.0001 --epoch_size $epoch_size --max_epoch $max_epoch --eval_bleu $eval_bleu --stopping_criterion $stopping_criterion --validation_metrics $validation_metrics --exp_id $exp_id  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kCJFNZw1UY7N"
   },
   "outputs": [],
   "source": [
    "# Si l'entrainement echoue\n",
    "#! rm -R dumped/unsupMT_esfr"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "xgG9b83apvC3",
    "kNkA4ggJ0mkX",
    "A9wxgjwDADDz"
   ],
   "name": "train_espagnol_francais.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
