{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data : Monolingual data (MLM) and/or Parallel data (TLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(bookmark:HOME) -> /home/jupyter/meta_XLM/XLM\n",
      "/home/jupyter/meta_XLM/XLM\n"
     ]
    }
   ],
   "source": [
    "%bookmark HOME \"/home/jupyter/meta_XLM/XLM\" \n",
    "%cd -b HOME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PARA=True\n",
      "env: MONO=True\n",
      "env: PARA_PATH=data/enfrde/para\n",
      "env: MONO_PATH=data/enfrde/mono\n",
      "env: SAME_VOCAB=True\n",
      "env: nCodes=10\n",
      "env: shuf_n_samples=1\n",
      "env: threads_for_tokenizer=16\n",
      "env: test_size=10\n",
      "env: val_size=10\n",
      "env: TOKENIZE=tools/tokenizer_our.sh\n",
      "env: LOWER_REMOVE_ACCENT=tools/lowercase_and_remove_accent.py\n",
      "env: FASTBPE=tools/fastBPE/fast\n",
      "env: OUTPATH=data/enfrde/processed\n",
      "env: n_samples=-1\n",
      "env: sub_task=en-fr:10,de-en:-1,de-fr:-1\n"
     ]
    }
   ],
   "source": [
    "%env PARA=True          \n",
    "%env MONO=True           \n",
    "                   \n",
    "%env PARA_PATH=data/enfrde/para      \n",
    "%env MONO_PATH=data/enfrde/mono    \n",
    "%env SAME_VOCAB=True    \n",
    "%env nCodes=10\n",
    "%env shuf_n_samples=1\n",
    "%env threads_for_tokenizer=16\n",
    "%env test_size=10       \n",
    "%env val_size=10        \n",
    "\n",
    "# tools paths\n",
    "%env TOKENIZE=tools/tokenizer_our.sh\n",
    "%env LOWER_REMOVE_ACCENT=tools/lowercase_and_remove_accent.py\n",
    "%env FASTBPE=tools/fastBPE/fast\n",
    "\n",
    "\n",
    "%env OUTPATH=data/enfrde/processed \n",
    "# create output path\n",
    "! mkdir -p $OUTPATH\n",
    "\n",
    "! chmod +x $FASTBPE\n",
    "! chmod +x ../build_meta_data.sh\n",
    "! chmod +x tools/mosesdecoder/scripts/tokenizer/*.perl\n",
    "\n",
    "%env n_samples=-1\n",
    "\n",
    "%env sub_task=en-fr:10,de-en:-1,de-fr:-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir data/enfrde/processed/fine_tune already exists\n",
      "params ok !\n",
      "*** Cleaning and tokenizing en-fr data ... ***\n",
      "file data/enfrde/para/en-fr.en.all already exists\n",
      "file data/enfrde/para/en-fr.fr.all already exists\n",
      "*** Cleaning and tokenizing de-en data ... ***\n",
      "file data/enfrde/para/de-en.de.all already exists\n",
      "file data/enfrde/para/de-en.en.all already exists\n",
      "*** Cleaning and tokenizing de-fr data ... ***\n",
      "file data/enfrde/para/de-fr.de.all already exists\n",
      "file data/enfrde/para/de-fr.fr.all already exists\n",
      "file data/enfrde/mono/en.all already exists\n",
      "file data/enfrde/mono/fr.all already exists\n",
      "file data/enfrde/mono/de.all already exists\n",
      "file data/enfrde/mono/en.all already exists\n",
      "file data/enfrde/mono/de.all already exists\n",
      "file data/enfrde/mono/fr.all already exists\n",
      "\n",
      "\n",
      "*** split into train / valid / test ***\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "\n",
      "\n",
      "\n",
      "***build the training set for BPE tokenization (10 codes)***\n",
      "\n",
      "\n",
      "***shuf ... Generating 1 random permutations of training data and store result in data/enfrde/processed/de-fr/bpe.train***\n",
      "file data/enfrde/processed/bpe.train already exists\n",
      "\n",
      "\n",
      "***Learn the BPE vocabulary on the training set : data/enfrde/processed/bpe.train ...***\n",
      "file data/enfrde/processed/codes already exists\n",
      "***Learn 10 BPE code on the bpe.train file***\n",
      "\n",
      "\n",
      "***Get the post-BPE vocab***\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/processed/bpe.train ...\n",
      "Read 356 words (209 unique) from text file.\n",
      "Applying BPE to data/enfrde/processed/bpe.train ...\n",
      "Modified 356 words from text file.\n",
      "Read 1623 words (69 unique) from text file.\n",
      "\n",
      "\n",
      "***Apply BPE tokenization on the corpora.***\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/para/en-fr.en.train ...\n",
      "Read 111998 words (10147 unique) from text file.\n",
      "Applying BPE to data/enfrde/para/en-fr.en.train ...\n",
      "Modified 111998 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/para/en-fr.en.valid ...\n",
      "Read 13526 words (3243 unique) from text file.\n",
      "Applying BPE to data/enfrde/para/en-fr.en.valid ...\n",
      "Modified 13526 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/para/en-fr.en.test ...\n",
      "Read 14027 words (3244 unique) from text file.\n",
      "Applying BPE to data/enfrde/para/en-fr.en.test ...\n",
      "Modified 14027 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/para/en-fr.fr.train ...\n",
      "Read 139524 words (11621 unique) from text file.\n",
      "Applying BPE to data/enfrde/para/en-fr.fr.train ...\n",
      "Modified 139524 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/para/en-fr.fr.valid ...\n",
      "Read 16291 words (3599 unique) from text file.\n",
      "Applying BPE to data/enfrde/para/en-fr.fr.valid ...\n",
      "Modified 16291 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/para/en-fr.fr.test ...\n",
      "Read 16858 words (3525 unique) from text file.\n",
      "Applying BPE to data/enfrde/para/en-fr.fr.test ...\n",
      "Modified 16858 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/para/de-en.de.train ...\n",
      "Read 139547 words (11620 unique) from text file.\n",
      "Applying BPE to data/enfrde/para/de-en.de.train ...\n",
      "Modified 139547 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/para/de-en.de.valid ...\n",
      "Read 16299 words (3598 unique) from text file.\n",
      "Applying BPE to data/enfrde/para/de-en.de.valid ...\n",
      "Modified 16299 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/para/de-en.de.test ...\n",
      "Read 16859 words (3524 unique) from text file.\n",
      "Applying BPE to data/enfrde/para/de-en.de.test ...\n",
      "Modified 16859 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/para/de-en.en.train ...\n",
      "Read 111998 words (10147 unique) from text file.\n",
      "Applying BPE to data/enfrde/para/de-en.en.train ...\n",
      "Modified 111998 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/para/de-en.en.valid ...\n",
      "Read 13526 words (3243 unique) from text file.\n",
      "Applying BPE to data/enfrde/para/de-en.en.valid ...\n",
      "Modified 13526 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/para/de-en.en.test ...\n",
      "Read 14027 words (3244 unique) from text file.\n",
      "Applying BPE to data/enfrde/para/de-en.en.test ...\n",
      "Modified 14027 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/para/de-fr.de.train ...\n",
      "Read 139547 words (11620 unique) from text file.\n",
      "Applying BPE to data/enfrde/para/de-fr.de.train ...\n",
      "Modified 139547 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/para/de-fr.de.valid ...\n",
      "Read 16299 words (3598 unique) from text file.\n",
      "Applying BPE to data/enfrde/para/de-fr.de.valid ...\n",
      "Modified 16299 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/para/de-fr.de.test ...\n",
      "Read 16859 words (3524 unique) from text file.\n",
      "Applying BPE to data/enfrde/para/de-fr.de.test ...\n",
      "Modified 16859 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/para/de-fr.fr.train ...\n",
      "Read 139524 words (11621 unique) from text file.\n",
      "Applying BPE to data/enfrde/para/de-fr.fr.train ...\n",
      "Modified 139524 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/para/de-fr.fr.valid ...\n",
      "Read 16291 words (3599 unique) from text file.\n",
      "Applying BPE to data/enfrde/para/de-fr.fr.valid ...\n",
      "Modified 16291 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/para/de-fr.fr.test ...\n",
      "Read 16858 words (3525 unique) from text file.\n",
      "Applying BPE to data/enfrde/para/de-fr.fr.test ...\n",
      "Modified 16858 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/mono/en.train ...\n",
      "Read 111998 words (10147 unique) from text file.\n",
      "Applying BPE to data/enfrde/mono/en.train ...\n",
      "Modified 111998 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/mono/en.valid ...\n",
      "Read 13526 words (3243 unique) from text file.\n",
      "Applying BPE to data/enfrde/mono/en.valid ...\n",
      "Modified 13526 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/mono/en.test ...\n",
      "Read 14027 words (3244 unique) from text file.\n",
      "Applying BPE to data/enfrde/mono/en.test ...\n",
      "Modified 14027 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/mono/fr.train ...\n",
      "Read 139524 words (11621 unique) from text file.\n",
      "Applying BPE to data/enfrde/mono/fr.train ...\n",
      "Modified 139524 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/mono/fr.valid ...\n",
      "Read 16291 words (3599 unique) from text file.\n",
      "Applying BPE to data/enfrde/mono/fr.valid ...\n",
      "Modified 16291 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/mono/fr.test ...\n",
      "Read 16858 words (3525 unique) from text file.\n",
      "Applying BPE to data/enfrde/mono/fr.test ...\n",
      "Modified 16858 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/mono/de.train ...\n",
      "Read 139547 words (11620 unique) from text file.\n",
      "Applying BPE to data/enfrde/mono/de.train ...\n",
      "Modified 139547 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/mono/de.valid ...\n",
      "Read 16299 words (3598 unique) from text file.\n",
      "Applying BPE to data/enfrde/mono/de.valid ...\n",
      "Modified 16299 words from text file.\n",
      "Loading codes from data/enfrde/processed/codes ...\n",
      "Read 0 codes from the codes file.\n",
      "Loading vocabulary from data/enfrde/mono/de.test ...\n",
      "Read 16859 words (3524 unique) from text file.\n",
      "Applying BPE to data/enfrde/mono/de.test ...\n",
      "Modified 16859 words from text file.\n",
      "file data/enfrde/processed/train.en already exists\n",
      "file data/enfrde/processed/valid.en already exists\n",
      "file data/enfrde/processed/test.en already exists\n",
      "file data/enfrde/processed/train.de already exists\n",
      "file data/enfrde/processed/valid.de already exists\n",
      "file data/enfrde/processed/test.de already exists\n",
      "file data/enfrde/processed/train.fr already exists\n",
      "file data/enfrde/processed/valid.fr already exists\n",
      "file data/enfrde/processed/test.fr already exists\n",
      "\n",
      "\n",
      "***Build fine_tune data***\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "\n",
      "\n",
      "***Binarize everything using preprocess.py.***\n",
      "INFO - 05/14/20 16:03:31 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/en-fr.en.train.pth ...\n",
      "INFO - 05/14/20 16:03:31 - 0:00:00 - 492009 words (83 unique) in 3602 sentences.\n",
      "INFO - 05/14/20 16:03:31 - 0:00:00 - 9099 unknown words (46 unique), covering 1.85% of the data.\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/fine_tune/en-fr.en.train.pth ...\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - 52831 words (83 unique) in 400 sentences.\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - 956 unknown words (25 unique), covering 1.81% of the data.\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - w@@: 490\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - k@@: 112\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - z@@: 67\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - p: 56\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - :: 36\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - 6: 30\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - 9@@: 29\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - 8@@: 24\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - 7: 23\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - b: 18\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - 4@@: 12\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - x: 11\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - q: 9\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - 6@@: 9\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - *: 8\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - •: 5\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - ,@@: 3\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - $: 3\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - ?: 3\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - }: 2\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - {: 2\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - &: 1\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - j: 1\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - '@@: 1\n",
      "INFO - 05/14/20 16:03:32 - 0:00:00 - v: 1\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/en-fr.en.valid.pth ...\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - 58513 words (83 unique) in 451 sentences.\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - 1125 unknown words (28 unique), covering 1.92% of the data.\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - w@@: 512\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - k@@: 170\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - z@@: 79\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - 9@@: 62\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - p: 46\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - 7: 37\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - 6: 37\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - :: 36\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - b: 28\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - 4@@: 27\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - 6@@: 20\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - x: 16\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - 8@@: 16\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - ,@@: 12\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - v: 5\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - $: 3\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - z: 3\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - ?: 3\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - q: 3\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - _: 2\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - €: 1\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - j: 1\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - ø@@: 1\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - ∗: 1\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - °: 1\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - >: 1\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - <: 1\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - +: 1\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/fine_tune/en-fr.en.valid.pth ...\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - 7840 words (83 unique) in 50 sentences.\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - 130 unknown words (14 unique), covering 1.66% of the data.\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - w@@: 57\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - k@@: 19\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - :: 11\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - z@@: 8\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - $: 6\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - 9@@: 6\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - p: 6\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - 6@@: 4\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - 6: 4\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - 8@@: 3\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - ,@@: 2\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - 4@@: 2\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - 7: 1\n",
      "INFO - 05/14/20 16:03:33 - 0:00:00 - x: 1\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/en-fr.en.test.pth ...\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - 61684 words (83 unique) in 451 sentences.\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - 1257 unknown words (26 unique), covering 2.04% of the data.\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - w@@: 589\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - k@@: 162\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - z@@: 80\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - 9@@: 68\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - p: 56\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - 6: 46\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - 4@@: 46\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - :: 38\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - 7: 33\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - 8@@: 32\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - 6@@: 26\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - b: 19\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - x: 14\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - ,@@: 10\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - v: 10\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - $: 9\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - q: 4\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - •: 3\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - =: 2\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - %: 2\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - <: 2\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - *: 2\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - γ: 1\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - z: 1\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - >: 1\n",
      "INFO - 05/14/20 16:03:34 - 0:00:00 - @: 1\n",
      "INFO - 05/14/20 16:03:35 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/fine_tune/en-fr.en.test.pth ...\n",
      "INFO - 05/14/20 16:03:35 - 0:00:00 - 6041 words (83 unique) in 50 sentences.\n",
      "INFO - 05/14/20 16:03:35 - 0:00:00 - 133 unknown words (17 unique), covering 2.20% of the data.\n",
      "INFO - 05/14/20 16:03:35 - 0:00:00 - w@@: 68\n",
      "INFO - 05/14/20 16:03:35 - 0:00:00 - k@@: 18\n",
      "INFO - 05/14/20 16:03:35 - 0:00:00 - z@@: 11\n",
      "INFO - 05/14/20 16:03:35 - 0:00:00 - p: 9\n",
      "INFO - 05/14/20 16:03:35 - 0:00:00 - :: 5\n",
      "INFO - 05/14/20 16:03:35 - 0:00:00 - 6@@: 5\n",
      "INFO - 05/14/20 16:03:35 - 0:00:00 - 9@@: 4\n",
      "INFO - 05/14/20 16:03:35 - 0:00:00 - 4@@: 3\n",
      "INFO - 05/14/20 16:03:35 - 0:00:00 - 7: 2\n",
      "INFO - 05/14/20 16:03:35 - 0:00:00 - z: 1\n",
      "INFO - 05/14/20 16:03:35 - 0:00:00 - v: 1\n",
      "INFO - 05/14/20 16:03:35 - 0:00:00 - @: 1\n",
      "INFO - 05/14/20 16:03:35 - 0:00:00 - 8@@: 1\n",
      "INFO - 05/14/20 16:03:35 - 0:00:00 - $: 1\n",
      "INFO - 05/14/20 16:03:35 - 0:00:00 - q: 1\n",
      "INFO - 05/14/20 16:03:35 - 0:00:00 - x: 1\n",
      "INFO - 05/14/20 16:03:35 - 0:00:00 - b: 1\n",
      "INFO - 05/14/20 16:03:35 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/en-fr.fr.train.pth ...\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - 567418 words (83 unique) in 3602 sentences.\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - 4944 unknown words (51 unique), covering 0.87% of the data.\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/fine_tune/en-fr.fr.train.pth ...\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - 60374 words (83 unique) in 400 sentences.\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - 444 unknown words (28 unique), covering 0.74% of the data.\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - x: 143\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - :: 40\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - 9@@: 26\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - k@@: 24\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - 6: 24\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - 7: 24\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - w@@: 20\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - z@@: 17\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - b: 16\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - 4@@: 16\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - 8@@: 15\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - 6@@: 11\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - p: 10\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - œ@@: 9\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - q: 8\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - •: 6\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - ,@@: 6\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - *: 5\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - µ@@: 4\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - %: 4\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - ?: 3\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - z: 3\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - j: 3\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - −: 2\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - °: 2\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - v: 1\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - №: 1\n",
      "INFO - 05/14/20 16:03:36 - 0:00:00 - º: 1\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/en-fr.fr.valid.pth ...\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - 66586 words (83 unique) in 451 sentences.\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - 601 unknown words (29 unique), covering 0.90% of the data.\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - x: 173\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - 9@@: 60\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - k@@: 42\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - 6: 39\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - :: 38\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - 7: 36\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - z@@: 32\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - 4@@: 31\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - w@@: 28\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - ,@@: 19\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - 6@@: 19\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - 8@@: 16\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - b: 14\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - œ@@: 11\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - p: 10\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - %: 7\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - z: 5\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - −: 4\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - ?: 3\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - q: 3\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - _: 2\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - v: 2\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - j: 1\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - ø@@: 1\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - *: 1\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - °: 1\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - >: 1\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - <: 1\n",
      "INFO - 05/14/20 16:03:37 - 0:00:00 - +: 1\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/fine_tune/en-fr.fr.valid.pth ...\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - 7973 words (83 unique) in 50 sentences.\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - 67 unknown words (13 unique), covering 0.84% of the data.\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - x: 17\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - :: 10\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - k@@: 8\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - ,@@: 6\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - 9@@: 6\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - 6@@: 4\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - 4@@: 3\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - 8@@: 3\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - p: 2\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - b: 2\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - 6: 2\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - 7: 2\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - œ@@: 2\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/en-fr.fr.test.pth ...\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - 69085 words (83 unique) in 451 sentences.\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - 637 unknown words (29 unique), covering 0.92% of the data.\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - x: 188\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - 9@@: 64\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - 6: 45\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - :: 39\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - w@@: 36\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - 4@@: 36\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - 7: 34\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - 8@@: 29\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - 6@@: 26\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - k@@: 25\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - z@@: 23\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - b: 18\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - p: 15\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - ,@@: 11\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - œ@@: 10\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - v: 6\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - %: 5\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - z: 5\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - q: 5\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - j: 3\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - •: 3\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - °: 2\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - −: 2\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - *: 2\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - γ: 1\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - ?: 1\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - >: 1\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - <: 1\n",
      "INFO - 05/14/20 16:03:38 - 0:00:00 - @: 1\n",
      "INFO - 05/14/20 16:03:39 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/fine_tune/en-fr.fr.test.pth ...\n",
      "INFO - 05/14/20 16:03:39 - 0:00:00 - 6509 words (83 unique) in 50 sentences.\n",
      "INFO - 05/14/20 16:03:39 - 0:00:00 - 44 unknown words (16 unique), covering 0.68% of the data.\n",
      "INFO - 05/14/20 16:03:39 - 0:00:00 - x: 8\n",
      "INFO - 05/14/20 16:03:39 - 0:00:00 - :: 6\n",
      "INFO - 05/14/20 16:03:39 - 0:00:00 - 6@@: 5\n",
      "INFO - 05/14/20 16:03:39 - 0:00:00 - k@@: 4\n",
      "INFO - 05/14/20 16:03:39 - 0:00:00 - 9@@: 4\n",
      "INFO - 05/14/20 16:03:39 - 0:00:00 - 4@@: 3\n",
      "INFO - 05/14/20 16:03:39 - 0:00:00 - 7: 2\n",
      "INFO - 05/14/20 16:03:39 - 0:00:00 - w@@: 2\n",
      "INFO - 05/14/20 16:03:39 - 0:00:00 - p: 2\n",
      "INFO - 05/14/20 16:03:39 - 0:00:00 - z@@: 2\n",
      "INFO - 05/14/20 16:03:39 - 0:00:00 - v: 1\n",
      "INFO - 05/14/20 16:03:39 - 0:00:00 - @: 1\n",
      "INFO - 05/14/20 16:03:39 - 0:00:00 - ,@@: 1\n",
      "INFO - 05/14/20 16:03:39 - 0:00:00 - 8@@: 1\n",
      "INFO - 05/14/20 16:03:39 - 0:00:00 - b: 1\n",
      "INFO - 05/14/20 16:03:39 - 0:00:00 - œ@@: 1\n",
      "INFO - 05/14/20 16:03:40 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/de-en.de.train.pth ...\n",
      "INFO - 05/14/20 16:03:40 - 0:00:00 - 627614 words (83 unique) in 4001 sentences.\n",
      "INFO - 05/14/20 16:03:40 - 0:00:00 - 5387 unknown words (53 unique), covering 0.86% of the data.\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/de-en.de.valid.pth ...\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - 74507 words (83 unique) in 500 sentences.\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - 667 unknown words (29 unique), covering 0.90% of the data.\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - x: 190\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - 9@@: 66\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - k@@: 50\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - :: 47\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - 6: 41\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - 7: 38\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - 4@@: 34\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - z@@: 32\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - w@@: 28\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - ,@@: 25\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - 6@@: 23\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - 8@@: 19\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - b: 16\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - œ@@: 13\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - p: 12\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - %: 7\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - z: 5\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - −: 4\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - ?: 3\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - q: 3\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - _: 2\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - v: 2\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - >: 1\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - <: 1\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - *: 1\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - j: 1\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - ø@@: 1\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - °: 1\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - +: 1\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/de-en.de.test.pth ...\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - 75485 words (83 unique) in 500 sentences.\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - 681 unknown words (29 unique), covering 0.90% of the data.\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - x: 196\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - 9@@: 68\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - 6: 45\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - :: 45\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - 4@@: 39\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - w@@: 38\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - 7: 36\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - 6@@: 31\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - 8@@: 30\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - k@@: 29\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - z@@: 25\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - b: 19\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - p: 17\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - ,@@: 12\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - œ@@: 11\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - v: 7\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - %: 5\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - q: 5\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - z: 5\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - j: 3\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - •: 3\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - °: 2\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - @: 2\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - *: 2\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - −: 2\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - γ: 1\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - >: 1\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - <: 1\n",
      "INFO - 05/14/20 16:03:41 - 0:00:00 - ?: 1\n",
      "INFO - 05/14/20 16:03:42 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/de-en.en.train.pth ...\n",
      "INFO - 05/14/20 16:03:42 - 0:00:00 - 544682 words (83 unique) in 4001 sentences.\n",
      "INFO - 05/14/20 16:03:42 - 0:00:00 - 10054 unknown words (47 unique), covering 1.85% of the data.\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/de-en.en.valid.pth ...\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - 66317 words (83 unique) in 500 sentences.\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - 1254 unknown words (28 unique), covering 1.89% of the data.\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - w@@: 569\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - k@@: 189\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - z@@: 87\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - 9@@: 68\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - p: 52\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - :: 46\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - 6: 41\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - 7: 38\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - 4@@: 29\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - b: 28\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - 6@@: 24\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - 8@@: 19\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - x: 17\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - ,@@: 14\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - $: 9\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - v: 5\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - ?: 3\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - z: 3\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - q: 3\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - _: 2\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - >: 1\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - <: 1\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - ∗: 1\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - j: 1\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - ø@@: 1\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - €: 1\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - °: 1\n",
      "INFO - 05/14/20 16:03:43 - 0:00:00 - +: 1\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/de-en.en.test.pth ...\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - 67592 words (83 unique) in 500 sentences.\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - 1389 unknown words (26 unique), covering 2.05% of the data.\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - w@@: 656\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - k@@: 180\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - z@@: 91\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - 9@@: 72\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - p: 65\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - 4@@: 49\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - 6: 46\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - :: 43\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - 7: 35\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - 8@@: 33\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - 6@@: 31\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - b: 20\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - x: 15\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - v: 11\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - $: 10\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - ,@@: 10\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - q: 5\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - •: 3\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - <: 2\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - @: 2\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - *: 2\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - =: 2\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - %: 2\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - z: 2\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - γ: 1\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - >: 1\n",
      "INFO - 05/14/20 16:03:44 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/de-fr.de.train.pth ...\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - 627614 words (83 unique) in 4001 sentences.\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - 5387 unknown words (53 unique), covering 0.86% of the data.\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/de-fr.de.valid.pth ...\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - 74507 words (83 unique) in 500 sentences.\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - 667 unknown words (29 unique), covering 0.90% of the data.\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - x: 190\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - 9@@: 66\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - k@@: 50\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - :: 47\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - 6: 41\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - 7: 38\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - 4@@: 34\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - z@@: 32\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - w@@: 28\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - ,@@: 25\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - 6@@: 23\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - 8@@: 19\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - b: 16\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - œ@@: 13\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - p: 12\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - %: 7\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - z: 5\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - −: 4\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - ?: 3\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - q: 3\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - _: 2\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - v: 2\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - >: 1\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - <: 1\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - *: 1\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - j: 1\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - ø@@: 1\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - °: 1\n",
      "INFO - 05/14/20 16:03:45 - 0:00:00 - +: 1\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/de-fr.de.test.pth ...\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - 75485 words (83 unique) in 500 sentences.\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - 681 unknown words (29 unique), covering 0.90% of the data.\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - x: 196\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - 9@@: 68\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - 6: 45\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - :: 45\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - 4@@: 39\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - w@@: 38\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - 7: 36\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - 6@@: 31\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - 8@@: 30\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - k@@: 29\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - z@@: 25\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - b: 19\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - p: 17\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - ,@@: 12\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - œ@@: 11\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - v: 7\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - %: 5\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - q: 5\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - z: 5\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - j: 3\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - •: 3\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - °: 2\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - @: 2\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - *: 2\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - −: 2\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - γ: 1\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - >: 1\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - <: 1\n",
      "INFO - 05/14/20 16:03:46 - 0:00:00 - ?: 1\n",
      "INFO - 05/14/20 16:03:47 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/de-fr.fr.train.pth ...\n",
      "INFO - 05/14/20 16:03:47 - 0:00:00 - 627614 words (83 unique) in 4001 sentences.\n",
      "INFO - 05/14/20 16:03:47 - 0:00:00 - 5386 unknown words (53 unique), covering 0.86% of the data.\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/de-fr.fr.valid.pth ...\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - 74507 words (83 unique) in 500 sentences.\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - 667 unknown words (29 unique), covering 0.90% of the data.\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - x: 190\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - 9@@: 66\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - k@@: 50\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - :: 47\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - 6: 41\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - 7: 38\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - 4@@: 34\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - z@@: 32\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - w@@: 28\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - ,@@: 25\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - 6@@: 23\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - 8@@: 19\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - b: 16\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - œ@@: 13\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - p: 12\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - %: 7\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - z: 5\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - −: 4\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - ?: 3\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - q: 3\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - _: 2\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - v: 2\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - >: 1\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - <: 1\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - *: 1\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - j: 1\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - ø@@: 1\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - °: 1\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - +: 1\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/de-fr.fr.test.pth ...\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - 75485 words (83 unique) in 500 sentences.\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - 681 unknown words (29 unique), covering 0.90% of the data.\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - x: 196\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - 9@@: 68\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - 6: 45\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - :: 45\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - 4@@: 39\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - w@@: 38\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - 7: 36\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - 6@@: 31\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - 8@@: 30\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - k@@: 29\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - z@@: 25\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - b: 19\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - p: 17\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - ,@@: 12\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - œ@@: 11\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - v: 7\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - %: 5\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - q: 5\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - z: 5\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - j: 3\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - •: 3\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - °: 2\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - @: 2\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - *: 2\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - −: 2\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - γ: 1\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - >: 1\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - <: 1\n",
      "INFO - 05/14/20 16:03:48 - 0:00:00 - ?: 1\n",
      "INFO - 05/14/20 16:03:49 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/train.en.pth ...\n",
      "INFO - 05/14/20 16:03:50 - 0:00:01 - 1806755 words (83 unique) in 12604 sentences.\n",
      "INFO - 05/14/20 16:03:50 - 0:00:01 - 26709 unknown words (57 unique), covering 1.48% of the data.\n",
      "INFO - 05/14/20 16:03:51 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/fine_tune/train.en.pth ...\n",
      "INFO - 05/14/20 16:03:51 - 0:00:00 - 194167 words (83 unique) in 1400 sentences.\n",
      "INFO - 05/14/20 16:03:51 - 0:00:00 - 2776 unknown words (42 unique), covering 1.43% of the data.\n",
      "INFO - 05/14/20 16:03:51 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/valid.en.pth ...\n",
      "INFO - 05/14/20 16:03:52 - 0:00:01 - 1366322 words (83 unique) in 9453 sentences.\n",
      "INFO - 05/14/20 16:03:52 - 0:00:01 - 18533 unknown words (63 unique), covering 1.36% of the data.\n",
      "INFO - 05/14/20 16:03:53 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/fine_tune/valid.en.pth ...\n",
      "INFO - 05/14/20 16:03:53 - 0:00:00 - 156238 words (83 unique) in 1050 sentences.\n",
      "INFO - 05/14/20 16:03:53 - 0:00:00 - 2155 unknown words (33 unique), covering 1.38% of the data.\n",
      "INFO - 05/14/20 16:03:53 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/test.en.pth ...\n",
      "INFO - 05/14/20 16:03:54 - 0:00:01 - 1367773 words (83 unique) in 9453 sentences.\n",
      "INFO - 05/14/20 16:03:54 - 0:00:01 - 18649 unknown words (62 unique), covering 1.36% of the data.\n",
      "INFO - 05/14/20 16:03:55 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/fine_tune/test.en.pth ...\n",
      "INFO - 05/14/20 16:03:55 - 0:00:00 - 156062 words (83 unique) in 1050 sentences.\n",
      "INFO - 05/14/20 16:03:55 - 0:00:00 - 2174 unknown words (32 unique), covering 1.39% of the data.\n",
      "INFO - 05/14/20 16:03:56 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/train.fr.pth ...\n",
      "INFO - 05/14/20 16:03:57 - 0:00:01 - 1882740 words (83 unique) in 12604 sentences.\n",
      "INFO - 05/14/20 16:03:57 - 0:00:01 - 22517 unknown words (62 unique), covering 1.20% of the data.\n",
      "INFO - 05/14/20 16:03:57 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/fine_tune/train.fr.pth ...\n",
      "INFO - 05/14/20 16:03:58 - 0:00:00 - 201112 words (83 unique) in 1400 sentences.\n",
      "INFO - 05/14/20 16:03:58 - 0:00:00 - 2300 unknown words (44 unique), covering 1.14% of the data.\n",
      "INFO - 05/14/20 16:03:58 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/valid.fr.pth ...\n",
      "INFO - 05/14/20 16:03:59 - 0:00:01 - 1373916 words (83 unique) in 9453 sentences.\n",
      "INFO - 05/14/20 16:03:59 - 0:00:01 - 17988 unknown words (62 unique), covering 1.31% of the data.\n",
      "INFO - 05/14/20 16:04:00 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/fine_tune/valid.fr.pth ...\n",
      "INFO - 05/14/20 16:04:00 - 0:00:00 - 156834 words (83 unique) in 1050 sentences.\n",
      "INFO - 05/14/20 16:04:00 - 0:00:00 - 2113 unknown words (33 unique), covering 1.35% of the data.\n",
      "INFO - 05/14/20 16:04:00 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/test.fr.pth ...\n",
      "INFO - 05/14/20 16:04:01 - 0:00:01 - 1374815 words (83 unique) in 9453 sentences.\n",
      "INFO - 05/14/20 16:04:01 - 0:00:01 - 18010 unknown words (62 unique), covering 1.31% of the data.\n",
      "INFO - 05/14/20 16:04:02 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/fine_tune/test.fr.pth ...\n",
      "INFO - 05/14/20 16:04:02 - 0:00:00 - 156913 words (83 unique) in 1050 sentences.\n",
      "INFO - 05/14/20 16:04:02 - 0:00:00 - 2105 unknown words (32 unique), covering 1.34% of the data.\n",
      "INFO - 05/14/20 16:04:02 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/train.de.pth ...\n",
      "INFO - 05/14/20 16:04:04 - 0:00:01 - 2083811 words (83 unique) in 14003 sentences.\n",
      "INFO - 05/14/20 16:04:04 - 0:00:01 - 24819 unknown words (63 unique), covering 1.19% of the data.\n",
      "INFO - 05/14/20 16:04:04 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/valid.de.pth ...\n",
      "INFO - 05/14/20 16:04:05 - 0:00:01 - 1530704 words (83 unique) in 10502 sentences.\n",
      "INFO - 05/14/20 16:04:05 - 0:00:01 - 20099 unknown words (63 unique), covering 1.31% of the data.\n",
      "INFO - 05/14/20 16:04:06 - 0:00:00 - Read 83 words from the vocabulary file.\n",
      "\n",
      "Saving the data to data/enfrde/processed/test.de.pth ...\n",
      "INFO - 05/14/20 16:04:07 - 0:00:01 - 1531682 words (83 unique) in 10502 sentences.\n",
      "INFO - 05/14/20 16:04:07 - 0:00:01 - 20113 unknown words (63 unique), covering 1.31% of the data.\n",
      "file data/enfrde/processed/train.en.pth already exists\n",
      "file data/enfrde/processed/fine_tune/train.en.pth already exists\n",
      "file data/enfrde/processed/valid.en.pth already exists\n",
      "file data/enfrde/processed/fine_tune/valid.en.pth already exists\n",
      "file data/enfrde/processed/test.en.pth already exists\n",
      "file data/enfrde/processed/fine_tune/test.en.pth already exists\n",
      "file data/enfrde/processed/train.de.pth already exists\n",
      "file data/enfrde/processed/valid.de.pth already exists\n",
      "file data/enfrde/processed/test.de.pth already exists\n",
      "file data/enfrde/processed/train.fr.pth already exists\n",
      "file data/enfrde/processed/fine_tune/train.fr.pth already exists\n",
      "file data/enfrde/processed/valid.fr.pth already exists\n",
      "file data/enfrde/processed/fine_tune/valid.fr.pth already exists\n",
      "file data/enfrde/processed/test.fr.pth already exists\n",
      "file data/enfrde/processed/fine_tune/test.fr.pth already exists\n",
      "\n",
      "\n",
      "***Creat the file to train the XLM model with MLM+TLM objective***\n",
      "\n",
      "\n",
      "*** build data with succes : dir data/enfrde/processed ***\n"
     ]
    }
   ],
   "source": [
    "! ../build_meta_data.sh $sub_task $n_samples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: exp_id=maml\n",
      "env: lgs=en-fr|de-en|de-fr\n",
      "env: batch_size=2\n",
      "env: max_epoch=1\n",
      "env: epoch_size=100\n",
      "env: train_n_samples=80\n",
      "env: valid_n_samples=10\n",
      "env: test_n_samples=10\n"
     ]
    }
   ],
   "source": [
    "%env exp_id=maml\n",
    "%env lgs=en-fr|de-en|de-fr\n",
    "#%env lgs=en-fr|de-fr\n",
    "\n",
    "%env batch_size=2\n",
    "%env max_epoch=1\n",
    "%env epoch_size=100\n",
    "\n",
    "# limit the number of examples (-1 by default for non limitation)\n",
    "%env train_n_samples=80\n",
    "%env valid_n_samples=10\n",
    "%env test_n_samples=10\n",
    "#--train_n_samples $train_n_samples --valid_n_samples $valid_n_samples --test_n_samples $test_n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: remove_long_sentences_train=True\n",
      "env: remove_long_sentences_valid=True\n",
      "env: remove_long_sentences_test=True\n"
     ]
    }
   ],
   "source": [
    "# If you don't have enough RAM or swap memory, leave these three parameters to True, otherwise you may get an error like this when evaluating \n",
    "# RuntimeError: copy_if failed to synchronize: cudaErrorAssert: device-side assert triggered\n",
    "%env remove_long_sentences_train=True\n",
    "%env remove_long_sentences_valid=True\n",
    "%env remove_long_sentences_test=True\n",
    "#--remove_long_sentences_train $remove_long_sentences_train --remove_long_sentences_valid $remove_long_sentences_valid --remove_long_sentences_test $remove_long_sentences_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain a language meta-model (MLM + TLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: stopping_criterion=_valid_mlm_ppl,10\n",
      "env: eval_bleu=false\n"
     ]
    }
   ],
   "source": [
    "# stopping criterion (if criterion does not improve 10 times)\n",
    "%env stopping_criterion=_valid_mlm_ppl,10\n",
    "%env eval_bleu false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: mlm_steps=en,fr,en-fr|en,de,en-de|de,fr,de-fr\n",
      "FAISS library was not found.\n",
      "FAISS not available. Switching to standard nearest neighbors search implementation.\n",
      "SLURM job: False\n",
      "0 - Number of nodes: 1\n",
      "0 - Node ID        : 0\n",
      "0 - Local rank     : 0\n",
      "0 - Global rank    : 0\n",
      "0 - World size     : 1\n",
      "0 - GPUs per node  : 1\n",
      "0 - Master         : True\n",
      "0 - Multi-node     : False\n",
      "0 - Multi-GPU      : False\n",
      "0 - Hostname       : african-translator-vm\n",
      "INFO - 05/14/20 16:07:01 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 05/14/20 16:07:01 - 0:00:00 - accumulate_gradients: 1\n",
      "                                     ae_steps: [[], [], []]\n",
      "                                     amp: -1\n",
      "                                     asm: False\n",
      "                                     attention_dropout: 0.1\n",
      "                                     batch_size: 2\n",
      "                                     beam_size: 1\n",
      "                                     bptt: 256\n",
      "                                     bt_src_langs: []\n",
      "                                     bt_steps: [[], [], []]\n",
      "                                     clip_grad_norm: 5\n",
      "                                     clm_steps: [[], [], []]\n",
      "                                     command: python train.py --exp_name mlm_enfrde --exp_id maml --dump_path './dumped/' --data_path 'data/enfrde/processed' --lgs 'en-fr|de-en|de-fr' --clm_steps '' --mlm_steps 'en,fr,en-fr|en,de,en-de|de,fr,de-fr' --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 2 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 100 --max_epoch 1 --validation_metrics _valid_mlm_ppl --stopping_criterion '_valid_mlm_ppl,10' --eval_bleu false --remove_long_sentences_train True --remove_long_sentences_valid True --remove_long_sentences_test True --train_n_samples 80 --valid_n_samples 10 --test_n_samples 10 --exp_id \"maml\"\n",
      "                                     context_size: 0\n",
      "                                     data_path: data/enfrde/processed\n",
      "                                     debug: False\n",
      "                                     debug_slurm: False\n",
      "                                     debug_train: False\n",
      "                                     dropout: 0.1\n",
      "                                     dump_path: ./dumped/mlm_enfrde/maml\n",
      "                                     early_stopping: False\n",
      "                                     emb_dim: 1024\n",
      "                                     encoder_only: True\n",
      "                                     epoch_size: 100\n",
      "                                     eval_bleu: False\n",
      "                                     eval_only: False\n",
      "                                     exp_id: maml\n",
      "                                     exp_name: mlm_enfrde\n",
      "                                     fp16: False\n",
      "                                     gelu_activation: True\n",
      "                                     global_rank: 0\n",
      "                                     group_by_size: True\n",
      "                                     id2lang: {0: 'de', 1: 'fr'}\n",
      "                                     is_master: True\n",
      "                                     is_slurm_job: False\n",
      "                                     lambda_ae: 1\n",
      "                                     lambda_bt: 1\n",
      "                                     lambda_clm: 1\n",
      "                                     lambda_mlm: 1\n",
      "                                     lambda_mt: 1\n",
      "                                     lambda_pc: 1\n",
      "                                     lang2id: {'de': 0, 'fr': 1}\n",
      "                                     langs: [['en', 'fr'], ['de', 'en'], ['de', 'fr']]\n",
      "                                     length_penalty: 1\n",
      "                                     lg_sampling_factor: -1\n",
      "                                     lgs: ['en-fr', 'de-en', 'de-fr']\n",
      "                                     local_rank: 0\n",
      "                                     master_port: -1\n",
      "                                     max_batch_size: 0\n",
      "                                     max_epoch: 1\n",
      "                                     max_len: 100\n",
      "                                     max_vocab: -1\n",
      "                                     meta_learning: True\n",
      "                                     meta_params: ...\n",
      "                                     min_count: 0\n",
      "                                     mlm_steps: [[('en', None), ('fr', None), ('en', 'fr')], [('en', None), ('de', None), ('en', 'de')], [('de', None), ('fr', None), ('de', 'fr')]]\n",
      "                                     mono_dataset: {'de': {'train': 'data/enfrde/processed/train.de.pth', 'valid': 'data/enfrde/processed/valid.de.pth', 'test': 'data/enfrde/processed/test.de.pth'}, 'fr': {'train': 'data/enfrde/processed/train.fr.pth', 'valid': 'data/enfrde/processed/valid.fr.pth', 'test': 'data/enfrde/processed/test.fr.pth'}}\n",
      "                                     mt_steps: [[], [], []]\n",
      "                                     multi_gpu: False\n",
      "                                     multi_node: False\n",
      "                                     n_gpu_per_node: 1\n",
      "                                     n_heads: 8\n",
      "                                     n_langs: 2\n",
      "                                     n_layers: 6\n",
      "                                     n_nodes: 1\n",
      "                                     n_samples: {'train': 80, 'valid': 10, 'test': 10}\n",
      "                                     n_task: 3\n",
      "                                     node_id: 0\n",
      "                                     optimizer: adam,lr=0.0001\n",
      "                                     para_dataset: {('de', 'fr'): {'train': ('data/enfrde/processed/train.de-fr.de.pth', 'data/enfrde/processed/train.de-fr.fr.pth'), 'valid': ('data/enfrde/processed/valid.de-fr.de.pth', 'data/enfrde/processed/valid.de-fr.fr.pth'), 'test': ('data/enfrde/processed/test.de-fr.de.pth', 'data/enfrde/processed/test.de-fr.fr.pth')}}\n",
      "                                     pc_steps: [[], [], []]\n",
      "                                     reload_checkpoint: \n",
      "                                     reload_emb: \n",
      "                                     reload_model: \n",
      "                                     remove_long_sentences: {'train': True, 'valid': True, 'test': True}\n",
      "                                     remove_long_sentences_test: True\n",
      "                                     remove_long_sentences_train: True\n",
      "                                     remove_long_sentences_valid: True\n",
      "                                     sample_alpha: 0\n",
      "                                     save_periodic: 0\n",
      "                                     share_inout_emb: True\n",
      "                                     sinusoidal_embeddings: False\n",
      "                                     split_data: False\n",
      "                                     stopping_criterion: _valid_mlm_ppl,10\n",
      "                                     test_n_samples: 10\n",
      "                                     tokens_per_batch: -1\n",
      "                                     train_n_samples: 80\n",
      "                                     use_lang_emb: True\n",
      "                                     use_memory: False\n",
      "                                     valid_n_samples: 10\n",
      "                                     validation_metrics: _valid_mlm_ppl\n",
      "                                     word_blank: 0\n",
      "                                     word_dropout: 0\n",
      "                                     word_keep: 0.1\n",
      "                                     word_mask: 0.8\n",
      "                                     word_mask_keep_rand: 0.8,0.1,0.1\n",
      "                                     word_pred: 0.15\n",
      "                                     word_rand: 0.1\n",
      "                                     word_shuffle: 0\n",
      "                                     world_size: 1\n",
      "INFO - 05/14/20 16:07:01 - 0:00:00 - The experiment will be stored in ./dumped/mlm_enfrde/maml\n",
      "                                     \n",
      "INFO - 05/14/20 16:07:01 - 0:00:00 - Running command: python train.py --exp_name mlm_enfrde --exp_id maml --dump_path './dumped/' --data_path 'data/enfrde/processed' --lgs 'en-fr|de-en|de-fr' --clm_steps '' --mlm_steps 'en,fr,en-fr|en,de,en-de|de,fr,de-fr' --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 2 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 100 --max_epoch 1 --validation_metrics _valid_mlm_ppl --stopping_criterion '_valid_mlm_ppl,10' --eval_bleu false --remove_long_sentences_train True --remove_long_sentences_valid True --remove_long_sentences_test True --train_n_samples 80 --valid_n_samples 10 --test_n_samples 10\n",
      "\n",
      "WARNING - 05/14/20 16:07:01 - 0:00:00 - Signal handler installed.\n",
      "INFO - 05/14/20 16:07:01 - 0:00:00 - ============ langs: en, fr\n",
      "INFO - 05/14/20 16:07:01 - 0:00:00 - ============ Monolingual data (en)\n",
      "INFO - 05/14/20 16:07:01 - 0:00:00 - Loading data from data/enfrde/processed/train.en.pth ...\n",
      "INFO - 05/14/20 16:07:01 - 0:00:00 - 1806755 words (83 unique) in 12604 sentences. 26709 unknown words (57 unique) covering 1.48% of the data.\n",
      "INFO - 05/14/20 16:07:01 - 0:00:00 - Selecting batches from 0 to 22 ...\n",
      "\n",
      "INFO - 05/14/20 16:07:01 - 0:00:00 - Loading data from data/enfrde/processed/valid.en.pth ...\n",
      "INFO - 05/14/20 16:07:01 - 0:00:00 - 1366322 words (83 unique) in 9453 sentences. 18533 unknown words (63 unique) covering 1.36% of the data.\n",
      "INFO - 05/14/20 16:07:01 - 0:00:00 - Selecting batches from 0 to 5 ...\n",
      "\n",
      "INFO - 05/14/20 16:07:01 - 0:00:00 - Loading data from data/enfrde/processed/test.en.pth ...\n",
      "INFO - 05/14/20 16:07:01 - 0:00:00 - 1367773 words (83 unique) in 9453 sentences. 18649 unknown words (62 unique) covering 1.36% of the data.\n",
      "INFO - 05/14/20 16:07:01 - 0:00:00 - Selecting batches from 0 to 5 ...\n",
      "\n",
      "INFO - 05/14/20 16:07:01 - 0:00:00 - ============ Monolingual data (fr)\n",
      "INFO - 05/14/20 16:07:01 - 0:00:00 - Loading data from data/enfrde/processed/train.fr.pth ...\n",
      "INFO - 05/14/20 16:07:01 - 0:00:00 - 1882740 words (83 unique) in 12604 sentences. 22517 unknown words (62 unique) covering 1.20% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting batches from 0 to 23 ...\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/valid.fr.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 1373916 words (83 unique) in 9453 sentences. 17988 unknown words (62 unique) covering 1.31% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting batches from 0 to 5 ...\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/test.fr.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 1374815 words (83 unique) in 9453 sentences. 18010 unknown words (62 unique) covering 1.31% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting batches from 0 to 5 ...\n",
      "\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - ============ Parallel data (en-fr)\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/train.en-fr.en.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 492009 words (83 unique) in 3602 sentences. 9099 unknown words (46 unique) covering 1.85% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/train.en-fr.fr.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 567418 words (83 unique) in 3602 sentences. 4944 unknown words (51 unique) covering 0.87% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Removed 2270 too long sentences.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting sentences from 0 to 80 ...\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/valid.en-fr.en.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 58513 words (83 unique) in 451 sentences. 1125 unknown words (28 unique) covering 1.92% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/valid.en-fr.fr.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 66586 words (83 unique) in 451 sentences. 601 unknown words (29 unique) covering 0.90% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Removed 279 too long sentences.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting sentences from 0 to 10 ...\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/test.en-fr.en.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 61684 words (83 unique) in 451 sentences. 1257 unknown words (26 unique) covering 2.04% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/test.en-fr.fr.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 69085 words (83 unique) in 451 sentences. 637 unknown words (29 unique) covering 0.92% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Removed 297 too long sentences.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting sentences from 0 to 10 ...\n",
      "\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - ============ Data summary\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Monolingual data   - train -           en:       362\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Monolingual data   - valid -           en:       236\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Monolingual data   -  test -           en:        66\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Monolingual data   - train -           fr:       157\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Monolingual data   - valid -           fr:        67\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Monolingual data   -  test -           fr:       191\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Parallel data      - train -        en-fr:        80\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Parallel data      - valid -        en-fr:        10\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Parallel data      -  test -        en-fr:        10\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - ============ langs: de, en\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - ============ Monolingual data (de)\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/train.de.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 2083811 words (83 unique) in 14003 sentences. 24819 unknown words (63 unique) covering 1.19% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting batches from 0 to 23 ...\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/valid.de.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 1530704 words (83 unique) in 10502 sentences. 20099 unknown words (63 unique) covering 1.31% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting batches from 0 to 5 ...\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/test.de.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 1531682 words (83 unique) in 10502 sentences. 20113 unknown words (63 unique) covering 1.31% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting batches from 0 to 5 ...\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - ============ Monolingual data (en)\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/train.en.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 1806755 words (83 unique) in 12604 sentences. 26709 unknown words (57 unique) covering 1.48% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting batches from 0 to 22 ...\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/valid.en.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 1366322 words (83 unique) in 9453 sentences. 18533 unknown words (63 unique) covering 1.36% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting batches from 0 to 5 ...\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/test.en.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 1367773 words (83 unique) in 9453 sentences. 18649 unknown words (62 unique) covering 1.36% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting batches from 0 to 5 ...\n",
      "\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - ============ Parallel data (de-en)\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/train.de-en.de.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 627614 words (83 unique) in 4001 sentences. 5387 unknown words (53 unique) covering 0.86% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/train.de-en.en.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 544682 words (83 unique) in 4001 sentences. 10054 unknown words (47 unique) covering 1.85% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Removed 2520 too long sentences.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting sentences from 0 to 80 ...\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/valid.de-en.de.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 74507 words (83 unique) in 500 sentences. 667 unknown words (29 unique) covering 0.90% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/valid.de-en.en.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 66317 words (83 unique) in 500 sentences. 1254 unknown words (28 unique) covering 1.89% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Removed 310 too long sentences.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting sentences from 0 to 10 ...\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/test.de-en.de.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 75485 words (83 unique) in 500 sentences. 681 unknown words (29 unique) covering 0.90% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/test.de-en.en.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 67592 words (83 unique) in 500 sentences. 1389 unknown words (26 unique) covering 2.05% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Removed 325 too long sentences.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting sentences from 0 to 10 ...\n",
      "\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - ============ Data summary\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Monolingual data   - train -           de:       438\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Monolingual data   - valid -           de:       175\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Monolingual data   -  test -           de:       223\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Monolingual data   - train -           en:       362\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Monolingual data   - valid -           en:       236\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Monolingual data   -  test -           en:        66\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Parallel data      - train -        de-en:        80\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Parallel data      - valid -        de-en:        10\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Parallel data      -  test -        de-en:        10\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - ============ langs: de, fr\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - ============ Monolingual data (de)\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/train.de.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 2083811 words (83 unique) in 14003 sentences. 24819 unknown words (63 unique) covering 1.19% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting batches from 0 to 23 ...\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/valid.de.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 1530704 words (83 unique) in 10502 sentences. 20099 unknown words (63 unique) covering 1.31% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting batches from 0 to 5 ...\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/test.de.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 1531682 words (83 unique) in 10502 sentences. 20113 unknown words (63 unique) covering 1.31% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting batches from 0 to 5 ...\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - ============ Monolingual data (fr)\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/train.fr.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 1882740 words (83 unique) in 12604 sentences. 22517 unknown words (62 unique) covering 1.20% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting batches from 0 to 23 ...\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/valid.fr.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 1373916 words (83 unique) in 9453 sentences. 17988 unknown words (62 unique) covering 1.31% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting batches from 0 to 5 ...\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/test.fr.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 1374815 words (83 unique) in 9453 sentences. 18010 unknown words (62 unique) covering 1.31% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting batches from 0 to 5 ...\n",
      "\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - ============ Parallel data (de-fr)\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/train.de-fr.de.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 627614 words (83 unique) in 4001 sentences. 5387 unknown words (53 unique) covering 0.86% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/train.de-fr.fr.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 627614 words (83 unique) in 4001 sentences. 5386 unknown words (53 unique) covering 0.86% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Removed 2473 too long sentences.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting sentences from 0 to 80 ...\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/valid.de-fr.de.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 74507 words (83 unique) in 500 sentences. 667 unknown words (29 unique) covering 0.90% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/valid.de-fr.fr.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 74507 words (83 unique) in 500 sentences. 667 unknown words (29 unique) covering 0.90% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Removed 304 too long sentences.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting sentences from 0 to 10 ...\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/test.de-fr.de.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 75485 words (83 unique) in 500 sentences. 681 unknown words (29 unique) covering 0.90% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Loading data from data/enfrde/processed/test.de-fr.fr.pth ...\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - 75485 words (83 unique) in 500 sentences. 681 unknown words (29 unique) covering 0.90% of the data.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Removed 318 too long sentences.\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Selecting sentences from 0 to 10 ...\n",
      "\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - ============ Data summary\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Monolingual data   - train -           de:       438\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Monolingual data   - valid -           de:       175\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Monolingual data   -  test -           de:       223\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Monolingual data   - train -           fr:       157\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Monolingual data   - valid -           fr:        67\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Monolingual data   -  test -           fr:       191\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Parallel data      - train -        de-fr:        80\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Parallel data      - valid -        de-fr:        10\n",
      "INFO - 05/14/20 16:07:02 - 0:00:00 - Parallel data      -  test -        de-fr:        10\n",
      "\n",
      "INFO - 05/14/20 16:07:02 - 0:00:01 - Model: TransformerModel(\n",
      "                                       (position_embeddings): Embedding(512, 1024)\n",
      "                                       (lang_embeddings): Embedding(2, 1024)\n",
      "                                       (embeddings): Embedding(83, 1024, padding_idx=2)\n",
      "                                       (layer_norm_emb): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                       (attentions): ModuleList(\n",
      "                                         (0): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (1): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (2): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (3): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (4): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (5): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                       )\n",
      "                                       (layer_norm1): ModuleList(\n",
      "                                         (0): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (2): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (3): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (4): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (5): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                       )\n",
      "                                       (ffns): ModuleList(\n",
      "                                         (0): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (1): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (2): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (3): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (4): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (5): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                       )\n",
      "                                       (layer_norm2): ModuleList(\n",
      "                                         (0): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (2): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (3): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (4): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (5): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                       )\n",
      "                                       (memories): ModuleDict()\n",
      "                                       (pred_layer): PredLayer(\n",
      "                                         (proj): Linear(in_features=1024, out_features=83, bias=True)\n",
      "                                       )\n",
      "                                     )\n",
      "INFO - 05/14/20 16:07:02 - 0:00:01 - Number of parameters (model): 76190803\n",
      "INFO - 05/14/20 16:07:05 - 0:00:04 - Found 0 memories.\n",
      "INFO - 05/14/20 16:07:05 - 0:00:04 - Found 6 FFN.\n",
      "INFO - 05/14/20 16:07:05 - 0:00:04 - Found 102 parameters in model.\n",
      "INFO - 05/14/20 16:07:05 - 0:00:04 - Optimizers: model\n",
      "INFO - 05/14/20 16:07:06 - 0:00:04 - ============ Starting epoch 0 ... ============\n",
      "INFO - 05/14/20 16:07:06 - 0:00:04 - Creating new training data iterator (pred,en) ...\n",
      "INFO - 05/14/20 16:07:07 - 0:00:05 - Creating new training data iterator (pred,fr) ...\n",
      "INFO - 05/14/20 16:07:07 - 0:00:05 - Creating new training data iterator (pred,en,fr) ...\n",
      "INFO - 05/14/20 16:07:07 - 0:00:05 - Creating new training data iterator (pred,de) ...\n",
      "INFO - 05/14/20 16:07:07 - 0:00:05 - Creating new training data iterator (pred,en,de) ...\n",
      "INFO - 05/14/20 16:07:07 - 0:00:06 - Creating new training data iterator (pred,de,fr) ...\n",
      "INFO - 05/14/20 16:07:12 - 0:00:11 - task : en-fr ||      5 -    4.22 sent/s -   126.60 words/s - MLM-en:  5.4441 || MLM-fr:  4.2955 || MLM-en-fr:  4.2346 -  - model LR: 1.0000e-04\n",
      "INFO - 05/14/20 16:07:12 - 0:00:11 - task : de-en ||      5 - 65433.76 sent/s - 2002273.05 words/s - MLM-de:  4.0660 || MLM-en-de:  3.7088 -  - model LR: 1.0000e-04\n",
      "INFO - 05/14/20 16:07:12 - 0:00:11 - task : de-fr ||      5 - 147168.56 sent/s - 4135436.58 words/s - MLM-de:  3.6580 || MLM-de-fr:  3.8299 -  - model LR: 1.0000e-04\n",
      "INFO - 05/14/20 16:07:13 - 0:00:12 - Creating new training data iterator (pred,de) ...\n",
      "INFO - 05/14/20 16:07:19 - 0:00:17 - task : en-fr ||     10 -    4.75 sent/s -   291.66 words/s - MLM-en:  3.7584 || MLM-fr:  3.5958 || MLM-en-fr:  3.6289 -  - model LR: 1.0000e-04\n",
      "INFO - 05/14/20 16:07:19 - 0:00:17 - task : de-en ||     10 - 35128.17 sent/s - 2173263.04 words/s - MLM-de:  3.5587 || MLM-en-de:  3.7156 -  - model LR: 1.0000e-04\n",
      "INFO - 05/14/20 16:07:19 - 0:00:17 - task : de-fr ||     10 - 113975.65 sent/s - 7020900.17 words/s - MLM-de:  3.5321 || MLM-de-fr:  3.4429 -  - model LR: 1.0000e-04\n",
      "INFO - 05/14/20 16:07:21 - 0:00:19 - Creating new training data iterator (pred,de) ...\n",
      "INFO - 05/14/20 16:07:25 - 0:00:24 - task : en-fr ||     15 -    4.69 sent/s -   438.05 words/s - MLM-en:  3.6854 || MLM-fr:  3.5496 || MLM-en-fr:  3.6639 -  - model LR: 1.0000e-04\n",
      "INFO - 05/14/20 16:07:25 - 0:00:24 - task : de-en ||     15 - 37128.69 sent/s - 3543314.36 words/s - MLM-de:  4.7296 || MLM-en-de:  3.5637 -  - model LR: 1.0000e-04\n",
      "INFO - 05/14/20 16:07:25 - 0:00:24 - task : de-fr ||     15 - 142340.63 sent/s - 13147529.85 words/s - MLM-de:  3.5276 || MLM-de-fr:  3.6943 -  - model LR: 1.0000e-04\n",
      "INFO - 05/14/20 16:07:27 - 0:00:26 - ============ End of epoch 0 ============\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - epoch -> 0.000000\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - valid_en_mlm_ppl -> 26.237319\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - valid_en_mlm_acc -> 18.500000\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - valid_fr_mlm_ppl -> 42.789887\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - valid_fr_mlm_acc -> 6.500000\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - valid_en_fr_mlm_ppl -> 39.355871\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - valid_en_fr_mlm_acc -> 1.639344\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - valid_mlm_ppl -> 33.714349\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - valid_mlm_acc -> 10.500000\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - valid_de_mlm_ppl -> 24.638811\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - valid_de_mlm_acc -> 14.500000\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - valid_en_de_mlm_ppl -> 49.139343\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - valid_en_de_mlm_acc -> 2.409639\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - valid_de_fr_mlm_ppl -> 39.081973\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - valid_de_fr_mlm_acc -> 3.888889\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - test_en_mlm_ppl -> 36.282587\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - test_en_mlm_acc -> 6.500000\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - test_fr_mlm_ppl -> 26.277349\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - test_fr_mlm_acc -> 16.000000\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - test_en_fr_mlm_ppl -> 29.177070\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - test_en_fr_mlm_acc -> 3.048780\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - test_mlm_ppl -> 26.648849\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - test_mlm_acc -> 17.000000\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - test_de_mlm_ppl -> 27.020349\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - test_de_mlm_acc -> 18.000000\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - test_en_de_mlm_ppl -> 39.298160\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - test_en_de_mlm_acc -> 1.183432\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - test_de_fr_mlm_ppl -> 34.680846\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - test_de_fr_mlm_acc -> 0.995025\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - __log__:{\"epoch\": 0, \"valid_en_mlm_ppl\": 26.23731876187388, \"valid_en_mlm_acc\": 18.5, \"valid_fr_mlm_ppl\": 42.78988744464152, \"valid_fr_mlm_acc\": 6.5, \"valid_en_fr_mlm_ppl\": 39.3558714275232, \"valid_en_fr_mlm_acc\": 1.639344262295082, \"valid_mlm_ppl\": 33.714348975861654, \"valid_mlm_acc\": 10.5, \"valid_de_mlm_ppl\": 24.63881050708178, \"valid_de_mlm_acc\": 14.5, \"valid_en_de_mlm_ppl\": 49.13934344452561, \"valid_en_de_mlm_acc\": 2.4096385542168677, \"valid_de_fr_mlm_ppl\": 39.08197275648095, \"valid_de_fr_mlm_acc\": 3.888888888888889, \"test_en_mlm_ppl\": 36.28258668135229, \"test_en_mlm_acc\": 6.5, \"test_fr_mlm_ppl\": 26.277349302835233, \"test_fr_mlm_acc\": 16.0, \"test_en_fr_mlm_ppl\": 29.177069527440807, \"test_en_fr_mlm_acc\": 3.048780487804878, \"test_mlm_ppl\": 26.648848943878058, \"test_mlm_acc\": 17.0, \"test_de_mlm_ppl\": 27.02034858492088, \"test_de_mlm_acc\": 18.0, \"test_en_de_mlm_ppl\": 39.29815963451262, \"test_en_de_mlm_acc\": 1.183431952662722, \"test_de_fr_mlm_ppl\": 34.68084606324056, \"test_de_fr_mlm_acc\": 0.9950248756218906}\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - New best score for valid_mlm_ppl: 33.714349\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - Saving best-valid_mlm_ppl to ./dumped/mlm_enfrde/maml/best-valid_mlm_ppl.pth ...\n",
      "WARNING - 05/14/20 16:07:29 - 0:00:27 - Saving model parameters ...\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - New best validation score: 33.714349\n",
      "INFO - 05/14/20 16:07:29 - 0:00:27 - Saving checkpoint to ./dumped/mlm_enfrde/maml/checkpoint.pth ...\n",
      "WARNING - 05/14/20 16:07:29 - 0:00:27 - Saving model parameters ...\n",
      "WARNING - 05/14/20 16:07:29 - 0:00:27 - Saving model optimizer ...\n",
      "INFO - 05/14/20 16:07:30 - 0:00:28 - ============= garbage collector collecting 0 ...\n"
     ]
    }
   ],
   "source": [
    "# MLM\n",
    "#%env mlm_steps=en,fr|en,de|de,fr\n",
    "# MLM + TML\n",
    "%env mlm_steps=en,fr,en-fr|en,de,en-de|de,fr,de-fr\n",
    "\n",
    "! python train.py --exp_name mlm_enfrde --exp_id $exp_id --dump_path ./dumped/ --data_path $OUTPATH --lgs $lgs --clm_steps '' --mlm_steps $mlm_steps --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout 0.1 --attention_dropout 0.1 --gelu_activation true --batch_size $batch_size --bptt 256 --optimizer adam,lr=0.0001 --epoch_size $epoch_size --max_epoch $max_epoch --validation_metrics _valid_mlm_ppl --stopping_criterion $stopping_criterion --eval_bleu $eval_bleu --remove_long_sentences_train $remove_long_sentences_train --remove_long_sentences_valid $remove_long_sentences_valid --remove_long_sentences_test $remove_long_sentences_test --train_n_samples $train_n_samples --valid_n_samples $valid_n_samples --test_n_samples $test_n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a (unsupervised/supervised) MT from a pretrained meta-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: lgs=en-fr|de-fr\n",
      "env: eval_bleu=true\n"
     ]
    }
   ],
   "source": [
    "#%env batch_size=...\n",
    "#%env epoch_size=...\n",
    "\n",
    "%env lgs=en-fr|de-fr\n",
    "\n",
    "%env eval_bleu=true\n",
    "! chmod +x src/evaluation/multi-bleu.perl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: stopping_criterion=valid_en-fr_mt_bleu,5\n",
      "env: validation_metrics=valid_en-fr_mt_bleu\n",
      "env: reload_model=dumped/mlm_enfrde/maml/best-valid_mlm_ppl.pth,dumped/mlm_enfrde/maml/best-valid_mlm_ppl.pth\n",
      "env: ae_steps=en,fr|de,fr\n",
      "env: bt_steps=en-fr-en,fr-en-fr|de-fr-de,fr-de-fr\n"
     ]
    }
   ],
   "source": [
    "%env stopping_criterion=valid_mt_bleu,5\n",
    "%env validation_metrics=valid_mt_bleu\n",
    "%env reload_model=dumped/mlm_enfrde/maml/best-valid_mlm_ppl.pth,dumped/mlm_enfrde/maml/best-valid_mlm_ppl.pth\n",
    "%env ae_steps=en,fr|de,fr\n",
    "%env bt_steps=en-fr-en,fr-en-fr|de-fr-de,fr-de-fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: train_n_samples=8\n",
      "env: valid_n_samples=2\n",
      "env: test_n_samples=2\n",
      "env: max_epoch=1\n",
      "env: batch_size=1\n",
      "env: epoch_size=20\n",
      "FAISS library was not found.\n",
      "FAISS not available. Switching to standard nearest neighbors search implementation.\n",
      "SLURM job: False\n",
      "0 - Number of nodes: 1\n",
      "0 - Node ID        : 0\n",
      "0 - Local rank     : 0\n",
      "0 - Global rank    : 0\n",
      "0 - World size     : 1\n",
      "0 - GPUs per node  : 1\n",
      "0 - Master         : True\n",
      "0 - Multi-node     : False\n",
      "0 - Multi-GPU      : False\n",
      "0 - Hostname       : african-translator-vm\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - accumulate_gradients: 1\n",
      "                                     ae_steps: [['en', 'fr'], ['de', 'fr']]\n",
      "                                     amp: -1\n",
      "                                     asm: False\n",
      "                                     attention_dropout: 0.1\n",
      "                                     batch_size: 1\n",
      "                                     beam_size: 1\n",
      "                                     bptt: 256\n",
      "                                     bt_src_langs: ['de', 'fr']\n",
      "                                     bt_steps: [[('en', 'fr', 'en'), ('fr', 'en', 'fr')], [('de', 'fr', 'de'), ('fr', 'de', 'fr')]]\n",
      "                                     clip_grad_norm: 5\n",
      "                                     clm_steps: [[], []]\n",
      "                                     command: python train.py --exp_name meta_MT_enfrde --exp_id maml --dump_path './dumped/' --reload_model 'dumped/mlm_enfrde/maml/best-valid_mlm_ppl.pth,dumped/mlm_enfrde/maml/best-valid_mlm_ppl.pth' --data_path 'data/enfrde/processed' --lgs 'en-fr|de-fr' --ae_steps 'en,fr|de,fr' --bt_steps 'en-fr-en,fr-en-fr|de-fr-de,fr-de-fr' --word_shuffle 3 --word_dropout '0.1' --word_blank '0.1' --lambda_ae '0:1,100000:0.1,300000:0' --encoder_only false --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --tokens_per_batch 2000 --batch_size 1 --bptt 256 --optimizer 'adam_inverse_sqrt,beta1=0.9,beta2=0.98,lr=0.0001' --epoch_size 20 --max_epoch 1 --eval_bleu true --stopping_criterion 'valid_en-fr_mt_bleu,5' --validation_metrics 'valid_en-fr_mt_bleu' --train_n_samples 8 --valid_n_samples 2 --test_n_samples 2 --remove_long_sentences_train True --remove_long_sentences_valid True --remove_long_sentences_test True --exp_id \"maml\"\n",
      "                                     context_size: 0\n",
      "                                     data_path: data/enfrde/processed\n",
      "                                     debug: False\n",
      "                                     debug_slurm: False\n",
      "                                     debug_train: False\n",
      "                                     dropout: 0.1\n",
      "                                     dump_path: ./dumped/meta_MT_enfrde/maml\n",
      "                                     early_stopping: False\n",
      "                                     emb_dim: 1024\n",
      "                                     encoder_only: False\n",
      "                                     epoch_size: 20\n",
      "                                     eval_bleu: True\n",
      "                                     eval_only: False\n",
      "                                     exp_id: maml\n",
      "                                     exp_name: meta_MT_enfrde\n",
      "                                     fp16: False\n",
      "                                     gelu_activation: True\n",
      "                                     global_rank: 0\n",
      "                                     group_by_size: True\n",
      "                                     id2lang: {0: 'de', 1: 'fr'}\n",
      "                                     is_master: True\n",
      "                                     is_slurm_job: False\n",
      "                                     lambda_ae: 0:1,100000:0.1,300000:0\n",
      "                                     lambda_bt: 1\n",
      "                                     lambda_clm: 1\n",
      "                                     lambda_mlm: 1\n",
      "                                     lambda_mt: 1\n",
      "                                     lambda_pc: 1\n",
      "                                     lang2id: {'de': 0, 'fr': 1}\n",
      "                                     langs: [['en', 'fr'], ['de', 'fr']]\n",
      "                                     length_penalty: 1\n",
      "                                     lg_sampling_factor: -1\n",
      "                                     lgs: ['en-fr', 'de-fr']\n",
      "                                     local_rank: 0\n",
      "                                     master_port: -1\n",
      "                                     max_batch_size: 0\n",
      "                                     max_epoch: 1\n",
      "                                     max_len: 100\n",
      "                                     max_vocab: -1\n",
      "                                     meta_learning: True\n",
      "                                     meta_params: ...\n",
      "                                     min_count: 0\n",
      "                                     mlm_steps: [[], []]\n",
      "                                     mono_dataset: {'de': {'train': 'data/enfrde/processed/train.de.pth', 'valid': 'data/enfrde/processed/valid.de.pth', 'test': 'data/enfrde/processed/test.de.pth'}, 'fr': {'train': 'data/enfrde/processed/train.fr.pth', 'valid': 'data/enfrde/processed/valid.fr.pth', 'test': 'data/enfrde/processed/test.fr.pth'}}\n",
      "                                     mt_steps: [[], []]\n",
      "                                     multi_gpu: False\n",
      "                                     multi_node: False\n",
      "                                     n_gpu_per_node: 1\n",
      "                                     n_heads: 8\n",
      "                                     n_langs: 2\n",
      "                                     n_layers: 6\n",
      "                                     n_nodes: 1\n",
      "                                     n_samples: {'train': 8, 'valid': 2, 'test': 2}\n",
      "                                     n_task: 2\n",
      "                                     node_id: 0\n",
      "                                     optimizer: adam_inverse_sqrt,beta1=0.9,beta2=0.98,lr=0.0001\n",
      "                                     para_dataset: {('de', 'fr'): {'valid': ('data/enfrde/processed/valid.de-fr.de.pth', 'data/enfrde/processed/valid.de-fr.fr.pth'), 'test': ('data/enfrde/processed/test.de-fr.de.pth', 'data/enfrde/processed/test.de-fr.fr.pth')}}\n",
      "                                     pc_steps: [[], []]\n",
      "                                     reload_checkpoint: \n",
      "                                     reload_emb: \n",
      "                                     reload_model: dumped/mlm_enfrde/maml/best-valid_mlm_ppl.pth,dumped/mlm_enfrde/maml/best-valid_mlm_ppl.pth\n",
      "                                     remove_long_sentences: {'train': True, 'valid': True, 'test': True}\n",
      "                                     remove_long_sentences_test: True\n",
      "                                     remove_long_sentences_train: True\n",
      "                                     remove_long_sentences_valid: True\n",
      "                                     sample_alpha: 0\n",
      "                                     save_periodic: 0\n",
      "                                     share_inout_emb: True\n",
      "                                     sinusoidal_embeddings: False\n",
      "                                     split_data: False\n",
      "                                     stopping_criterion: valid_en-fr_mt_bleu,5\n",
      "                                     test_n_samples: 2\n",
      "                                     tokens_per_batch: 2000\n",
      "                                     train_n_samples: 8\n",
      "                                     use_lang_emb: True\n",
      "                                     use_memory: False\n",
      "                                     valid_n_samples: 2\n",
      "                                     validation_metrics: valid_en-fr_mt_bleu\n",
      "                                     word_blank: 0.1\n",
      "                                     word_dropout: 0.1\n",
      "                                     word_keep: 0.1\n",
      "                                     word_mask: 0.8\n",
      "                                     word_mask_keep_rand: 0.8,0.1,0.1\n",
      "                                     word_pred: 0.15\n",
      "                                     word_rand: 0.1\n",
      "                                     word_shuffle: 3.0\n",
      "                                     world_size: 1\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - The experiment will be stored in ./dumped/meta_MT_enfrde/maml\n",
      "                                     \n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Running command: python train.py --exp_name meta_MT_enfrde --exp_id maml --dump_path './dumped/' --reload_model 'dumped/mlm_enfrde/maml/best-valid_mlm_ppl.pth,dumped/mlm_enfrde/maml/best-valid_mlm_ppl.pth' --data_path 'data/enfrde/processed' --lgs 'en-fr|de-fr' --ae_steps 'en,fr|de,fr' --bt_steps 'en-fr-en,fr-en-fr|de-fr-de,fr-de-fr' --word_shuffle 3 --word_dropout '0.1' --word_blank '0.1' --lambda_ae '0:1,100000:0.1,300000:0' --encoder_only false --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --tokens_per_batch 2000 --batch_size 1 --bptt 256 --optimizer 'adam_inverse_sqrt,beta1=0.9,beta2=0.98,lr=0.0001' --epoch_size 20 --max_epoch 1 --eval_bleu true --stopping_criterion 'valid_en-fr_mt_bleu,5' --validation_metrics 'valid_en-fr_mt_bleu' --train_n_samples 8 --valid_n_samples 2 --test_n_samples 2 --remove_long_sentences_train True --remove_long_sentences_valid True --remove_long_sentences_test True\n",
      "\n",
      "WARNING - 05/14/20 18:43:12 - 0:00:00 - Signal handler installed.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - ============ langs: en, fr\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - ============ Monolingual data (en)\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Loading data from data/enfrde/processed/train.en.pth ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - 1806755 words (83 unique) in 12604 sentences. 26709 unknown words (57 unique) covering 1.48% of the data.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting batches from 0 to 4 ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 7402 too long sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting sentences from 0 to 8 ...\n",
      "\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Loading data from data/enfrde/processed/valid.en.pth ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - 1366322 words (83 unique) in 9453 sentences. 18533 unknown words (63 unique) covering 1.36% of the data.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting batches from 0 to 1 ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 5579 too long sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting sentences from 0 to 2 ...\n",
      "\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Loading data from data/enfrde/processed/test.en.pth ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - 1367773 words (83 unique) in 9453 sentences. 18649 unknown words (62 unique) covering 1.36% of the data.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting batches from 0 to 1 ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 5604 too long sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting sentences from 0 to 2 ...\n",
      "\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - ============ Monolingual data (fr)\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Loading data from data/enfrde/processed/train.fr.pth ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - 1882740 words (83 unique) in 12604 sentences. 22517 unknown words (62 unique) covering 1.20% of the data.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting batches from 0 to 4 ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 7582 too long sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting sentences from 0 to 8 ...\n",
      "\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Loading data from data/enfrde/processed/valid.fr.pth ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - 1373916 words (83 unique) in 9453 sentences. 17988 unknown words (62 unique) covering 1.31% of the data.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting batches from 0 to 1 ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 5608 too long sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting sentences from 0 to 2 ...\n",
      "\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Loading data from data/enfrde/processed/test.fr.pth ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - 1374815 words (83 unique) in 9453 sentences. 18010 unknown words (62 unique) covering 1.31% of the data.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting batches from 0 to 1 ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 5626 too long sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting sentences from 0 to 2 ...\n",
      "\n",
      "\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - ============ Parallel data (en-fr)\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Loading data from data/enfrde/processed/valid.en-fr.en.pth ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - 58513 words (83 unique) in 451 sentences. 1125 unknown words (28 unique) covering 1.92% of the data.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Loading data from data/enfrde/processed/valid.en-fr.fr.pth ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - 66586 words (83 unique) in 451 sentences. 601 unknown words (29 unique) covering 0.90% of the data.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 279 too long sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting sentences from 0 to 2 ...\n",
      "\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Loading data from data/enfrde/processed/test.en-fr.en.pth ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - 61684 words (83 unique) in 451 sentences. 1257 unknown words (26 unique) covering 2.04% of the data.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Loading data from data/enfrde/processed/test.en-fr.fr.pth ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - 69085 words (83 unique) in 451 sentences. 637 unknown words (29 unique) covering 0.92% of the data.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 297 too long sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting sentences from 0 to 2 ...\n",
      "\n",
      "\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - ============ Data summary\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Monolingual data   - train -           en:        40\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Monolingual data   - valid -           en:       227\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Monolingual data   -  test -           en:        58\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Monolingual data   - train -           fr:        86\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Monolingual data   - valid -           fr:        59\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Monolingual data   -  test -           fr:       182\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Parallel data      - valid -        en-fr:         2\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Parallel data      -  test -        en-fr:         2\n",
      "\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - ============ langs: de, fr\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - ============ Monolingual data (de)\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Loading data from data/enfrde/processed/train.de.pth ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - 2083811 words (83 unique) in 14003 sentences. 24819 unknown words (63 unique) covering 1.19% of the data.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting batches from 0 to 4 ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 8404 too long sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting sentences from 0 to 8 ...\n",
      "\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Loading data from data/enfrde/processed/valid.de.pth ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - 1530704 words (83 unique) in 10502 sentences. 20099 unknown words (63 unique) covering 1.31% of the data.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting batches from 0 to 1 ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 6235 too long sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting sentences from 0 to 2 ...\n",
      "\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Loading data from data/enfrde/processed/test.de.pth ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - 1531682 words (83 unique) in 10502 sentences. 20113 unknown words (63 unique) covering 1.31% of the data.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting batches from 0 to 1 ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 6249 too long sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting sentences from 0 to 2 ...\n",
      "\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - ============ Monolingual data (fr)\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Loading data from data/enfrde/processed/train.fr.pth ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - 1882740 words (83 unique) in 12604 sentences. 22517 unknown words (62 unique) covering 1.20% of the data.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting batches from 0 to 4 ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 7582 too long sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting sentences from 0 to 8 ...\n",
      "\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Loading data from data/enfrde/processed/valid.fr.pth ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - 1373916 words (83 unique) in 9453 sentences. 17988 unknown words (62 unique) covering 1.31% of the data.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting batches from 0 to 1 ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 5608 too long sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting sentences from 0 to 2 ...\n",
      "\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Loading data from data/enfrde/processed/test.fr.pth ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - 1374815 words (83 unique) in 9453 sentences. 18010 unknown words (62 unique) covering 1.31% of the data.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting batches from 0 to 1 ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 5626 too long sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting sentences from 0 to 2 ...\n",
      "\n",
      "\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - ============ Parallel data (de-fr)\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Loading data from data/enfrde/processed/valid.de-fr.de.pth ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - 74507 words (83 unique) in 500 sentences. 667 unknown words (29 unique) covering 0.90% of the data.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Loading data from data/enfrde/processed/valid.de-fr.fr.pth ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - 74507 words (83 unique) in 500 sentences. 667 unknown words (29 unique) covering 0.90% of the data.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 304 too long sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting sentences from 0 to 2 ...\n",
      "\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Loading data from data/enfrde/processed/test.de-fr.de.pth ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - 75485 words (83 unique) in 500 sentences. 681 unknown words (29 unique) covering 0.90% of the data.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Loading data from data/enfrde/processed/test.de-fr.fr.pth ...\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - 75485 words (83 unique) in 500 sentences. 681 unknown words (29 unique) covering 0.90% of the data.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 0 empty sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Removed 318 too long sentences.\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Selecting sentences from 0 to 2 ...\n",
      "\n",
      "\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - ============ Data summary\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Monolingual data   - train -           de:       112\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Monolingual data   - valid -           de:       171\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Monolingual data   -  test -           de:       217\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Monolingual data   - train -           fr:        86\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Monolingual data   - valid -           fr:        59\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Monolingual data   -  test -           fr:       182\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Parallel data      - valid -        de-fr:         2\n",
      "INFO - 05/14/20 18:43:12 - 0:00:00 - Parallel data      -  test -        de-fr:         2\n",
      "\n",
      "INFO - 05/14/20 18:43:14 - 0:00:01 - Reloading encoder from dumped/mlm_enfrde/maml/best-valid_mlm_ppl.pth ...\n",
      "INFO - 05/14/20 18:43:17 - 0:00:05 - Reloading decoder from dumped/mlm_enfrde/maml/best-valid_mlm_ppl.pth ...\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter layer_norm15.0.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter layer_norm15.0.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.0.q_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.0.q_lin.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.0.k_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.0.k_lin.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.0.v_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.0.v_lin.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.0.out_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.0.out_lin.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter layer_norm15.1.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter layer_norm15.1.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.1.q_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.1.q_lin.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.1.k_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.1.k_lin.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.1.v_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.1.v_lin.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.1.out_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.1.out_lin.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter layer_norm15.2.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter layer_norm15.2.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.2.q_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.2.q_lin.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.2.k_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.2.k_lin.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.2.v_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.2.v_lin.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.2.out_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.2.out_lin.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter layer_norm15.3.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter layer_norm15.3.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.3.q_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.3.q_lin.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.3.k_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.3.k_lin.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.3.v_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.3.v_lin.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.3.out_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.3.out_lin.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter layer_norm15.4.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter layer_norm15.4.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.4.q_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.4.q_lin.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.4.k_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.4.k_lin.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.4.v_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.4.v_lin.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.4.out_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.4.out_lin.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter layer_norm15.5.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter layer_norm15.5.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.5.q_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.5.q_lin.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.5.k_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.5.k_lin.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.5.v_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.5.v_lin.bias not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.5.out_lin.weight not found.\n",
      "WARNING - 05/14/20 18:43:17 - 0:00:05 - Parameter encoder_attn.5.out_lin.bias not found.\n",
      "INFO - 05/14/20 18:43:17 - 0:00:05 - Number of parameters (encoder): 76190803\n",
      "INFO - 05/14/20 18:43:17 - 0:00:05 - Number of parameters (decoder): 101393491\n",
      "INFO - 05/14/20 18:43:18 - 0:00:05 - Found 0 memories.\n",
      "INFO - 05/14/20 18:43:18 - 0:00:05 - Found 12 FFN.\n",
      "INFO - 05/14/20 18:43:18 - 0:00:05 - Found 264 parameters in model.\n",
      "INFO - 05/14/20 18:43:18 - 0:00:05 - Optimizers: model\n",
      "Exception 'para'\n",
      "INFO - 05/14/20 18:43:18 - 0:00:06 - ============ Starting epoch 0 ... ============\n",
      "INFO - 05/14/20 18:43:18 - 0:00:06 - Creating new training data iterator (ae,en) ...\n",
      "INFO - 05/14/20 18:43:19 - 0:00:07 - Creating new training data iterator (ae,fr) ...\n",
      "INFO - 05/14/20 18:43:19 - 0:00:07 - Creating new training data iterator (ae,de) ...\n",
      "INFO - 05/14/20 18:43:19 - 0:00:07 - Creating new training data iterator (ae,fr) ...\n",
      "INFO - 05/14/20 18:43:20 - 0:00:08 - Creating new training data iterator (ae,en) ...\n",
      "INFO - 05/14/20 18:43:21 - 0:00:09 - Creating new training data iterator (ae,fr) ...\n",
      "INFO - 05/14/20 18:43:21 - 0:00:09 - Creating new training data iterator (ae,de) ...\n",
      "INFO - 05/14/20 18:43:21 - 0:00:09 - Creating new training data iterator (ae,fr) ...\n",
      "INFO - 05/14/20 18:43:22 - 0:00:10 - Creating new training data iterator (ae,en) ...\n",
      "INFO - 05/14/20 18:43:23 - 0:00:10 - Creating new training data iterator (ae,fr) ...\n",
      "INFO - 05/14/20 18:43:23 - 0:00:11 - Creating new training data iterator (ae,de) ...\n",
      "INFO - 05/14/20 18:43:23 - 0:00:11 - Creating new training data iterator (ae,fr) ...\n",
      "INFO - 05/14/20 18:43:24 - 0:00:12 - Creating new training data iterator (ae,en) ...\n",
      "INFO - 05/14/20 18:43:25 - 0:00:12 - Creating new training data iterator (ae,fr) ...\n",
      "INFO - 05/14/20 18:43:25 - 0:00:13 - Creating new training data iterator (ae,de) ...\n",
      "INFO - 05/14/20 18:43:25 - 0:00:13 - Creating new training data iterator (ae,fr) ...\n",
      "INFO - 05/14/20 18:43:26 - 0:00:14 - Creating new training data iterator (ae,en) ...\n",
      "INFO - 05/14/20 18:43:26 - 0:00:14 - Creating new training data iterator (ae,fr) ...\n",
      "INFO - 05/14/20 18:43:27 - 0:00:15 - Creating new training data iterator (ae,de) ...\n",
      "INFO - 05/14/20 18:43:27 - 0:00:15 - Creating new training data iterator (ae,fr) ...\n",
      "INFO - 05/14/20 18:43:28 - 0:00:16 - task : en-fr ||      5 -    7.74 sent/s -   458.97 words/s - AE-en:  3.7686 || AE-fr:  3.8099 -  - model LR: 7.2438e-07\n",
      "INFO - 05/14/20 18:43:28 - 0:00:16 - task : de-fr ||      5 - 78233.70 sent/s - 4156165.07 words/s - AE-de:  3.5943 || AE-fr:  3.7968 -  - model LR: 7.2438e-07\n",
      "INFO - 05/14/20 18:43:28 - 0:00:16 - Creating new training data iterator (ae,en) ...\n",
      "INFO - 05/14/20 18:43:28 - 0:00:16 - Creating new training data iterator (ae,fr) ...\n",
      "INFO - 05/14/20 18:43:29 - 0:00:16 - Creating new training data iterator (ae,de) ...\n",
      "INFO - 05/14/20 18:43:29 - 0:00:17 - Creating new training data iterator (ae,fr) ...\n",
      "INFO - 05/14/20 18:43:30 - 0:00:18 - Creating new training data iterator (ae,en) ...\n",
      "INFO - 05/14/20 18:43:30 - 0:00:18 - Creating new training data iterator (ae,fr) ...\n",
      "INFO - 05/14/20 18:43:31 - 0:00:18 - Creating new training data iterator (ae,de) ...\n",
      "INFO - 05/14/20 18:43:31 - 0:00:19 - Creating new training data iterator (ae,fr) ...\n",
      "INFO - 05/14/20 18:43:32 - 0:00:20 - Creating new training data iterator (ae,en) ...\n",
      "INFO - 05/14/20 18:43:32 - 0:00:20 - Creating new training data iterator (ae,fr) ...\n",
      "INFO - 05/14/20 18:43:32 - 0:00:20 - Creating new training data iterator (ae,de) ...\n",
      "INFO - 05/14/20 18:43:33 - 0:00:21 - Creating new training data iterator (ae,fr) ...\n",
      "INFO - 05/14/20 18:43:34 - 0:00:22 - Creating new training data iterator (ae,en) ...\n",
      "INFO - 05/14/20 18:43:34 - 0:00:22 - Creating new training data iterator (ae,fr) ...\n",
      "INFO - 05/14/20 18:43:34 - 0:00:22 - Creating new training data iterator (ae,de) ...\n",
      "INFO - 05/14/20 18:43:35 - 0:00:22 - Creating new training data iterator (ae,fr) ...\n",
      "INFO - 05/14/20 18:43:36 - 0:00:23 - Creating new training data iterator (ae,en) ...\n",
      "INFO - 05/14/20 18:43:36 - 0:00:24 - Creating new training data iterator (ae,fr) ...\n",
      "INFO - 05/14/20 18:43:36 - 0:00:24 - Creating new training data iterator (ae,de) ...\n",
      "INFO - 05/14/20 18:43:37 - 0:00:24 - Creating new training data iterator (ae,fr) ...\n",
      "INFO - 05/14/20 18:43:38 - 0:00:25 - task : en-fr ||     10 -    8.39 sent/s -   995.03 words/s - AE-en:  3.6752 || AE-fr:  3.6849 -  - model LR: 1.3488e-06\n",
      "INFO - 05/14/20 18:43:38 - 0:00:25 - task : de-fr ||     10 - 79701.74 sent/s - 8468309.74 words/s - AE-de:  3.5049 || AE-fr:  3.6667 -  - model LR: 1.3488e-06\n",
      "INFO - 05/14/20 18:43:38 - 0:00:25 - ============ End of epoch 0 ============\n",
      "ref ./dumped/meta_MT_enfrde/maml/hypotheses/ref.fr-en.valid.txt\n",
      "Illegal division by zero at /home/jupyter/meta_XLM/XLM/src/evaluation/multi-bleu.perl line 154, <STDIN> line 2.\n",
      "WARNING - 05/14/20 18:43:38 - 0:00:26 - Impossible to parse BLEU score! \"\"\n",
      "INFO - 05/14/20 18:43:38 - 0:00:26 - BLEU ./dumped/meta_MT_enfrde/maml/hypotheses/hyp0.fr-en.valid.txt ./dumped/meta_MT_enfrde/maml/hypotheses/ref.fr-en.valid.txt : -1.000000\n",
      "ref ./dumped/meta_MT_enfrde/maml/hypotheses/ref.en-fr.valid.txt\n",
      "Illegal division by zero at /home/jupyter/meta_XLM/XLM/src/evaluation/multi-bleu.perl line 154, <STDIN> line 2.\n",
      "WARNING - 05/14/20 18:43:38 - 0:00:26 - Impossible to parse BLEU score! \"\"\n",
      "INFO - 05/14/20 18:43:38 - 0:00:26 - BLEU ./dumped/meta_MT_enfrde/maml/hypotheses/hyp0.en-fr.valid.txt ./dumped/meta_MT_enfrde/maml/hypotheses/ref.en-fr.valid.txt : -1.000000\n",
      "ref ./dumped/meta_MT_enfrde/maml/hypotheses/ref.fr-de.valid.txt\n",
      "Illegal division by zero at /home/jupyter/meta_XLM/XLM/src/evaluation/multi-bleu.perl line 154, <STDIN> line 2.\n",
      "WARNING - 05/14/20 18:43:38 - 0:00:26 - Impossible to parse BLEU score! \"\"\n",
      "INFO - 05/14/20 18:43:38 - 0:00:26 - BLEU ./dumped/meta_MT_enfrde/maml/hypotheses/hyp0.fr-de.valid.txt ./dumped/meta_MT_enfrde/maml/hypotheses/ref.fr-de.valid.txt : -1.000000\n",
      "ref ./dumped/meta_MT_enfrde/maml/hypotheses/ref.de-fr.valid.txt\n",
      "Illegal division by zero at /home/jupyter/meta_XLM/XLM/src/evaluation/multi-bleu.perl line 154, <STDIN> line 2.\n",
      "WARNING - 05/14/20 18:43:38 - 0:00:26 - Impossible to parse BLEU score! \"\"\n",
      "INFO - 05/14/20 18:43:38 - 0:00:26 - BLEU ./dumped/meta_MT_enfrde/maml/hypotheses/hyp0.de-fr.valid.txt ./dumped/meta_MT_enfrde/maml/hypotheses/ref.de-fr.valid.txt : -1.000000\n",
      "ref ./dumped/meta_MT_enfrde/maml/hypotheses/ref.fr-en.test.txt\n",
      "Illegal division by zero at /home/jupyter/meta_XLM/XLM/src/evaluation/multi-bleu.perl line 154, <STDIN> line 2.\n",
      "WARNING - 05/14/20 18:43:38 - 0:00:26 - Impossible to parse BLEU score! \"\"\n",
      "INFO - 05/14/20 18:43:38 - 0:00:26 - BLEU ./dumped/meta_MT_enfrde/maml/hypotheses/hyp0.fr-en.test.txt ./dumped/meta_MT_enfrde/maml/hypotheses/ref.fr-en.test.txt : -1.000000\n",
      "ref ./dumped/meta_MT_enfrde/maml/hypotheses/ref.en-fr.test.txt\n",
      "Illegal division by zero at /home/jupyter/meta_XLM/XLM/src/evaluation/multi-bleu.perl line 154, <STDIN> line 2.\n",
      "WARNING - 05/14/20 18:43:39 - 0:00:26 - Impossible to parse BLEU score! \"\"\n",
      "INFO - 05/14/20 18:43:39 - 0:00:26 - BLEU ./dumped/meta_MT_enfrde/maml/hypotheses/hyp0.en-fr.test.txt ./dumped/meta_MT_enfrde/maml/hypotheses/ref.en-fr.test.txt : -1.000000\n",
      "INFO - 05/14/20 18:43:39 - 0:00:26 - ============ task : en-fr \n",
      "INFO - 05/14/20 18:43:39 - 0:00:26 - valid_fr-en_mt_ppl -> 31.450668\n",
      "INFO - 05/14/20 18:43:39 - 0:00:26 - valid_fr-en_mt_acc -> 3.773585\n",
      "INFO - 05/14/20 18:43:39 - 0:00:26 - valid_fr-en_mt_bleu -> -1.000000\n",
      "INFO - 05/14/20 18:43:39 - 0:00:26 - valid_en-fr_mt_ppl -> 25.151953\n",
      "INFO - 05/14/20 18:43:39 - 0:00:26 - valid_en-fr_mt_acc -> 1.801802\n",
      "INFO - 05/14/20 18:43:39 - 0:00:26 - valid_en-fr_mt_bleu -> -1.000000\n",
      "INFO - 05/14/20 18:43:39 - 0:00:26 - test_fr-en_mt_ppl -> 33.874480\n",
      "INFO - 05/14/20 18:43:39 - 0:00:26 - test_fr-en_mt_acc -> 5.128205\n",
      "INFO - 05/14/20 18:43:39 - 0:00:26 - test_fr-en_mt_bleu -> -1.000000\n",
      "INFO - 05/14/20 18:43:39 - 0:00:26 - test_en-fr_mt_ppl -> 30.668817\n",
      "INFO - 05/14/20 18:43:39 - 0:00:26 - test_en-fr_mt_acc -> 4.651163\n",
      "INFO - 05/14/20 18:43:39 - 0:00:26 - test_en-fr_mt_bleu -> -1.000000\n",
      "INFO - 05/14/20 18:43:39 - 0:00:26 - ============ task : de-fr \n",
      "INFO - 05/14/20 18:43:39 - 0:00:26 - valid_fr-de_mt_ppl -> 28.335568\n",
      "INFO - 05/14/20 18:43:39 - 0:00:26 - valid_fr-de_mt_acc -> 10.000000\n",
      "INFO - 05/14/20 18:43:39 - 0:00:26 - valid_fr-de_mt_bleu -> -1.000000\n",
      "INFO - 05/14/20 18:43:39 - 0:00:26 - valid_de-fr_mt_ppl -> 28.737523\n",
      "INFO - 05/14/20 18:43:39 - 0:00:26 - valid_de-fr_mt_acc -> 6.923077\n",
      "INFO - 05/14/20 18:43:39 - 0:00:26 - valid_de-fr_mt_bleu -> -1.000000\n",
      "INFO - 05/14/20 18:43:39 - 0:00:26 - __log__:{\"epoch\": 0, \"en-fr\": {\"epoch\": 0, \"valid_fr-en_mt_ppl\": 31.450668219000953, \"valid_fr-en_mt_acc\": 3.7735849056603774, \"valid_fr-en_mt_bleu\": -1, \"valid_en-fr_mt_ppl\": 25.15195324610732, \"valid_en-fr_mt_acc\": 1.8018018018018018, \"valid_en-fr_mt_bleu\": -1, \"test_fr-en_mt_ppl\": 33.87447985886686, \"test_fr-en_mt_acc\": 5.128205128205129, \"test_fr-en_mt_bleu\": -1, \"test_en-fr_mt_ppl\": 30.66881684091963, \"test_en-fr_mt_acc\": 4.651162790697675, \"test_en-fr_mt_bleu\": -1}, \"de-fr\": {\"epoch\": 0, \"valid_fr-de_mt_ppl\": 28.335567911692692, \"valid_fr-de_mt_acc\": 10.0, \"valid_fr-de_mt_bleu\": -1, \"valid_de-fr_mt_ppl\": 28.737522878259185, \"valid_de-fr_mt_acc\": 6.923076923076923, \"valid_de-fr_mt_bleu\": -1}}\n",
      "WARNING - 05/14/20 18:43:39 - 0:00:26 - Metric \"valid_en-fr_mt_bleu\" not found in scores!\n",
      "INFO - 05/14/20 18:43:39 - 0:00:26 - ============ garbage collector collecting 5 ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%env train_n_samples=8\n",
    "%env valid_n_samples=2\n",
    "%env test_n_samples=2\n",
    "\n",
    "%env max_epoch=1   \n",
    "%env batch_size=1\n",
    "%env epoch_size=20\n",
    "\n",
    "# unsupervised MT\n",
    "! python train.py --exp_name meta_MT_enfrde --exp_id $exp_id --dump_path ./dumped/ --reload_model $reload_model --data_path $OUTPATH --lgs $lgs --ae_steps $ae_steps --bt_steps $bt_steps --word_shuffle 3 --word_dropout 0.1 --word_blank 0.1 --lambda_ae '0:1,100000:0.1,300000:0' --encoder_only false --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout 0.1 --attention_dropout 0.1 --gelu_activation true --tokens_per_batch 2000 --batch_size $batch_size --bptt 256 --optimizer adam_inverse_sqrt,beta1=0.9,beta2=0.98,lr=0.0001 --epoch_size $epoch_size --max_epoch $max_epoch --eval_bleu $eval_bleu --stopping_criterion $stopping_criterion --validation_metrics $validation_metrics --train_n_samples $train_n_samples --valid_n_samples $valid_n_samples --test_n_samples $test_n_samples --remove_long_sentences_train $remove_long_sentences_train --remove_long_sentences_valid $remove_long_sentences_valid --remove_long_sentences_test $remove_long_sentences_test    \n",
    "\n",
    "# supervised MT\n",
    "#%env mt_steps=en-fr,fr-en|de-fr,fr-de           \n",
    "#! python train.py --exp_name meta_MT_enfrde --exp_id $exp_id  --dump_path ./dumped/ --reload_model $reload_model --data_path $OUTPATH --lgs $lgs --ae_steps $ae_steps --mt_steps $mt_steps --bt_steps $bt_steps --word_shuffle 3 --word_dropout 0.1 --word_blank 0.1 --lambda_ae '0:1,100000:0.1,300000:0' --encoder_only false --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout 0.1 --attention_dropout 0.1 --gelu_activation true --tokens_per_batch 2000 --batch_size $batch_size --bptt 256 --optimizer adam_inverse_sqrt,beta1=0.9,beta2=0.98,lr=0.0001 --epoch_size $epoch_size --max_epoch $max_epoch --eval_bleu $eval_bleu --stopping_criterion $stopping_criterion --validation_metrics $validation_metrics --train_n_samples $train_n_samples --valid_n_samples $valid_n_samples --test_n_samples $test_n_samples --remove_long_sentences_train $remove_long_sentences_train --remove_long_sentences_valid $remove_long_sentences_valid --remove_long_sentences_test $remove_long_sentences_test    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune the meta-model on a specific (sub) nmt (meta) task : en-fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%env batch_size=...\n",
    "#%env epoch_size=...\n",
    "\n",
    "%env lgs=en-fr\n",
    "\n",
    "%env eval_bleu=true\n",
    "! chmod +x src/evaluation/multi-bleu.perl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env stopping_criterion=valid_en-fr_mt_bleu,5\n",
    "%env validation_metrics=valid_en-fr_mt_bleu\n",
    "%env reload_model=/dumped/meta_MT_enfrde/maml/best-valid_mt_bleu.pth,/dumped/meta_MT_enfrde/maml/best-valid_mt_bleu.pth\n",
    "%env ae_steps=en,fr\n",
    "%env bt_steps=en-fr-en,fr-en-fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env train_n_samples=8\n",
    "%env valid_n_samples=2\n",
    "%env test_n_samples=2\n",
    "\n",
    "%env max_epoch=1   \n",
    "%env batch_size=1\n",
    "%env epoch_size=20\n",
    "\n",
    "# unsupervised MT\n",
    "! python train.py --exp_name meta_MT_enfr --exp_id $exp_id --dump_path ./dumped/ --reload_model $reload_model --data_path $OUTPATH/fine-tune --lgs $lgs --ae_steps $ae_steps --bt_steps $bt_steps --word_shuffle 3 --word_dropout 0.1 --word_blank 0.1 --lambda_ae '0:1,100000:0.1,300000:0' --encoder_only false --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout 0.1 --attention_dropout 0.1 --gelu_activation true --tokens_per_batch 2000 --batch_size $batch_size --bptt 256 --optimizer adam_inverse_sqrt,beta1=0.9,beta2=0.98,lr=0.0001 --epoch_size $epoch_size --max_epoch $max_epoch --eval_bleu $eval_bleu --stopping_criterion $stopping_criterion --validation_metrics $validation_metrics --train_n_samples $train_n_samples --valid_n_samples $valid_n_samples --test_n_samples $test_n_samples #--remove_long_sentences_train $remove_long_sentences_train --remove_long_sentences_valid $remove_long_sentences_valid --remove_long_sentences_test $remove_long_sentences_test  \n",
    "\n",
    "# supervised MT\n",
    "#%env mt_steps=en-fr,fr-en           \n",
    "#! python train.py --exp_name meta_MT_enfr --exp_id $exp_id --dump_path ./dumped/ --reload_model $reload_model --data_path $OUTPATH/fine_tune --lgs $lgs --ae_steps $ae_steps --mt_steps $mt_steps --bt_steps $bt_steps --word_shuffle 3 --word_dropout 0.1 --word_blank 0.1 --lambda_ae '0:1,100000:0.1,300000:0' --encoder_only false --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout 0.1 --attention_dropout 0.1 --gelu_activation true --tokens_per_batch 2000 --batch_size $batch_size --bptt 256 --optimizer adam_inverse_sqrt,beta1=0.9,beta2=0.98,lr=0.0001 --epoch_size $epoch_size --max_epoch $max_epoch --eval_bleu $eval_bleu --stopping_criterion $stopping_criterion --validation_metrics $validation_metrics --train_n_samples $train_n_samples --valid_n_samples $valid_n_samples --test_n_samples $test_n_samples #--remove_long_sentences_train $remove_long_sentences_train --remove_long_sentences_valid $remove_long_sentences_valid --remove_long_sentences_test $remove_long_sentences_test      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/meta_XLM\n"
     ]
    }
   ],
   "source": [
    " %cd \"/home/jupyter/meta_XLM\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 6f2974b] start correction of evaluation problems\n",
      " 5 files changed, 2919 insertions(+), 1439 deletions(-)\n",
      "Username for 'https://github.com': "
     ]
    }
   ],
   "source": [
    "! git add *\n",
    "! git commit -a -m\"start correction of evaluation problems\"\n",
    "! git push origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
