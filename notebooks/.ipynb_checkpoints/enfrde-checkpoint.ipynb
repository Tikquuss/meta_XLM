{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(bookmark:HOME) -> /home/jupyter/meta_XLM/XLM\n",
      "/home/jupyter/meta_XLM/XLM\n"
     ]
    }
   ],
   "source": [
    "%bookmark HOME \"/home/jupyter/meta_XLM/XLM\" \n",
    "%cd -b HOME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PARA=True\n",
      "env: MONO=True\n",
      "env: PARA_PATH=data/enfrde/para\n",
      "env: MONO_PATH=data/enfrde/mono\n",
      "env: SAME_VOCAB=True\n",
      "env: nCodes=10\n",
      "env: shuf_n_samples=10\n",
      "env: threads_for_tokenizer=16\n",
      "env: test_size=10\n",
      "env: val_size=10\n",
      "env: TOKENIZE=tools/tokenizer_our.sh\n",
      "env: LOWER_REMOVE_ACCENT=tools/lowercase_and_remove_accent.py\n",
      "env: FASTBPE=tools/fastBPE/fast\n",
      "env: OUTPATH=data/enfrde/processed\n",
      "env: n_samples=-1\n",
      "env: sub_task=en-fr:10,en-de:-1,de-fr:-1\n"
     ]
    }
   ],
   "source": [
    "%env PARA=True          \n",
    "%env MONO=True           \n",
    "                   \n",
    "%env PARA_PATH=data/enfrde/para      \n",
    "%env MONO_PATH=data/enfrde/mono    \n",
    "%env SAME_VOCAB=True    \n",
    "%env nCodes=10\n",
    "%env shuf_n_samples=1\n",
    "%env threads_for_tokenizer=16\n",
    "%env test_size=10       \n",
    "%env val_size=10        \n",
    "\n",
    "# tools paths\n",
    "%env TOKENIZE=tools/tokenizer_our.sh\n",
    "%env LOWER_REMOVE_ACCENT=tools/lowercase_and_remove_accent.py\n",
    "%env FASTBPE=tools/fastBPE/fast\n",
    "\n",
    "\n",
    "%env OUTPATH=data/enfrde/processed \n",
    "# create output path\n",
    "! mkdir -p $OUTPATH\n",
    "\n",
    "! chmod +x $FASTBPE\n",
    "! chmod +x ../build_meta_data.sh\n",
    "! chmod +x tools/mosesdecoder/scripts/tokenizer/*.perl\n",
    "\n",
    "%env n_samples=-1\n",
    "\n",
    "%env sub_task=en-fr:10,en-de:-1,de-fr:-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir data/enfrde/processed/fine_tune already exists\n",
      "params ok !\n",
      "*** Cleaning and tokenizing en-fr data ... ***\n",
      "file data/enfrde/para/en-fr.en.all already exists\n",
      "file data/enfrde/para/en-fr.fr.all already exists\n",
      "*** Cleaning and tokenizing en-de data ... ***\n",
      "file data/enfrde/para/en-de.en.all already exists\n",
      "file data/enfrde/para/en-de.de.all already exists\n",
      "*** Cleaning and tokenizing de-fr data ... ***\n",
      "file data/enfrde/para/de-fr.de.all already exists\n",
      "file data/enfrde/para/de-fr.fr.all already exists\n",
      "file data/enfrde/mono/en.all already exists\n",
      "file data/enfrde/mono/fr.all already exists\n",
      "file data/enfrde/mono/en.all already exists\n",
      "file data/enfrde/mono/de.all already exists\n",
      "file data/enfrde/mono/de.all already exists\n",
      "file data/enfrde/mono/fr.all already exists\n",
      "\n",
      "\n",
      "*** split into train / valid / test ***\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "\n",
      "\n",
      "\n",
      "***build the training set for BPE tokenization (10 codes)***\n",
      "\n",
      "\n",
      "***shuf ... Generating 10 random permutations of train data and store result in data/enfrde/processed/de-fr/bpe.train***\n",
      "\n",
      "\n",
      "***Learn the BPE vocabulary on the training set : data/enfrde/processed/bpe.train ...***\n",
      "Loading vocabulary from data/enfrde/processed/bpe.train ...\n",
      "Read 4005 words (1472 unique) from text file.\n",
      "terminate called after throwing an instance of 'std::bad_alloc'\n",
      "  what():  std::bad_alloc\n",
      "../build_meta_data.sh: line 238: 16549 Aborted                 $FASTBPE learnbpe $nCodes $OUTPATH/bpe.train > $OUTPATH/codes\n"
     ]
    }
   ],
   "source": [
    "! ../build_meta_data.sh $sub_task $n_samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
