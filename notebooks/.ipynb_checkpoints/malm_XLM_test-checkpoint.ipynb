{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(bookmark:HOME) -> /home/jupyter/meta_XLM/XLM_our\n",
      "/home/jupyter/meta_XLM/XLM_our\n"
     ]
    }
   ],
   "source": [
    "%bookmark HOME \"/home/jupyter/meta_XLM/XLM_our\" \n",
    "%cd -b HOME "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Je fusionne deux dossiers es-it et de-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending incremental file list\n",
      "codes\n",
      "        487,116 100%  433.30MB/s    0:00:00 (xfr#1, to-chk=20/21)\n",
      "es-it.es.test.pth\n",
      "     39,869,081 100%  279.57MB/s    0:00:00 (xfr#2, to-chk=19/21)\n",
      "es-it.es.train.pth\n",
      "    313,208,065 100%  255.52MB/s    0:00:01 (xfr#3, to-chk=18/21)\n",
      "es-it.es.valid.pth\n",
      "     39,943,773 100%  124.90MB/s    0:00:00 (xfr#4, to-chk=17/21)\n",
      "es-it.it.test.pth\n",
      "     38,691,996 100%   83.67MB/s    0:00:00 (xfr#5, to-chk=16/21)\n",
      "es-it.it.train.pth\n",
      "    303,647,395 100%  199.99MB/s    0:00:01 (xfr#6, to-chk=15/21)\n",
      "es-it.it.valid.pth\n",
      "     38,741,018 100%   63.81MB/s    0:00:00 (xfr#7, to-chk=14/21)\n",
      "test.es-it.es.pth\n",
      "     39,869,081 100%   53.25MB/s    0:00:00 (xfr#8, to-chk=13/21)\n",
      "test.es-it.it.pth\n",
      "     38,691,996 100%   43.82MB/s    0:00:00 (xfr#9, to-chk=12/21)\n",
      "test.es.pth\n",
      "     39,869,081 100%   39.00MB/s    0:00:00 (xfr#10, to-chk=11/21)\n",
      "test.it.pth\n",
      "     38,691,996 100%   33.36MB/s    0:00:01 (xfr#11, to-chk=10/21)\n",
      "train\n",
      "    348,824,186 100%  247.33MB/s    0:00:01 (xfr#12, to-chk=9/21)\n",
      "train.es-it.es.pth\n",
      "    313,208,065 100%  200.74MB/s    0:00:01 (xfr#13, to-chk=8/21)\n",
      "train.es-it.it.pth\n",
      "    303,647,395 100%   89.43MB/s    0:00:03 (xfr#14, to-chk=7/21)\n",
      "train.es.pth\n",
      "    313,208,065 100%  246.04MB/s    0:00:01 (xfr#15, to-chk=6/21)\n",
      "train.it.pth\n",
      "    303,647,395 100%   82.86MB/s    0:00:03 (xfr#16, to-chk=5/21)\n",
      "valid.es-it.es.pth\n",
      "     39,943,773 100%   59.15MB/s    0:00:00 (xfr#17, to-chk=4/21)\n",
      "valid.es-it.it.pth\n",
      "     38,741,018 100%   47.19MB/s    0:00:00 (xfr#18, to-chk=3/21)\n",
      "valid.es.pth\n",
      "     39,943,773 100%   41.05MB/s    0:00:00 (xfr#19, to-chk=2/21)\n",
      "valid.it.pth\n",
      "     38,741,018 100%   34.50MB/s    0:00:01 (xfr#20, to-chk=1/21)\n",
      "vocab\n",
      "        381,041 100%    4.91MB/s    0:00:00 (xfr#21, to-chk=0/21)\n",
      "\n",
      "sent 2,672,650,033 bytes  received 415 bytes  197,974,107.26 bytes/sec\n",
      "total size is 2,671,996,327  speedup is 1.00\n"
     ]
    }
   ],
   "source": [
    "#!  sudo rsync -av --progress /home/hkseventh/data/30000/es-it/* /home/hkseventh/data/30000/meta_learning --exclude *.train --exclude *.test --exclude *.valid --exclude *.es --exclude *.it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending incremental file list\n",
      "codes\n",
      "        438,572 100%  129.00MB/s    0:00:00 (xfr#1, to-chk=20/21)\n",
      "de-en.de.test.pth\n",
      "     80,093,732 100%  271.83MB/s    0:00:00 (xfr#2, to-chk=19/21)\n",
      "de-en.de.train.pth\n",
      "    634,705,069 100%  245.96MB/s    0:00:02 (xfr#3, to-chk=18/21)\n",
      "de-en.de.valid.pth\n",
      "     80,091,671 100%  102.25MB/s    0:00:00 (xfr#4, to-chk=17/21)\n",
      "de-en.en.test.pth\n",
      "     82,283,219 100%   75.38MB/s    0:00:01 (xfr#5, to-chk=16/21)\n",
      "de-en.en.train.pth\n",
      "    649,432,702 100%  133.65MB/s    0:00:04 (xfr#6, to-chk=15/21)\n",
      "de-en.en.valid.pth\n",
      "     82,227,820 100%   96.69MB/s    0:00:00 (xfr#7, to-chk=14/21)\n",
      "test.de-en.de.pth\n",
      "     80,093,732 100%   68.88MB/s    0:00:01 (xfr#8, to-chk=13/21)\n",
      "test.de-en.en.pth\n",
      "     82,283,219 100%  188.63MB/s    0:00:00 (xfr#9, to-chk=12/21)\n",
      "test.de.pth\n",
      "     80,093,732 100%  106.68MB/s    0:00:00 (xfr#10, to-chk=11/21)\n",
      "test.en.pth\n",
      "     82,283,219 100%   76.71MB/s    0:00:01 (xfr#11, to-chk=10/21)\n",
      "train\n",
      "     78,917,864 100%  237.42MB/s    0:00:00 (xfr#12, to-chk=9/21)\n",
      "train.de-en.de.pth\n",
      "    634,705,069 100%   35.59MB/s    0:00:17 (xfr#13, to-chk=8/21)\n",
      "train.de-en.en.pth\n",
      "    649,432,702 100%   47.79MB/s    0:00:12 (xfr#14, to-chk=7/21)\n",
      "train.de.pth\n",
      "    634,705,069 100%   38.35MB/s    0:00:15 (xfr#15, to-chk=6/21)\n",
      "train.en.pth\n",
      "    649,432,702 100%   86.43MB/s    0:00:07 (xfr#16, to-chk=5/21)\n",
      "valid.de-en.de.pth\n",
      "     80,091,671 100%   66.77MB/s    0:00:01 (xfr#17, to-chk=4/21)\n",
      "valid.de-en.en.pth\n",
      "     82,227,820 100%   37.63MB/s    0:00:02 (xfr#18, to-chk=3/21)\n",
      "valid.de.pth\n",
      "     80,091,671 100%   58.31MB/s    0:00:01 (xfr#19, to-chk=2/21)\n",
      "valid.en.pth\n",
      "     82,227,820 100%   38.42MB/s    0:00:02 (xfr#20, to-chk=1/21)\n",
      "vocab\n",
      "        330,270 100%  472.22kB/s    0:00:00 (xfr#21, to-chk=0/21)\n",
      "\n",
      "sent 4,907,388,563 bytes  received 415 bytes  73,795,322.98 bytes/sec\n",
      "total size is 4,906,189,345  speedup is 1.00\n"
     ]
    }
   ],
   "source": [
    "# On conserve le code & vocab issu de de-en \n",
    "#!  sudo rsync -av --progress /home/hkseventh/data/30000/de-en/* /home/hkseventh/data/30000/meta_learning --exclude *.train --exclude *.test --exclude *.valid --exclude *.de --exclude *.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codes\t\t    es-it.it.test.pth\ttest.it.pth\t    valid.de-en.de.pth\n",
      "de-en.de.test.pth   es-it.it.train.pth\ttrain\t\t    valid.de-en.en.pth\n",
      "de-en.de.train.pth  es-it.it.valid.pth\ttrain.de-en.de.pth  valid.de.pth\n",
      "de-en.de.valid.pth  test.de-en.de.pth\ttrain.de-en.en.pth  valid.en.pth\n",
      "de-en.en.test.pth   test.de-en.en.pth\ttrain.de.pth\t    valid.es-it.es.pth\n",
      "de-en.en.train.pth  test.de.pth\t\ttrain.en.pth\t    valid.es-it.it.pth\n",
      "de-en.en.valid.pth  test.en.pth\t\ttrain.es-it.es.pth  valid.es.pth\n",
      "es-it.es.test.pth   test.es-it.es.pth\ttrain.es-it.it.pth  valid.it.pth\n",
      "es-it.es.train.pth  test.es-it.it.pth\ttrain.es.pth\t    vocab\n",
      "es-it.es.valid.pth  test.es.pth\t\ttrain.it.pth\n"
     ]
    }
   ],
   "source": [
    "# ! rm -r  /home/hkseventh/data/30000/meta_learning \n",
    "! ls /home/hkseventh/data/30000/meta_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OUTPATH=/home/hkseventh/data/30000/meta_learning\n"
     ]
    }
   ],
   "source": [
    "%env OUTPATH=/home/hkseventh/data/30000/meta_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: batch_size=2\n",
      "env: stopping_criterion=_valid_mlm_ppl,10\n",
      "env: eval_bleu=false\n",
      "env: exp_id=test\n"
     ]
    }
   ],
   "source": [
    "%env batch_size=2\n",
    "# stopping criterion (if criterion does not improve 10 times)\n",
    "%env stopping_criterion=_valid_mlm_ppl,10\n",
    "%env eval_bleu false\n",
    "%env exp_id=test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: max_epoch=1\n",
      "env: epoch_size=20\n",
      "env: train_n_samples=30\n",
      "env: valid_n_samples=10\n",
      "env: test_n_samples=10\n"
     ]
    }
   ],
   "source": [
    "# MLM only\n",
    "%env max_epoch=1\n",
    "%env epoch_size=20\n",
    "\n",
    "# limit the number of examples (-1 by default for non limitation)\n",
    "%env train_n_samples=30\n",
    "%env valid_n_samples=10\n",
    "%env test_n_samples=10\n",
    "#--train_n_samples $train_n_samples --valid_n_samples $valid_n_samples --test_n_samples $test_n_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: lgs=es-it|de-en\n",
      "env: mlm_steps=es,it|de,en\n",
      "FAISS library was not found.\n",
      "FAISS not available. Switching to standard nearest neighbors search implementation.\n",
      "1 es,it|de,en\n",
      "SLURM job: False\n",
      "0 - Number of nodes: 1\n",
      "0 - Node ID        : 0\n",
      "0 - Local rank     : 0\n",
      "0 - Global rank    : 0\n",
      "0 - World size     : 1\n",
      "0 - GPUs per node  : 1\n",
      "0 - Master         : True\n",
      "0 - Multi-node     : False\n",
      "0 - Multi-GPU      : False\n",
      "0 - Hostname       : african-translator-vm\n",
      "INFO - 05/12/20 09:20:57 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 05/12/20 09:20:57 - 0:00:00 - accumulate_gradients: 1\n",
      "                                     ae_steps: []\n",
      "                                     aes: [[], []]\n",
      "                                     amp: -1\n",
      "                                     asm: False\n",
      "                                     attention_dropout: 0.1\n",
      "                                     batch_size: 2\n",
      "                                     beam_size: 1\n",
      "                                     bptt: 256\n",
      "                                     bt_src_langs: []\n",
      "                                     bt_steps: []\n",
      "                                     bts: [[], []]\n",
      "                                     clip_grad_norm: 5\n",
      "                                     clm_steps: []\n",
      "                                     clms: [[], []]\n",
      "                                     command: python train.py --exp_name test_meta_mlm --dump_path './dumped/' --data_path '/home/hkseventh/data/30000/meta_learning' --lgs 'es-it|de-en' --clm_steps '' --mlm_steps 'es,it|de,en' --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 2 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 20 --max_epoch 1 --validation_metrics _valid_mlm_ppl --stopping_criterion '_valid_mlm_ppl,10' --eval_bleu false --exp_id test --train_n_samples 30 --valid_n_samples 10 --test_n_samples 10 --exp_id \"test\"\n",
      "                                     context_size: 0\n",
      "                                     data_path: /home/hkseventh/data/30000/meta_learning\n",
      "                                     debug: False\n",
      "                                     debug_slurm: False\n",
      "                                     debug_train: False\n",
      "                                     dropout: 0.1\n",
      "                                     dump_path: ./dumped/test_meta_mlm/test\n",
      "                                     early_stopping: False\n",
      "                                     emb_dim: 1024\n",
      "                                     encoder_only: True\n",
      "                                     epoch_size: 20\n",
      "                                     eval_bleu: False\n",
      "                                     eval_only: False\n",
      "                                     exp_id: test\n",
      "                                     exp_name: test_meta_mlm\n",
      "                                     fp16: False\n",
      "                                     gelu_activation: True\n",
      "                                     global_rank: 0\n",
      "                                     group_by_size: True\n",
      "                                     id2lang: {0: 'de', 1: 'en'}\n",
      "                                     is_master: True\n",
      "                                     is_slurm_job: False\n",
      "                                     lambda_ae: 1\n",
      "                                     lambda_bt: 1\n",
      "                                     lambda_clm: 1\n",
      "                                     lambda_mlm: 1\n",
      "                                     lambda_mt: 1\n",
      "                                     lambda_pc: 1\n",
      "                                     lang2id: {'de': 0, 'en': 1}\n",
      "                                     langs: [['es', 'it'], ['de', 'en']]\n",
      "                                     length_penalty: 1\n",
      "                                     lg_sampling_factor: -1\n",
      "                                     lgs: ['es-it', 'de-en']\n",
      "                                     local_rank: 0\n",
      "                                     master_port: -1\n",
      "                                     max_batch_size: 0\n",
      "                                     max_epoch: 1\n",
      "                                     max_len: 100\n",
      "                                     max_vocab: -1\n",
      "                                     meta_learning: True\n",
      "                                     meta_params: {'es-it': Namespace(accumulate_gradients=1, ae_steps=[], amp=-1, asm=False, attention_dropout=0.1, batch_size=2, beam_size=1, bptt=256, bt_src_langs=[], bt_steps=[], clip_grad_norm=5, clm_steps=[], context_size=0, data_path='/home/hkseventh/data/30000/meta_learning', debug=False, debug_slurm=False, debug_train=False, dropout=0.1, dump_path='./dumped/', early_stopping=False, emb_dim=1024, encoder_only=True, epoch_size=20, eval_bleu=False, eval_only=False, exp_id='test', exp_name='test_meta_mlm', fp16=False, gelu_activation=True, group_by_size=True, id2lang={0: 'es', 1: 'it'}, lambda_ae='1', lambda_bt='1', lambda_clm='1', lambda_mlm='1', lambda_mt='1', lambda_pc='1', lang2id={'es': 0, 'it': 1}, langs=['es', 'it'], length_penalty=1, lg_sampling_factor=-1, lgs='es-it', local_rank=-1, master_port=-1, max_batch_size=0, max_epoch=1, max_len=100, max_vocab=-1, meta_learning=True, meta_params={}, min_count=0, mlm_steps=[('es', None), ('it', None)], mono_dataset={'es': {'train': '/home/hkseventh/data/30000/meta_learning/train.es.pth', 'valid': '/home/hkseventh/data/30000/meta_learning/valid.es.pth', 'test': '/home/hkseventh/data/30000/meta_learning/test.es.pth'}, 'it': {'train': '/home/hkseventh/data/30000/meta_learning/train.it.pth', 'valid': '/home/hkseventh/data/30000/meta_learning/valid.it.pth', 'test': '/home/hkseventh/data/30000/meta_learning/test.it.pth'}}, mt_steps=[], n_heads=8, n_langs=2, n_layers=6, n_samples={'train': 30, 'valid': 10, 'test': 10}, optimizer='adam,lr=0.0001', para_dataset={}, pc_steps=[], reload_checkpoint='', reload_emb='', reload_model='', remove_long_sentences={'train': True, 'valid': True, 'test': True}, remove_long_sentences_test=True, remove_long_sentences_train=True, remove_long_sentences_valid=True, sample_alpha=0, save_periodic=0, share_inout_emb=True, sinusoidal_embeddings=False, split_data=False, stopping_criterion='_valid_mlm_ppl,10', test_n_samples=10, tokens_per_batch=-1, train_n_samples=30, use_lang_emb=True, use_memory=False, valid_n_samples=10, validation_metrics='_valid_mlm_ppl', word_blank=0, word_dropout=0, word_keep=0.1, word_mask=0.8, word_mask_keep_rand='0.8,0.1,0.1', word_pred=0.15, word_rand=0.1, word_shuffle=0), 'de-en': Namespace(accumulate_gradients=1, ae_steps=[], amp=-1, asm=False, attention_dropout=0.1, batch_size=2, beam_size=1, bptt=256, bt_src_langs=[], bt_steps=[], clip_grad_norm=5, clm_steps=[], context_size=0, data_path='/home/hkseventh/data/30000/meta_learning', debug=False, debug_slurm=False, debug_train=False, dropout=0.1, dump_path='./dumped/', early_stopping=False, emb_dim=1024, encoder_only=True, epoch_size=20, eval_bleu=False, eval_only=False, exp_id='test', exp_name='test_meta_mlm', fp16=False, gelu_activation=True, group_by_size=True, id2lang={0: 'de', 1: 'en'}, lambda_ae='1', lambda_bt='1', lambda_clm='1', lambda_mlm='1', lambda_mt='1', lambda_pc='1', lang2id={'de': 0, 'en': 1}, langs=['de', 'en'], length_penalty=1, lg_sampling_factor=-1, lgs='de-en', local_rank=-1, master_port=-1, max_batch_size=0, max_epoch=1, max_len=100, max_vocab=-1, meta_learning=True, meta_params={'es-it': Namespace(accumulate_gradients=1, ae_steps=[], amp=-1, asm=False, attention_dropout=0.1, batch_size=2, beam_size=1, bptt=256, bt_src_langs=[], bt_steps=[], clip_grad_norm=5, clm_steps=[], context_size=0, data_path='/home/hkseventh/data/30000/meta_learning', debug=False, debug_slurm=False, debug_train=False, dropout=0.1, dump_path='./dumped/', early_stopping=False, emb_dim=1024, encoder_only=True, epoch_size=20, eval_bleu=False, eval_only=False, exp_id='test', exp_name='test_meta_mlm', fp16=False, gelu_activation=True, group_by_size=True, id2lang={0: 'es', 1: 'it'}, lambda_ae='1', lambda_bt='1', lambda_clm='1', lambda_mlm='1', lambda_mt='1', lambda_pc='1', lang2id={'es': 0, 'it': 1}, langs=['es', 'it'], length_penalty=1, lg_sampling_factor=-1, lgs='es-it', local_rank=-1, master_port=-1, max_batch_size=0, max_epoch=1, max_len=100, max_vocab=-1, meta_learning=True, meta_params={}, min_count=0, mlm_steps=[('es', None), ('it', None)], mono_dataset={'es': {'train': '/home/hkseventh/data/30000/meta_learning/train.es.pth', 'valid': '/home/hkseventh/data/30000/meta_learning/valid.es.pth', 'test': '/home/hkseventh/data/30000/meta_learning/test.es.pth'}, 'it': {'train': '/home/hkseventh/data/30000/meta_learning/train.it.pth', 'valid': '/home/hkseventh/data/30000/meta_learning/valid.it.pth', 'test': '/home/hkseventh/data/30000/meta_learning/test.it.pth'}}, mt_steps=[], n_heads=8, n_langs=2, n_layers=6, n_samples={'train': 30, 'valid': 10, 'test': 10}, optimizer='adam,lr=0.0001', para_dataset={}, pc_steps=[], reload_checkpoint='', reload_emb='', reload_model='', remove_long_sentences={'train': True, 'valid': True, 'test': True}, remove_long_sentences_test=True, remove_long_sentences_train=True, remove_long_sentences_valid=True, sample_alpha=0, save_periodic=0, share_inout_emb=True, sinusoidal_embeddings=False, split_data=False, stopping_criterion='_valid_mlm_ppl,10', test_n_samples=10, tokens_per_batch=-1, train_n_samples=30, use_lang_emb=True, use_memory=False, valid_n_samples=10, validation_metrics='_valid_mlm_ppl', word_blank=0, word_dropout=0, word_keep=0.1, word_mask=0.8, word_mask_keep_rand='0.8,0.1,0.1', word_pred=0.15, word_rand=0.1, word_shuffle=0)}, min_count=0, mlm_steps=[('de', None), ('en', None)], mono_dataset={'de': {'train': '/home/hkseventh/data/30000/meta_learning/train.de.pth', 'valid': '/home/hkseventh/data/30000/meta_learning/valid.de.pth', 'test': '/home/hkseventh/data/30000/meta_learning/test.de.pth'}, 'en': {'train': '/home/hkseventh/data/30000/meta_learning/train.en.pth', 'valid': '/home/hkseventh/data/30000/meta_learning/valid.en.pth', 'test': '/home/hkseventh/data/30000/meta_learning/test.en.pth'}}, mt_steps=[], n_heads=8, n_langs=2, n_layers=6, n_samples={'train': 30, 'valid': 10, 'test': 10}, optimizer='adam,lr=0.0001', para_dataset={}, pc_steps=[], reload_checkpoint='', reload_emb='', reload_model='', remove_long_sentences={'train': True, 'valid': True, 'test': True}, remove_long_sentences_test=True, remove_long_sentences_train=True, remove_long_sentences_valid=True, sample_alpha=0, save_periodic=0, share_inout_emb=True, sinusoidal_embeddings=False, split_data=False, stopping_criterion='_valid_mlm_ppl,10', test_n_samples=10, tokens_per_batch=-1, train_n_samples=30, use_lang_emb=True, use_memory=False, valid_n_samples=10, validation_metrics='_valid_mlm_ppl', word_blank=0, word_dropout=0, word_keep=0.1, word_mask=0.8, word_mask_keep_rand='0.8,0.1,0.1', word_pred=0.15, word_rand=0.1, word_shuffle=0)}\n",
      "                                     min_count: 0\n",
      "                                     mlm_steps: [('de', None), ('en', None)]\n",
      "                                     mlms: [[('es', None), ('it', None)], [('de', None), ('en', None)]]\n",
      "                                     mono_dataset: {'de': {'train': '/home/hkseventh/data/30000/meta_learning/train.de.pth', 'valid': '/home/hkseventh/data/30000/meta_learning/valid.de.pth', 'test': '/home/hkseventh/data/30000/meta_learning/test.de.pth'}, 'en': {'train': '/home/hkseventh/data/30000/meta_learning/train.en.pth', 'valid': '/home/hkseventh/data/30000/meta_learning/valid.en.pth', 'test': '/home/hkseventh/data/30000/meta_learning/test.en.pth'}}\n",
      "                                     mt_steps: []\n",
      "                                     mts: [[], []]\n",
      "                                     multi_gpu: False\n",
      "                                     multi_node: False\n",
      "                                     n_gpu_per_node: 1\n",
      "                                     n_heads: 8\n",
      "                                     n_langs: 2\n",
      "                                     n_layers: 6\n",
      "                                     n_nodes: 1\n",
      "                                     n_samples: {'train': 30, 'valid': 10, 'test': 10}\n",
      "                                     node_id: 0\n",
      "                                     optimizer: adam,lr=0.0001\n",
      "                                     para_dataset: {}\n",
      "                                     pc_steps: []\n",
      "                                     pcs: [[], []]\n",
      "                                     reload_checkpoint: \n",
      "                                     reload_emb: \n",
      "                                     reload_model: \n",
      "                                     remove_long_sentences: {'train': True, 'valid': True, 'test': True}\n",
      "                                     remove_long_sentences_test: True\n",
      "                                     remove_long_sentences_train: True\n",
      "                                     remove_long_sentences_valid: True\n",
      "                                     sample_alpha: 0\n",
      "                                     save_periodic: 0\n",
      "                                     share_inout_emb: True\n",
      "                                     sinusoidal_embeddings: False\n",
      "                                     split_data: False\n",
      "                                     stopping_criterion: _valid_mlm_ppl,10\n",
      "                                     test_n_samples: 10\n",
      "                                     tokens_per_batch: -1\n",
      "                                     train_n_samples: 30\n",
      "                                     use_lang_emb: True\n",
      "                                     use_memory: False\n",
      "                                     valid_n_samples: 10\n",
      "                                     validation_metrics: _valid_mlm_ppl\n",
      "                                     word_blank: 0\n",
      "                                     word_dropout: 0\n",
      "                                     word_keep: 0.1\n",
      "                                     word_mask: 0.8\n",
      "                                     word_mask_keep_rand: 0.8,0.1,0.1\n",
      "                                     word_pred: 0.15\n",
      "                                     word_rand: 0.1\n",
      "                                     word_shuffle: 0\n",
      "                                     world_size: 1\n",
      "INFO - 05/12/20 09:20:57 - 0:00:00 - The experiment will be stored in ./dumped/test_meta_mlm/test\n",
      "                                     \n",
      "INFO - 05/12/20 09:20:57 - 0:00:00 - Running command: python train.py --exp_name test_meta_mlm --dump_path './dumped/' --data_path '/home/hkseventh/data/30000/meta_learning' --lgs 'es-it|de-en' --clm_steps '' --mlm_steps 'es,it|de,en' --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 2 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 20 --max_epoch 1 --validation_metrics _valid_mlm_ppl --stopping_criterion '_valid_mlm_ppl,10' --eval_bleu false --exp_id test --train_n_samples 30 --valid_n_samples 10 --test_n_samples 10\n",
      "\n",
      "WARNING - 05/12/20 09:20:57 - 0:00:00 - Signal handler installed.\n",
      "valeur.langs ['es', 'it']\n",
      "INFO - 05/12/20 09:20:57 - 0:00:00 - ============ Monolingual data (es)\n",
      "INFO - 05/12/20 09:20:57 - 0:00:00 - Loading data from /home/hkseventh/data/30000/meta_learning/train.es.pth ...\n",
      "INFO - 05/12/20 09:20:58 - 0:00:00 - 121534108 words (30760 unique) in 3847126 sentences. 668 unknown words (515 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 15\n",
      "INFO - 05/12/20 09:20:59 - 0:00:02 - Selecting batches from 0 to 1 ...\n",
      "\n",
      "INFO - 05/12/20 09:20:59 - 0:00:02 - Loading data from /home/hkseventh/data/30000/meta_learning/valid.es.pth ...\n",
      "INFO - 05/12/20 09:20:59 - 0:00:02 - 15199981 words (30760 unique) in 480890 sentences. 129 unknown words (111 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 7\n",
      "INFO - 05/12/20 09:20:59 - 0:00:02 - Selecting batches from 0 to 1 ...\n",
      "\n",
      "INFO - 05/12/20 09:20:59 - 0:00:02 - Loading data from /home/hkseventh/data/30000/meta_learning/test.es.pth ...\n",
      "INFO - 05/12/20 09:20:59 - 0:00:02 - 15162799 words (30760 unique) in 480890 sentences. 81 unknown words (73 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 7\n",
      "INFO - 05/12/20 09:20:59 - 0:00:02 - Selecting batches from 0 to 1 ...\n",
      "\n",
      "INFO - 05/12/20 09:20:59 - 0:00:02 - ============ Monolingual data (it)\n",
      "INFO - 05/12/20 09:20:59 - 0:00:02 - Loading data from /home/hkseventh/data/30000/meta_learning/train.it.pth ...\n",
      "INFO - 05/12/20 09:21:00 - 0:00:02 - 116753884 words (30760 unique) in 3847126 sentences. 633 unknown words (490 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 16\n",
      "INFO - 05/12/20 09:21:01 - 0:00:04 - Selecting batches from 0 to 1 ...\n",
      "\n",
      "INFO - 05/12/20 09:21:01 - 0:00:04 - Loading data from /home/hkseventh/data/30000/meta_learning/valid.it.pth ...\n",
      "INFO - 05/12/20 09:21:01 - 0:00:04 - 14598718 words (30760 unique) in 480890 sentences. 104 unknown words (84 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 8\n",
      "INFO - 05/12/20 09:21:01 - 0:00:04 - Selecting batches from 0 to 1 ...\n",
      "\n",
      "INFO - 05/12/20 09:21:01 - 0:00:04 - Loading data from /home/hkseventh/data/30000/meta_learning/test.it.pth ...\n",
      "INFO - 05/12/20 09:21:01 - 0:00:04 - 14574268 words (30760 unique) in 480890 sentences. 77 unknown words (72 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 8\n",
      "INFO - 05/12/20 09:21:01 - 0:00:04 - Selecting batches from 0 to 1 ...\n",
      "\n",
      "\n",
      "\n",
      "INFO - 05/12/20 09:21:01 - 0:00:04 - ============ Data summary\n",
      "INFO - 05/12/20 09:21:01 - 0:00:04 - Monolingual data   - train -           es:       267\n",
      "INFO - 05/12/20 09:21:01 - 0:00:04 - Monolingual data   - valid -           es:       158\n",
      "INFO - 05/12/20 09:21:01 - 0:00:04 - Monolingual data   -  test -           es:       218\n",
      "INFO - 05/12/20 09:21:01 - 0:00:04 - Monolingual data   - train -           it:        97\n",
      "INFO - 05/12/20 09:21:01 - 0:00:04 - Monolingual data   - valid -           it:        79\n",
      "INFO - 05/12/20 09:21:01 - 0:00:04 - Monolingual data   -  test -           it:       205\n",
      "\n",
      "valeur.langs ['de', 'en']\n",
      "INFO - 05/12/20 09:21:01 - 0:00:04 - ============ Monolingual data (de)\n",
      "INFO - 05/12/20 09:21:01 - 0:00:04 - Loading data from /home/hkseventh/data/30000/meta_learning/train.de.pth ...\n",
      "INFO - 05/12/20 09:21:02 - 0:00:05 - 153669772 words (30146 unique) in 18140497 sentences. 800 unknown words (144 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 54\n",
      "WARNING - 05/12/20 09:21:04 - 0:00:06 - Invalid split values: 0 0 - 335567\n",
      "\n",
      "INFO - 05/12/20 09:21:04 - 0:00:06 - Loading data from /home/hkseventh/data/30000/meta_learning/valid.de.pth ...\n",
      "INFO - 05/12/20 09:21:04 - 0:00:06 - 19219789 words (30146 unique) in 2267562 sentences. 142 unknown words (86 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 27\n",
      "WARNING - 05/12/20 09:21:04 - 0:00:07 - Invalid split values: 0 0 - 83935\n",
      "\n",
      "INFO - 05/12/20 09:21:04 - 0:00:07 - Loading data from /home/hkseventh/data/30000/meta_learning/test.de.pth ...\n",
      "INFO - 05/12/20 09:21:04 - 0:00:07 - 19220980 words (30146 unique) in 2267562 sentences. 90 unknown words (50 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 27\n",
      "WARNING - 05/12/20 09:21:04 - 0:00:07 - Invalid split values: 0 0 - 83940\n",
      "\n",
      "INFO - 05/12/20 09:21:04 - 0:00:07 - ============ Monolingual data (en)\n",
      "INFO - 05/12/20 09:21:04 - 0:00:07 - Loading data from /home/hkseventh/data/30000/meta_learning/train.en.pth ...\n",
      "INFO - 05/12/20 09:21:05 - 0:00:08 - 161033023 words (30146 unique) in 18140497 sentences. 1797 unknown words (274 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 51\n",
      "WARNING - 05/12/20 09:21:07 - 0:00:10 - Invalid split values: 0 0 - 349949\n",
      "\n",
      "INFO - 05/12/20 09:21:07 - 0:00:10 - Loading data from /home/hkseventh/data/30000/meta_learning/valid.en.pth ...\n",
      "INFO - 05/12/20 09:21:07 - 0:00:10 - 20287791 words (30146 unique) in 2267562 sentences. 241 unknown words (105 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 25\n",
      "WARNING - 05/12/20 09:21:07 - 0:00:10 - Invalid split values: 0 0 - 88107\n",
      "\n",
      "INFO - 05/12/20 09:21:07 - 0:00:10 - Loading data from /home/hkseventh/data/30000/meta_learning/test.en.pth ...\n",
      "INFO - 05/12/20 09:21:07 - 0:00:10 - 20315569 words (30146 unique) in 2267562 sentences. 204 unknown words (89 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 25\n",
      "WARNING - 05/12/20 09:21:07 - 0:00:10 - Invalid split values: 0 0 - 88216\n",
      "\n",
      "\n",
      "\n",
      "INFO - 05/12/20 09:21:07 - 0:00:10 - ============ Data summary\n",
      "INFO - 05/12/20 09:21:07 - 0:00:10 - Monolingual data   - train -           de:  18140497\n",
      "INFO - 05/12/20 09:21:07 - 0:00:10 - Monolingual data   - valid -           de:   2267562\n",
      "INFO - 05/12/20 09:21:07 - 0:00:10 - Monolingual data   -  test -           de:   2267562\n",
      "INFO - 05/12/20 09:21:07 - 0:00:10 - Monolingual data   - train -           en:  18140497\n",
      "INFO - 05/12/20 09:21:07 - 0:00:10 - Monolingual data   - valid -           en:   2267562\n",
      "INFO - 05/12/20 09:21:07 - 0:00:10 - Monolingual data   -  test -           en:   2267562\n",
      "\n",
      "INFO - 05/12/20 09:21:08 - 0:00:11 - Model: TransformerModel(\n",
      "                                       (position_embeddings): Embedding(512, 1024)\n",
      "                                       (lang_embeddings): Embedding(2, 1024)\n",
      "                                       (embeddings): Embedding(30760, 1024, padding_idx=2)\n",
      "                                       (layer_norm_emb): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                       (attentions): ModuleList(\n",
      "                                         (0): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (1): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (2): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (3): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (4): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (5): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                       )\n",
      "                                       (layer_norm1): ModuleList(\n",
      "                                         (0): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (2): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (3): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (4): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (5): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                       )\n",
      "                                       (ffns): ModuleList(\n",
      "                                         (0): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (1): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (2): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (3): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (4): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (5): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                       )\n",
      "                                       (layer_norm2): ModuleList(\n",
      "                                         (0): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (2): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (3): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (4): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (5): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                       )\n",
      "                                       (memories): ModuleDict()\n",
      "                                       (pred_layer): PredLayer(\n",
      "                                         (proj): Linear(in_features=1024, out_features=30760, bias=True)\n",
      "                                       )\n",
      "                                     )\n",
      "INFO - 05/12/20 09:21:08 - 0:00:11 - Number of parameters (model): 107634728\n",
      "INFO - 05/12/20 09:21:12 - 0:00:15 - Found 0 memories.\n",
      "INFO - 05/12/20 09:21:12 - 0:00:15 - Found 6 FFN.\n",
      "INFO - 05/12/20 09:21:12 - 0:00:15 - Found 102 parameters in model.\n",
      "INFO - 05/12/20 09:21:12 - 0:00:15 - Optimizers: model\n",
      "INFO - 05/12/20 09:21:12 - 0:00:15 - ============ Starting epoch 0 ... ============\n",
      "params.meta_params.keys() dict_keys(['es-it', 'de-en'])\n",
      "INFO - 05/12/20 09:21:12 - 0:00:15 - Creating new training data iterator (pred,it) ...\n",
      "INFO - 05/12/20 09:21:12 - 0:00:15 - Creating new training data iterator (pred,es) ...\n",
      "params.meta_params.keys() dict_keys(['es-it', 'de-en'])\n",
      "INFO - 05/12/20 09:21:12 - 0:00:15 - Creating new training data iterator (pred,de) ...\n",
      "INFO - 05/12/20 09:21:13 - 0:00:16 - Creating new training data iterator (pred,en) ...\n",
      "params.meta_params.keys() dict_keys(['es-it', 'de-en'])\n",
      "INFO - 05/12/20 09:21:13 - 0:00:16 - Creating new training data iterator (pred,es) ...\n",
      "INFO - 05/12/20 09:21:13 - 0:00:16 - Creating new training data iterator (pred,it) ...\n",
      "params.meta_params.keys() dict_keys(['es-it', 'de-en'])\n",
      "params.meta_params.keys() dict_keys(['es-it', 'de-en'])\n",
      "INFO - 05/12/20 09:21:14 - 0:00:17 - Creating new training data iterator (pred,it) ...\n",
      "INFO - 05/12/20 09:21:14 - 0:00:17 - Creating new training data iterator (pred,es) ...\n",
      "params.meta_params.keys() dict_keys(['es-it', 'de-en'])\n",
      "INFO - 05/12/20 09:21:15 - 0:00:17 - ============ End of epoch 0 ============\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - epoch -> 0.000000\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - valid_es_mlm_ppl -> 82.920906\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - valid_es_mlm_acc -> 64.102564\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - valid_it_mlm_ppl -> 2951.510199\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - valid_it_mlm_acc -> 35.897436\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - valid_mlm_ppl -> 43326.488898\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - valid_mlm_acc -> 10.751295\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - valid_de_mlm_ppl -> 40204.024092\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - valid_de_mlm_acc -> 9.067358\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - valid_en_mlm_ppl -> 46448.953705\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - valid_en_mlm_acc -> 12.435233\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - test_es_mlm_ppl -> 2.457237\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - test_es_mlm_acc -> 92.307692\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - test_it_mlm_ppl -> 11.323915\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - test_it_mlm_acc -> 82.051282\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - test_mlm_ppl -> 20914.736719\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - test_mlm_acc -> 16.450777\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - test_de_mlm_ppl -> 16535.453272\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - test_de_mlm_acc -> 15.803109\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - test_en_mlm_ppl -> 25294.020167\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - test_en_mlm_acc -> 17.098446\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - __log__:{\"epoch\": 0, \"valid_es_mlm_ppl\": 82.92090576318925, \"valid_es_mlm_acc\": 64.1025641025641, \"valid_it_mlm_ppl\": 2951.5101994732786, \"valid_it_mlm_acc\": 35.8974358974359, \"valid_mlm_ppl\": 43326.488898480035, \"valid_mlm_acc\": 10.751295336787564, \"valid_de_mlm_ppl\": 40204.024092185326, \"valid_de_mlm_acc\": 9.067357512953368, \"valid_en_mlm_ppl\": 46448.953704774736, \"valid_en_mlm_acc\": 12.435233160621761, \"test_es_mlm_ppl\": 2.4572372732069816, \"test_es_mlm_acc\": 92.3076923076923, \"test_it_mlm_ppl\": 11.32391473561309, \"test_it_mlm_acc\": 82.05128205128206, \"test_mlm_ppl\": 20914.736719391738, \"test_mlm_acc\": 16.450777202072537, \"test_de_mlm_ppl\": 16535.45327179791, \"test_de_mlm_acc\": 15.803108808290155, \"test_en_mlm_ppl\": 25294.020166985567, \"test_en_mlm_acc\": 17.098445595854923}\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - New best score for valid_mlm_ppl: 43326.488898\n",
      "INFO - 05/12/20 09:21:15 - 0:00:18 - Saving best-valid_mlm_ppl to ./dumped/test_meta_mlm/test/best-valid_mlm_ppl.pth ...\n",
      "WARNING - 05/12/20 09:21:15 - 0:00:18 - Saving model parameters ...\n",
      "INFO - 05/12/20 09:21:16 - 0:00:19 - New best validation score: 43326.488898\n",
      "INFO - 05/12/20 09:21:16 - 0:00:19 - Saving checkpoint to ./dumped/test_meta_mlm/test/checkpoint.pth ...\n",
      "WARNING - 05/12/20 09:21:16 - 0:00:19 - Saving model parameters ...\n",
      "WARNING - 05/12/20 09:21:16 - 0:00:19 - Saving model optimizer ...\n"
     ]
    }
   ],
   "source": [
    "%env lgs=es-it\n",
    "%env mlm_steps=es,it\n",
    "! python train.py --exp_name test_meta_mlm --dump_path ./dumped/ --data_path $OUTPATH --lgs $lgs --clm_steps '' --mlm_steps $mlm_steps --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout 0.1 --attention_dropout 0.1 --gelu_activation true --batch_size $batch_size --bptt 256 --optimizer adam,lr=0.0001 --epoch_size $epoch_size --max_epoch $max_epoch --validation_metrics _valid_mlm_ppl --stopping_criterion $stopping_criterion --eval_bleu $eval_bleu --exp_id $exp_id --train_n_samples $train_n_samples --valid_n_samples $valid_n_samples --test_n_samples $test_n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
