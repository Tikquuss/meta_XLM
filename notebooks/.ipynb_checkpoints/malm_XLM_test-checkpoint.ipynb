{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(bookmark:HOME) -> /home/jupyter/meta_XLM/XLM_our\n",
      "/home/jupyter/meta_XLM/XLM_our\n"
     ]
    }
   ],
   "source": [
    "%bookmark HOME \"/home/jupyter/meta_XLM/XLM_our\" \n",
    "%cd -b HOME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OUTPATH=/home/hkseventh/data/30000/es-it\n"
     ]
    }
   ],
   "source": [
    "%env OUTPATH=/home/hkseventh/data/30000/es-it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: batch_size=2\n",
      "env: stopping_criterion=_valid_mlm_ppl,10\n",
      "env: eval_bleu=false\n",
      "env: exp_id=test\n"
     ]
    }
   ],
   "source": [
    "%env batch_size=2\n",
    "# stopping criterion (if criterion does not improve 10 times)\n",
    "%env stopping_criterion=_valid_mlm_ppl,10\n",
    "%env eval_bleu false\n",
    "%env exp_id=test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: max_epoch=1\n",
      "env: epoch_size=2\n",
      "env: train_n_samples=8\n",
      "env: valid_n_samples=1\n",
      "env: test_n_samples=1\n"
     ]
    }
   ],
   "source": [
    "# MLM only\n",
    "%env max_epoch=1\n",
    "%env epoch_size=2\n",
    "\n",
    "# limit the number of examples (-1 by default for non limitation)\n",
    "%env train_n_samples=8\n",
    "%env valid_n_samples=1\n",
    "%env test_n_samples=1\n",
    "#--train_n_samples $train_n_samples --valid_n_samples $valid_n_samples --test_n_samples $test_n_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: lgs=es-it|it-es\n",
      "env: mlm_steps=es,it|it,es\n",
      "FAISS library was not found.\n",
      "FAISS not available. Switching to standard nearest neighbors search implementation.\n",
      "1 es,it|it,es\n",
      "\n",
      "2 es,it\n",
      "3 [('es', None), ('it', None)]\n",
      "4 [('es', None), ('it', None)]\n",
      "lgs ------- es-it\n",
      "2 it,es\n",
      "3 [('it', None), ('es', None)]\n",
      "4 [('it', None), ('es', None)]\n",
      "lgs ------- it-es\n",
      "SLURM job: False\n",
      "0 - Number of nodes: 1\n",
      "0 - Node ID        : 0\n",
      "0 - Local rank     : 0\n",
      "0 - Global rank    : 0\n",
      "0 - World size     : 1\n",
      "0 - GPUs per node  : 1\n",
      "0 - Master         : True\n",
      "0 - Multi-node     : False\n",
      "0 - Multi-GPU      : False\n",
      "0 - Hostname       : african-translator-vm\n",
      "INFO - 05/11/20 21:49:30 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 05/11/20 21:49:30 - 0:00:00 - accumulate_gradients: 1\n",
      "                                     ae_steps: []\n",
      "                                     amp: -1\n",
      "                                     asm: False\n",
      "                                     attention_dropout: 0.1\n",
      "                                     batch_size: 2\n",
      "                                     beam_size: 1\n",
      "                                     bptt: 256\n",
      "                                     bt_src_langs: []\n",
      "                                     bt_steps: []\n",
      "                                     clip_grad_norm: 5\n",
      "                                     clm_steps: []\n",
      "                                     command: python train.py --exp_name test_esit_mlm --dump_path './dumped/' --data_path '/home/hkseventh/data/30000/es-it' --lgs 'es-it|it-es' --clm_steps '' --mlm_steps 'es,it|it,es' --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 2 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 2 --max_epoch 1 --validation_metrics _valid_mlm_ppl --stopping_criterion '_valid_mlm_ppl,10' --eval_bleu false --exp_id test --train_n_samples 8 --valid_n_samples 1 --test_n_samples 1 --exp_id \"test\"\n",
      "                                     context_size: 0\n",
      "                                     data_path: /home/hkseventh/data/30000/es-it\n",
      "                                     debug: False\n",
      "                                     debug_slurm: False\n",
      "                                     debug_train: False\n",
      "                                     dropout: 0.1\n",
      "                                     dump_path: ./dumped/test_esit_mlm/test\n",
      "                                     early_stopping: False\n",
      "                                     emb_dim: 1024\n",
      "                                     encoder_only: True\n",
      "                                     epoch_size: 2\n",
      "                                     eval_bleu: False\n",
      "                                     eval_only: False\n",
      "                                     exp_id: test\n",
      "                                     exp_name: test_esit_mlm\n",
      "                                     fp16: False\n",
      "                                     gelu_activation: True\n",
      "                                     global_rank: 0\n",
      "                                     group_by_size: True\n",
      "                                     id2lang: {0: 'es', 1: 'it'}\n",
      "                                     is_master: True\n",
      "                                     is_slurm_job: False\n",
      "                                     lambda_ae: 1\n",
      "                                     lambda_bt: 1\n",
      "                                     lambda_clm: 1\n",
      "                                     lambda_mlm: 1\n",
      "                                     lambda_mt: 1\n",
      "                                     lambda_pc: 1\n",
      "                                     lang2id: {'es': 0, 'it': 1}\n",
      "                                     langs: ['it', 'es']\n",
      "                                     length_penalty: 1\n",
      "                                     lg_sampling_factor: -1\n",
      "                                     lgs: ['es-it', 'it-es']\n",
      "                                     local_rank: 0\n",
      "                                     master_port: -1\n",
      "                                     max_batch_size: 0\n",
      "                                     max_epoch: 1\n",
      "                                     max_len: 100\n",
      "                                     max_vocab: -1\n",
      "                                     meta_learning: True\n",
      "                                     meta_params: {'es-it': Namespace(accumulate_gradients=1, ae_steps=[], amp=-1, asm=False, attention_dropout=0.1, batch_size=2, beam_size=1, bptt=256, bt_src_langs=[], bt_steps=[], clip_grad_norm=5, clm_steps=[], command='python train.py --exp_name test_esit_mlm --dump_path \\'./dumped/\\' --data_path \\'/home/hkseventh/data/30000/es-it\\' --lgs \\'es-it|it-es\\' --clm_steps \\'\\' --mlm_steps \\'es,it|it,es\\' --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout \\'0.1\\' --attention_dropout \\'0.1\\' --gelu_activation true --batch_size 2 --bptt 256 --optimizer \\'adam,lr=0.0001\\' --epoch_size 2 --max_epoch 1 --validation_metrics _valid_mlm_ppl --stopping_criterion \\'_valid_mlm_ppl,10\\' --eval_bleu false --exp_id test --train_n_samples 8 --valid_n_samples 1 --test_n_samples 1 --exp_id \"test\"', context_size=0, data_path='/home/hkseventh/data/30000/es-it', debug=False, debug_slurm=False, debug_train=False, dropout=0.1, dump_path='./dumped/test_esit_mlm/test', early_stopping=False, emb_dim=1024, encoder_only=True, epoch_size=2, eval_bleu=False, eval_only=False, exp_id='test', exp_name='test_esit_mlm', fp16=False, gelu_activation=True, global_rank=0, group_by_size=True, id2lang={0: 'es', 1: 'it'}, is_master=True, is_slurm_job=False, lambda_ae='1', lambda_bt='1', lambda_clm='1', lambda_mlm='1', lambda_mt='1', lambda_pc='1', lang2id={'es': 0, 'it': 1}, langs=['it', 'es'], length_penalty=1, lg_sampling_factor=-1, lgs=['es-it', 'it-es'], local_rank=0, master_port=-1, max_batch_size=0, max_epoch=1, max_len=100, max_vocab=-1, meta_learning=True, meta_params={...}, min_count=0, mlm_steps=[('it', None), ('es', None)], mono_dataset={'it': {'train': '/home/hkseventh/data/30000/es-it/train.it.pth', 'valid': '/home/hkseventh/data/30000/es-it/valid.it.pth', 'test': '/home/hkseventh/data/30000/es-it/test.it.pth'}, 'es': {'train': '/home/hkseventh/data/30000/es-it/train.es.pth', 'valid': '/home/hkseventh/data/30000/es-it/valid.es.pth', 'test': '/home/hkseventh/data/30000/es-it/test.es.pth'}}, mt_steps=[], multi_gpu=False, multi_node=False, n_gpu_per_node=1, n_heads=8, n_langs=2, n_layers=6, n_nodes=1, n_samples={'train': 8, 'valid': 1, 'test': 1}, node_id=0, optimizer='adam,lr=0.0001', para_dataset={}, pc_steps=[], reload_checkpoint='', reload_emb='', reload_model='', remove_long_sentences={'train': True, 'valid': True, 'test': True}, remove_long_sentences_test=True, remove_long_sentences_train=True, remove_long_sentences_valid=True, sample_alpha=0, save_periodic=0, share_inout_emb=True, sinusoidal_embeddings=False, split_data=False, stopping_criterion='_valid_mlm_ppl,10', test_n_samples=1, tokens_per_batch=-1, train_n_samples=8, use_lang_emb=True, use_memory=False, valid_n_samples=1, validation_metrics='_valid_mlm_ppl', word_blank=0, word_dropout=0, word_keep=0.1, word_mask=0.8, word_mask_keep_rand='0.8,0.1,0.1', word_pred=0.15, word_rand=0.1, word_shuffle=0, world_size=1), 'it-es': Namespace(accumulate_gradients=1, ae_steps=[], amp=-1, asm=False, attention_dropout=0.1, batch_size=2, beam_size=1, bptt=256, bt_src_langs=[], bt_steps=[], clip_grad_norm=5, clm_steps=[], command='python train.py --exp_name test_esit_mlm --dump_path \\'./dumped/\\' --data_path \\'/home/hkseventh/data/30000/es-it\\' --lgs \\'es-it|it-es\\' --clm_steps \\'\\' --mlm_steps \\'es,it|it,es\\' --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout \\'0.1\\' --attention_dropout \\'0.1\\' --gelu_activation true --batch_size 2 --bptt 256 --optimizer \\'adam,lr=0.0001\\' --epoch_size 2 --max_epoch 1 --validation_metrics _valid_mlm_ppl --stopping_criterion \\'_valid_mlm_ppl,10\\' --eval_bleu false --exp_id test --train_n_samples 8 --valid_n_samples 1 --test_n_samples 1 --exp_id \"test\"', context_size=0, data_path='/home/hkseventh/data/30000/es-it', debug=False, debug_slurm=False, debug_train=False, dropout=0.1, dump_path='./dumped/test_esit_mlm/test', early_stopping=False, emb_dim=1024, encoder_only=True, epoch_size=2, eval_bleu=False, eval_only=False, exp_id='test', exp_name='test_esit_mlm', fp16=False, gelu_activation=True, global_rank=0, group_by_size=True, id2lang={0: 'es', 1: 'it'}, is_master=True, is_slurm_job=False, lambda_ae='1', lambda_bt='1', lambda_clm='1', lambda_mlm='1', lambda_mt='1', lambda_pc='1', lang2id={'es': 0, 'it': 1}, langs=['it', 'es'], length_penalty=1, lg_sampling_factor=-1, lgs=['es-it', 'it-es'], local_rank=0, master_port=-1, max_batch_size=0, max_epoch=1, max_len=100, max_vocab=-1, meta_learning=True, meta_params={...}, min_count=0, mlm_steps=[('it', None), ('es', None)], mono_dataset={'it': {'train': '/home/hkseventh/data/30000/es-it/train.it.pth', 'valid': '/home/hkseventh/data/30000/es-it/valid.it.pth', 'test': '/home/hkseventh/data/30000/es-it/test.it.pth'}, 'es': {'train': '/home/hkseventh/data/30000/es-it/train.es.pth', 'valid': '/home/hkseventh/data/30000/es-it/valid.es.pth', 'test': '/home/hkseventh/data/30000/es-it/test.es.pth'}}, mt_steps=[], multi_gpu=False, multi_node=False, n_gpu_per_node=1, n_heads=8, n_langs=2, n_layers=6, n_nodes=1, n_samples={'train': 8, 'valid': 1, 'test': 1}, node_id=0, optimizer='adam,lr=0.0001', para_dataset={}, pc_steps=[], reload_checkpoint='', reload_emb='', reload_model='', remove_long_sentences={'train': True, 'valid': True, 'test': True}, remove_long_sentences_test=True, remove_long_sentences_train=True, remove_long_sentences_valid=True, sample_alpha=0, save_periodic=0, share_inout_emb=True, sinusoidal_embeddings=False, split_data=False, stopping_criterion='_valid_mlm_ppl,10', test_n_samples=1, tokens_per_batch=-1, train_n_samples=8, use_lang_emb=True, use_memory=False, valid_n_samples=1, validation_metrics='_valid_mlm_ppl', word_blank=0, word_dropout=0, word_keep=0.1, word_mask=0.8, word_mask_keep_rand='0.8,0.1,0.1', word_pred=0.15, word_rand=0.1, word_shuffle=0, world_size=1)}\n",
      "                                     min_count: 0\n",
      "                                     mlm_steps: [('it', None), ('es', None)]\n",
      "                                     mono_dataset: {'it': {'train': '/home/hkseventh/data/30000/es-it/train.it.pth', 'valid': '/home/hkseventh/data/30000/es-it/valid.it.pth', 'test': '/home/hkseventh/data/30000/es-it/test.it.pth'}, 'es': {'train': '/home/hkseventh/data/30000/es-it/train.es.pth', 'valid': '/home/hkseventh/data/30000/es-it/valid.es.pth', 'test': '/home/hkseventh/data/30000/es-it/test.es.pth'}}\n",
      "                                     mt_steps: []\n",
      "                                     multi_gpu: False\n",
      "                                     multi_node: False\n",
      "                                     n_gpu_per_node: 1\n",
      "                                     n_heads: 8\n",
      "                                     n_langs: 2\n",
      "                                     n_layers: 6\n",
      "                                     n_nodes: 1\n",
      "                                     n_samples: {'train': 8, 'valid': 1, 'test': 1}\n",
      "                                     node_id: 0\n",
      "                                     optimizer: adam,lr=0.0001\n",
      "                                     para_dataset: {}\n",
      "                                     pc_steps: []\n",
      "                                     reload_checkpoint: \n",
      "                                     reload_emb: \n",
      "                                     reload_model: \n",
      "                                     remove_long_sentences: {'train': True, 'valid': True, 'test': True}\n",
      "                                     remove_long_sentences_test: True\n",
      "                                     remove_long_sentences_train: True\n",
      "                                     remove_long_sentences_valid: True\n",
      "                                     sample_alpha: 0\n",
      "                                     save_periodic: 0\n",
      "                                     share_inout_emb: True\n",
      "                                     sinusoidal_embeddings: False\n",
      "                                     split_data: False\n",
      "                                     stopping_criterion: _valid_mlm_ppl,10\n",
      "                                     test_n_samples: 1\n",
      "                                     tokens_per_batch: -1\n",
      "                                     train_n_samples: 8\n",
      "                                     use_lang_emb: True\n",
      "                                     use_memory: False\n",
      "                                     valid_n_samples: 1\n",
      "                                     validation_metrics: _valid_mlm_ppl\n",
      "                                     word_blank: 0\n",
      "                                     word_dropout: 0\n",
      "                                     word_keep: 0.1\n",
      "                                     word_mask: 0.8\n",
      "                                     word_mask_keep_rand: 0.8,0.1,0.1\n",
      "                                     word_pred: 0.15\n",
      "                                     word_rand: 0.1\n",
      "                                     word_shuffle: 0\n",
      "                                     world_size: 1\n",
      "INFO - 05/11/20 21:49:30 - 0:00:00 - The experiment will be stored in ./dumped/test_esit_mlm/test\n",
      "                                     \n",
      "INFO - 05/11/20 21:49:30 - 0:00:00 - Running command: python train.py --exp_name test_esit_mlm --dump_path './dumped/' --data_path '/home/hkseventh/data/30000/es-it' --lgs 'es-it|it-es' --clm_steps '' --mlm_steps 'es,it|it,es' --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 2 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 2 --max_epoch 1 --validation_metrics _valid_mlm_ppl --stopping_criterion '_valid_mlm_ppl,10' --eval_bleu false --exp_id test --train_n_samples 8 --valid_n_samples 1 --test_n_samples 1\n",
      "\n",
      "WARNING - 05/11/20 21:49:30 - 0:00:00 - Signal handler installed.\n",
      "INFO - 05/11/20 21:49:30 - 0:00:00 - ============ Monolingual data (it)\n",
      "INFO - 05/11/20 21:49:30 - 0:00:00 - Loading data from /home/hkseventh/data/30000/es-it/train.it.pth ...\n",
      "INFO - 05/11/20 21:49:30 - 0:00:00 - 116753884 words (30760 unique) in 3847126 sentences. 633 unknown words (490 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 16\n",
      "WARNING - 05/11/20 21:49:31 - 0:00:02 - Invalid split values: 0 0 - 235549\n",
      "\n",
      "INFO - 05/11/20 21:49:31 - 0:00:02 - Loading data from /home/hkseventh/data/30000/es-it/valid.it.pth ...\n",
      "INFO - 05/11/20 21:49:31 - 0:00:02 - 14598718 words (30760 unique) in 480890 sentences. 104 unknown words (84 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 8\n",
      "WARNING - 05/11/20 21:49:31 - 0:00:02 - Invalid split values: 0 0 - 58905\n",
      "\n",
      "INFO - 05/11/20 21:49:31 - 0:00:02 - Loading data from /home/hkseventh/data/30000/es-it/test.it.pth ...\n",
      "INFO - 05/11/20 21:49:31 - 0:00:02 - 14574268 words (30760 unique) in 480890 sentences. 77 unknown words (72 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 8\n",
      "WARNING - 05/11/20 21:49:32 - 0:00:02 - Invalid split values: 0 0 - 58810\n",
      "\n",
      "INFO - 05/11/20 21:49:32 - 0:00:02 - ============ Monolingual data (es)\n",
      "INFO - 05/11/20 21:49:32 - 0:00:02 - Loading data from /home/hkseventh/data/30000/es-it/train.es.pth ...\n",
      "INFO - 05/11/20 21:49:32 - 0:00:02 - 121534108 words (30760 unique) in 3847126 sentences. 668 unknown words (515 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 15\n",
      "WARNING - 05/11/20 21:49:33 - 0:00:04 - Invalid split values: 0 0 - 244886\n",
      "\n",
      "INFO - 05/11/20 21:49:33 - 0:00:04 - Loading data from /home/hkseventh/data/30000/es-it/valid.es.pth ...\n",
      "INFO - 05/11/20 21:49:33 - 0:00:04 - 15199981 words (30760 unique) in 480890 sentences. 129 unknown words (111 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 7\n",
      "WARNING - 05/11/20 21:49:33 - 0:00:04 - Invalid split values: 0 0 - 61254\n",
      "\n",
      "INFO - 05/11/20 21:49:33 - 0:00:04 - Loading data from /home/hkseventh/data/30000/es-it/test.es.pth ...\n",
      "INFO - 05/11/20 21:49:34 - 0:00:04 - 15162799 words (30760 unique) in 480890 sentences. 81 unknown words (73 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 7\n",
      "WARNING - 05/11/20 21:49:34 - 0:00:04 - Invalid split values: 0 0 - 61109\n",
      "\n",
      "\n",
      "\n",
      "INFO - 05/11/20 21:49:34 - 0:00:04 - ============ Data summary\n",
      "INFO - 05/11/20 21:49:34 - 0:00:04 - Monolingual data   - train -           it:   3847126\n",
      "INFO - 05/11/20 21:49:34 - 0:00:04 - Monolingual data   - valid -           it:    480890\n",
      "INFO - 05/11/20 21:49:34 - 0:00:04 - Monolingual data   -  test -           it:    480890\n",
      "INFO - 05/11/20 21:49:34 - 0:00:04 - Monolingual data   - train -           es:   3847126\n",
      "INFO - 05/11/20 21:49:34 - 0:00:04 - Monolingual data   - valid -           es:    480890\n",
      "INFO - 05/11/20 21:49:34 - 0:00:04 - Monolingual data   -  test -           es:    480890\n",
      "\n",
      "INFO - 05/11/20 21:49:34 - 0:00:04 - ============ Monolingual data (it)\n",
      "INFO - 05/11/20 21:49:34 - 0:00:04 - Loading data from /home/hkseventh/data/30000/es-it/train.it.pth ...\n",
      "INFO - 05/11/20 21:49:34 - 0:00:04 - 116753884 words (30760 unique) in 3847126 sentences. 633 unknown words (490 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 16\n",
      "WARNING - 05/11/20 21:49:35 - 0:00:06 - Invalid split values: 0 0 - 235549\n",
      "\n",
      "INFO - 05/11/20 21:49:35 - 0:00:06 - Loading data from /home/hkseventh/data/30000/es-it/valid.it.pth ...\n",
      "INFO - 05/11/20 21:49:35 - 0:00:06 - 14598718 words (30760 unique) in 480890 sentences. 104 unknown words (84 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 8\n",
      "WARNING - 05/11/20 21:49:35 - 0:00:06 - Invalid split values: 0 0 - 58905\n",
      "\n",
      "INFO - 05/11/20 21:49:35 - 0:00:06 - Loading data from /home/hkseventh/data/30000/es-it/test.it.pth ...\n",
      "INFO - 05/11/20 21:49:35 - 0:00:06 - 14574268 words (30760 unique) in 480890 sentences. 77 unknown words (72 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 8\n",
      "WARNING - 05/11/20 21:49:35 - 0:00:06 - Invalid split values: 0 0 - 58810\n",
      "\n",
      "INFO - 05/11/20 21:49:35 - 0:00:06 - ============ Monolingual data (es)\n",
      "INFO - 05/11/20 21:49:35 - 0:00:06 - Loading data from /home/hkseventh/data/30000/es-it/train.es.pth ...\n",
      "INFO - 05/11/20 21:49:36 - 0:00:06 - 121534108 words (30760 unique) in 3847126 sentences. 668 unknown words (515 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 15\n",
      "WARNING - 05/11/20 21:49:37 - 0:00:07 - Invalid split values: 0 0 - 244886\n",
      "\n",
      "INFO - 05/11/20 21:49:37 - 0:00:07 - Loading data from /home/hkseventh/data/30000/es-it/valid.es.pth ...\n",
      "INFO - 05/11/20 21:49:37 - 0:00:08 - 15199981 words (30760 unique) in 480890 sentences. 129 unknown words (111 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 7\n",
      "WARNING - 05/11/20 21:49:37 - 0:00:08 - Invalid split values: 0 0 - 61254\n",
      "\n",
      "INFO - 05/11/20 21:49:37 - 0:00:08 - Loading data from /home/hkseventh/data/30000/es-it/test.es.pth ...\n",
      "INFO - 05/11/20 21:49:37 - 0:00:08 - 15162799 words (30760 unique) in 480890 sentences. 81 unknown words (73 unique) covering 0.00% of the data.\n",
      "phrase_par_batch = 7\n",
      "WARNING - 05/11/20 21:49:37 - 0:00:08 - Invalid split values: 0 0 - 61109\n",
      "\n",
      "\n",
      "\n",
      "INFO - 05/11/20 21:49:37 - 0:00:08 - ============ Data summary\n",
      "INFO - 05/11/20 21:49:37 - 0:00:08 - Monolingual data   - train -           it:   3847126\n",
      "INFO - 05/11/20 21:49:37 - 0:00:08 - Monolingual data   - valid -           it:    480890\n",
      "INFO - 05/11/20 21:49:37 - 0:00:08 - Monolingual data   -  test -           it:    480890\n",
      "INFO - 05/11/20 21:49:37 - 0:00:08 - Monolingual data   - train -           es:   3847126\n",
      "INFO - 05/11/20 21:49:37 - 0:00:08 - Monolingual data   - valid -           es:    480890\n",
      "INFO - 05/11/20 21:49:37 - 0:00:08 - Monolingual data   -  test -           es:    480890\n",
      "\n",
      "INFO - 05/11/20 21:49:39 - 0:00:09 - Model: TransformerModel(\n",
      "                                       (position_embeddings): Embedding(512, 1024)\n",
      "                                       (lang_embeddings): Embedding(2, 1024)\n",
      "                                       (embeddings): Embedding(30760, 1024, padding_idx=2)\n",
      "                                       (layer_norm_emb): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                       (attentions): ModuleList(\n",
      "                                         (0): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (1): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (2): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (3): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (4): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (5): MultiHeadAttention(\n",
      "                                           (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                           (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                       )\n",
      "                                       (layer_norm1): ModuleList(\n",
      "                                         (0): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (2): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (3): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (4): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (5): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                       )\n",
      "                                       (ffns): ModuleList(\n",
      "                                         (0): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (1): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (2): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (3): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (4): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                         (5): TransformerFFN(\n",
      "                                           (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                                           (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                                         )\n",
      "                                       )\n",
      "                                       (layer_norm2): ModuleList(\n",
      "                                         (0): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (2): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (3): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (4): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                         (5): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                                       )\n",
      "                                       (memories): ModuleDict()\n",
      "                                       (pred_layer): PredLayer(\n",
      "                                         (proj): Linear(in_features=1024, out_features=30760, bias=True)\n",
      "                                       )\n",
      "                                     )\n",
      "INFO - 05/11/20 21:49:39 - 0:00:09 - Number of parameters (model): 107634728\n",
      "INFO - 05/11/20 21:49:42 - 0:00:12 - Found 0 memories.\n",
      "INFO - 05/11/20 21:49:42 - 0:00:12 - Found 6 FFN.\n",
      "INFO - 05/11/20 21:49:42 - 0:00:12 - Found 102 parameters in model.\n",
      "INFO - 05/11/20 21:49:42 - 0:00:12 - Optimizers: model\n",
      "WARNING - 05/11/20 21:49:42 - 0:00:12 - Reloading checkpoint from ./dumped/test_esit_mlm/test/checkpoint.pth ...\n",
      "WARNING - 05/11/20 21:49:43 - 0:00:13 - Not reloading checkpoint optimizer model.\n",
      "WARNING - 05/11/20 21:49:43 - 0:00:13 - No 'num_updates' for optimizer model.\n",
      "WARNING - 05/11/20 21:49:43 - 0:00:13 - Checkpoint reloaded. Resuming at epoch 2 / iteration 2 ...\n",
      "INFO - 05/11/20 21:49:43 - 0:00:13 - ============ Starting epoch 2 ... ============\n",
      "params.meta_params[lgs].clm_steps [('it', None), ('es', None)]\n",
      "lang1, lang2 it None\n",
      "lang1, lang2 it None\n",
      "params.meta_params[lgs].clm_steps [('it', None), ('es', None)]\n",
      "lang1, lang2 it None\n",
      "lang1, lang2 it None\n",
      "lang1, lang2 ['it', 'it', 'it', 'it'] [None, None, None, None]\n",
      "INFO - 05/11/20 21:49:43 - 0:00:13 - Creating new training data iterator (pred,it) ...\n",
      "INFO - 05/11/20 21:49:44 - 0:00:14 - ============ End of epoch 2 ============\n"
     ]
    }
   ],
   "source": [
    "%env lgs=es-it|it-es\n",
    "%env mlm_steps=es,it|it,es\n",
    "! python train.py --exp_name test_esit_mlm --dump_path ./dumped/ --data_path $OUTPATH --lgs $lgs --clm_steps '' --mlm_steps $mlm_steps --emb_dim 1024 --n_layers 6 --n_heads 8 --dropout 0.1 --attention_dropout 0.1 --gelu_activation true --batch_size $batch_size --bptt 256 --optimizer adam,lr=0.0001 --epoch_size $epoch_size --max_epoch $max_epoch --validation_metrics _valid_mlm_ppl --stopping_criterion $stopping_criterion --eval_bleu $eval_bleu --exp_id $exp_id --train_n_samples $train_n_samples --valid_n_samples $valid_n_samples --test_n_samples $test_n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
