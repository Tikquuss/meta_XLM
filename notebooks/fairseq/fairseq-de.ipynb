{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare text data for evaluation : en, zh, fr, de, it, ru and es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used [anki's](http://www.manythings.org/anki/) data because the data is almost parallel.  \n",
    "[anki.sh] script downloads and extracts for the specified pair the corresponding parallel data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/meta_XLM\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jupyter/meta_XLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: outpath=/home/jupyter/data/fairseq/evaluation/de\n",
      "env: n_samples=100000\n"
     ]
    }
   ],
   "source": [
    "%env outpath=/home/jupyter/data/fairseq/evaluation/de\n",
    "%env n_samples=100000\n",
    "! chmod +x anki.sh\n",
    "! chmod +x fairseq/samples.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### download and extract && rename and reduce the number of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "--2020-05-31 13:53:43--  http://www.manythings.org/anki/cmn-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.24.108.196, 104.24.109.196, 172.67.173.198, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.24.108.196|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 963049 (940K) [application/zip]\n",
      "Saving to: ‘/home/jupyter/data/fairseq/evaluation/de/cmn-eng.zip’\n",
      "\n",
      "cmn-eng.zip         100%[===================>] 940.48K  3.32MB/s    in 0.3s    \n",
      "\n",
      "2020-05-31 13:53:43 (3.32 MB/s) - ‘/home/jupyter/data/fairseq/evaluation/de/cmn-eng.zip’ saved [963049/963049]\n",
      "\n",
      "Archive:  /home/jupyter/data/fairseq/evaluation/de/cmn-eng.zip\n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/de/cmn.txt  \n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/de/_about.txt  \n",
      "download and extract cmn-eng data in /home/jupyter/data/fairseq/evaluation/de\n",
      "===========================\n",
      "===========================\n",
      "select 100000 of /home/jupyter/data/fairseq/evaluation/de/en-zh.zh.txt to /home/jupyter/data/fairseq/evaluation/de/zh.txt \n",
      "===========================\n",
      "===========================\n",
      "--2020-05-31 13:53:44--  http://www.manythings.org/anki/fra-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 172.67.173.198, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5982778 (5.7M) [application/zip]\n",
      "Saving to: ‘/home/jupyter/data/fairseq/evaluation/de/fra-eng.zip’\n",
      "\n",
      "fra-eng.zip         100%[===================>]   5.71M  13.6MB/s    in 0.4s    \n",
      "\n",
      "2020-05-31 13:53:44 (13.6 MB/s) - ‘/home/jupyter/data/fairseq/evaluation/de/fra-eng.zip’ saved [5982778/5982778]\n",
      "\n",
      "Archive:  /home/jupyter/data/fairseq/evaluation/de/fra-eng.zip\n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/de/_about.txt  \n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/de/fra.txt  \n",
      "download and extract fra-eng data in /home/jupyter/data/fairseq/evaluation/de\n",
      "===========================\n",
      "===========================\n",
      "select 100000 of /home/jupyter/data/fairseq/evaluation/de/en-fr.fr.txt to /home/jupyter/data/fairseq/evaluation/de/fr.txt \n",
      "===========================\n",
      "===========================\n",
      "--2020-05-31 13:53:47--  http://www.manythings.org/anki/deu-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 172.67.173.198, 104.24.108.196, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7876575 (7.5M) [application/zip]\n",
      "Saving to: ‘/home/jupyter/data/fairseq/evaluation/de/deu-eng.zip’\n",
      "\n",
      "deu-eng.zip         100%[===================>]   7.51M  16.0MB/s    in 0.5s    \n",
      "\n",
      "2020-05-31 13:53:47 (16.0 MB/s) - ‘/home/jupyter/data/fairseq/evaluation/de/deu-eng.zip’ saved [7876575/7876575]\n",
      "\n",
      "Archive:  /home/jupyter/data/fairseq/evaluation/de/deu-eng.zip\n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/de/deu.txt  \n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/de/_about.txt  \n",
      "download and extract deu-eng data in /home/jupyter/data/fairseq/evaluation/de\n",
      "===========================\n",
      "===========================\n",
      "select 100000 of /home/jupyter/data/fairseq/evaluation/de/de-en.de.txt to /home/jupyter/data/fairseq/evaluation/de/de.txt \n",
      "===========================\n",
      "===========================\n",
      "--2020-05-31 13:53:50--  http://www.manythings.org/anki/ita-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 172.67.173.198, 104.24.108.196, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7345811 (7.0M) [application/zip]\n",
      "Saving to: ‘/home/jupyter/data/fairseq/evaluation/de/ita-eng.zip’\n",
      "\n",
      "ita-eng.zip         100%[===================>]   7.00M  16.2MB/s    in 0.4s    \n",
      "\n",
      "2020-05-31 13:53:50 (16.2 MB/s) - ‘/home/jupyter/data/fairseq/evaluation/de/ita-eng.zip’ saved [7345811/7345811]\n",
      "\n",
      "Archive:  /home/jupyter/data/fairseq/evaluation/de/ita-eng.zip\n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/de/ita.txt  \n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/de/_about.txt  \n",
      "download and extract ita-eng data in /home/jupyter/data/fairseq/evaluation/de\n",
      "===========================\n",
      "===========================\n",
      "select 100000 of /home/jupyter/data/fairseq/evaluation/de/en-it.it.txt to /home/jupyter/data/fairseq/evaluation/de/it.txt \n",
      "===========================\n",
      "===========================\n",
      "--2020-05-31 13:53:54--  http://www.manythings.org/anki/rus-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 172.67.173.198, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12863721 (12M) [application/zip]\n",
      "Saving to: ‘/home/jupyter/data/fairseq/evaluation/de/rus-eng.zip’\n",
      "\n",
      "rus-eng.zip         100%[===================>]  12.27M  21.0MB/s    in 0.6s    \n",
      "\n",
      "2020-05-31 13:53:55 (21.0 MB/s) - ‘/home/jupyter/data/fairseq/evaluation/de/rus-eng.zip’ saved [12863721/12863721]\n",
      "\n",
      "Archive:  /home/jupyter/data/fairseq/evaluation/de/rus-eng.zip\n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/de/rus.txt  \n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/de/_about.txt  \n",
      "download and extract rus-eng data in /home/jupyter/data/fairseq/evaluation/de\n",
      "===========================\n",
      "===========================\n",
      "select 100000 of /home/jupyter/data/fairseq/evaluation/de/en-ru.ru.txt to /home/jupyter/data/fairseq/evaluation/de/ru.txt \n",
      "===========================\n",
      "===========================\n",
      "--2020-05-31 13:54:00--  http://www.manythings.org/anki/spa-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.24.108.196, 172.67.173.198, 104.24.109.196, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.24.108.196|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4781548 (4.6M) [application/zip]\n",
      "Saving to: ‘/home/jupyter/data/fairseq/evaluation/de/spa-eng.zip’\n",
      "\n",
      "spa-eng.zip         100%[===================>]   4.56M  12.0MB/s    in 0.4s    \n",
      "\n",
      "2020-05-31 13:54:00 (12.0 MB/s) - ‘/home/jupyter/data/fairseq/evaluation/de/spa-eng.zip’ saved [4781548/4781548]\n",
      "\n",
      "Archive:  /home/jupyter/data/fairseq/evaluation/de/spa-eng.zip\n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/de/_about.txt  \n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/de/spa.txt  \n",
      "download and extract spa-eng data in /home/jupyter/data/fairseq/evaluation/de\n",
      "===========================\n",
      "===========================\n",
      "select 100000 of /home/jupyter/data/fairseq/evaluation/de/en-es.es.txt to /home/jupyter/data/fairseq/evaluation/de/es.txt \n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "! ./anki.sh en,zh cmn-eng $outpath anki.py && ./fairseq/samples.sh $outpath/en-zh.zh.txt $outpath/zh.txt $n_samples\n",
    "! ./anki.sh en,fr fra-eng $outpath anki.py && ./fairseq/samples.sh $outpath/en-fr.fr.txt $outpath/fr.txt $n_samples\n",
    "! ./anki.sh de,en deu-eng $outpath anki.py && ./fairseq/samples.sh $outpath/de-en.de.txt $outpath/de.txt $n_samples\n",
    "! ./anki.sh en,it ita-eng $outpath anki.py && ./fairseq/samples.sh $outpath/en-it.it.txt $outpath/it.txt $n_samples\n",
    "! ./anki.sh en,ru rus-eng $outpath anki.py && ./fairseq/samples.sh $outpath/en-ru.ru.txt $outpath/ru.txt $n_samples\n",
    "! ./anki.sh en,es spa-eng $outpath anki.py && ./fairseq/samples.sh $outpath/en-es.es.txt $outpath/es.txt $n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### en data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "select 100000 of /home/jupyter/data/fairseq/evaluation/de/de-en.en.txt to /home/jupyter/data/fairseq/evaluation/de/en.txt \n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "! ./fairseq/samples.sh $outpath/de-en.en.txt $outpath/en.txt $n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to train your one model, look https://github.com/pytorch/fairseq/tree/master/examples/language_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_path=/home/jupyter/fairseq_models\n"
     ]
    }
   ],
   "source": [
    "%env tgt_path=/home/jupyter/fairseq_models\n",
    "! chmod +x ./fairseq/download_model.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-31 13:54:54--  https://dl.fbaipublicfiles.com/fairseq/models/lm/wmt19.de.tar.gz\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 2606:4700:10::6816:4b8e, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2238366726 (2.1G) [application/gzip]\n",
      "Saving to: ‘/home/jupyter/fairseq_models/wmt19.de.tar.gz’\n",
      "\n",
      "wmt19.de.tar.gz     100%[===================>]   2.08G  25.1MB/s    in 94s     \n",
      "\n",
      "2020-05-31 13:56:28 (22.8 MB/s) - ‘/home/jupyter/fairseq_models/wmt19.de.tar.gz’ saved [2238366726/2238366726]\n",
      "\n",
      "wmt19.de/\n",
      "wmt19.de/model.pt\n",
      "wmt19.de/dict.txt\n",
      "wmt19.de/bpecodes\n"
     ]
    }
   ],
   "source": [
    "! ./fairseq/download_model.sh de $tgt_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install dependencies and clone fairseq if not already done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! pip install fastBPE sacremoses  \n",
    "! git clone https://github.com/pytorch/fairseq /home/jupyter/fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/fairseq\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jupyter/fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: modelpath=/home/jupyter/fairseq_models/wmt19.de\n",
      "env: destdir=/home/jupyter/fairseq_data/de\n",
      "env: src_lang=de\n"
     ]
    }
   ],
   "source": [
    "#%env modelpath=$tgt_path/wmnt19.de\n",
    "%env modelpath=/home/jupyter/fairseq_models/wmt19.de\n",
    "%env destdir=/home/jupyter/fairseq_data/de\n",
    "%env src_lang=de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### de vs en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_lang=en\n",
      "2020-05-31 14:04:25 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/home/jupyter/fairseq_data/de/de-en', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, quantization_config_path=None, seed=1, source_lang=None, srcdict='/home/jupyter/fairseq_models/wmt19.de/dict.txt', target_lang=None, task='translation', tensorboard_logdir='', testpref='/home/jupyter/data/fairseq/evaluation/de/en.txt', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=20)\n",
      "2020-05-31 14:04:25 | INFO | fairseq_cli.preprocess | [None] Dictionary: 33551 types\n",
      "2020-05-31 14:04:27 | INFO | fairseq_cli.preprocess | [None] /home/jupyter/data/fairseq/evaluation/de/en.txt: 100000 sents, 774440 tokens, 21.3% replaced by <unk>\n",
      "2020-05-31 14:04:27 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /home/jupyter/fairseq_data/de/de-en\n",
      "2020-05-31 14:04:29 | INFO | fairseq_cli.eval_lm | Namespace(add_bos_token=False, all_gather_list_size=16384, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', context_window=400, cpu=False, criterion='cross_entropy', data='/home/jupyter/fairseq_data/de/de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', empty_cache_freq=0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, max_sentences=2, max_target_positions=None, max_tokens=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, momentum=0.99, no_progress_bar=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='nag', output_dictionary_size=-1, output_word_probs=False, output_word_stats=False, past_target=False, path='/home/jupyter/fairseq_models/wmt19.de/model.pt', quantization_config_path=None, quiet=False, remove_bpe=None, required_batch_size_multiple=8, results_path=None, sample_break_mode='none', seed=1, self_target=False, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, softmax_batch=9223372036854775807, task='language_modeling', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, tpu=False, truncate_sequence=False, user_dir=None, warmup_updates=0, weight_decay=0.0)\n",
      "2020-05-31 14:04:29 | INFO | fairseq.tasks.language_modeling | dictionary: 33552 types\n",
      "2020-05-31 14:04:29 | INFO | fairseq_cli.eval_lm | loading model(s) from /home/jupyter/fairseq_models/wmt19.de/model.pt\n",
      "2020-05-31 14:04:34 | INFO | fairseq.tasks.language_modeling | dictionary: 33552 types\n",
      "2020-05-31 14:04:34 | INFO | fairseq.data.data_utils | loaded 100000 examples from: /home/jupyter/fairseq_data/de/de-en/test\n",
      "2020-05-31 14:04:34 | INFO | fairseq_cli.eval_lm | /home/jupyter/fairseq_data/de/de-en test 6915 examples\n",
      "2020-05-31 14:04:38 | INFO | fairseq_cli.eval_lm | num. model params: 404566016\n",
      "100%|██████████████████████████████| 3458/3458 [14:31<00:00,  4.74it/s, wps=889]2020-05-31 14:19:09 | INFO | fairseq.data.iterators | Data loading buffer is empty or nearly empty. This may indicate a data loading bottleneck, and increasing the number of workers (--num-workers) may help.\n",
      "2020-05-31 14:19:09 | INFO | fairseq_cli.eval_lm | Evaluated 774440 tokens in 867.2s (893.02 tokens/s)\n",
      "2020-05-31 14:19:09 | INFO | fairseq_cli.eval_lm | Loss (base 2): 14.3483, Perplexity: 20858.51\n"
     ]
    }
   ],
   "source": [
    "%env tgt_lang=en\n",
    "# Processes data (only --testpref)\n",
    "! fairseq-preprocess --only-source --testpref $outpath/$tgt_lang.txt --destdir $destdir/$src_lang-$tgt_lang --workers 20 --joined-dictionary --srcdict $modelpath/dict.txt\n",
    "# run evalution\n",
    "! fairseq-eval-lm $destdir/$src_lang-$tgt_lang --path $modelpath/model.pt --max-sentences 2 --tokens-per-sample 512 --context-window 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### de vs zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_lang=zh\n",
      "2020-05-31 16:03:32 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/home/jupyter/fairseq_data/de/de-zh', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, quantization_config_path=None, seed=1, source_lang=None, srcdict='/home/jupyter/fairseq_models/wmt19.de/dict.txt', target_lang=None, task='translation', tensorboard_logdir='', testpref='/home/jupyter/data/fairseq/evaluation/de/zh.txt', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=20)\n",
      "2020-05-31 16:03:32 | INFO | fairseq_cli.preprocess | [None] Dictionary: 33551 types\n",
      "2020-05-31 16:03:33 | INFO | fairseq_cli.preprocess | [None] /home/jupyter/data/fairseq/evaluation/de/zh.txt: 22075 sents, 44300 tokens, 50.1% replaced by <unk>\n",
      "2020-05-31 16:03:33 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /home/jupyter/fairseq_data/de/de-zh\n",
      "2020-05-31 16:03:34 | INFO | fairseq_cli.eval_lm | Namespace(add_bos_token=False, all_gather_list_size=16384, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', context_window=400, cpu=False, criterion='cross_entropy', data='/home/jupyter/fairseq_data/de/de-zh', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', empty_cache_freq=0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, max_sentences=2, max_target_positions=None, max_tokens=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, momentum=0.99, no_progress_bar=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='nag', output_dictionary_size=-1, output_word_probs=False, output_word_stats=False, past_target=False, path='/home/jupyter/fairseq_models/wmt19.de/model.pt', quantization_config_path=None, quiet=False, remove_bpe=None, required_batch_size_multiple=8, results_path=None, sample_break_mode='none', seed=1, self_target=False, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, softmax_batch=9223372036854775807, task='language_modeling', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, tpu=False, truncate_sequence=False, user_dir=None, warmup_updates=0, weight_decay=0.0)\n",
      "2020-05-31 16:03:35 | INFO | fairseq.tasks.language_modeling | dictionary: 33552 types\n",
      "2020-05-31 16:03:35 | INFO | fairseq_cli.eval_lm | loading model(s) from /home/jupyter/fairseq_models/wmt19.de/model.pt\n",
      "2020-05-31 16:03:40 | INFO | fairseq.tasks.language_modeling | dictionary: 33552 types\n",
      "2020-05-31 16:03:40 | INFO | fairseq.data.data_utils | loaded 22075 examples from: /home/jupyter/fairseq_data/de/de-zh/test\n",
      "2020-05-31 16:03:40 | INFO | fairseq_cli.eval_lm | /home/jupyter/fairseq_data/de/de-zh test 396 examples\n",
      "2020-05-31 16:03:51 | INFO | fairseq_cli.eval_lm | num. model params: 404566016\n",
      "2020-05-31 16:06:00 | INFO | fairseq_cli.eval_lm | Evaluated 44300 tokens in 124.5s (355.86 tokens/s)\n",
      "2020-05-31 16:06:00 | INFO | fairseq_cli.eval_lm | Loss (base 2): 19.4811, Perplexity: 731801.31\n"
     ]
    }
   ],
   "source": [
    "%env tgt_lang=zh\n",
    "# Processes data (only --testpref)\n",
    "! fairseq-preprocess --only-source --testpref $outpath/$tgt_lang.txt --destdir $destdir/$src_lang-$tgt_lang --workers 20 --joined-dictionary --srcdict $modelpath/dict.txt\n",
    "# run evalution\n",
    "! fairseq-eval-lm $destdir/$src_lang-$tgt_lang --path $modelpath/model.pt --max-sentences 2 --tokens-per-sample 512 --context-window 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: skip-invalid_size_inputs_valid_test=True\n",
      "env: tgt_lang=zh\n",
      "2020-05-31 16:29:38 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/home/jupyter/fairseq_data/de/de-zh-1', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, quantization_config_path=None, seed=1, source_lang=None, srcdict='/home/jupyter/fairseq_models/wmt19.de/dict.txt', target_lang=None, task='translation', tensorboard_logdir='', testpref='/home/jupyter/data/fairseq/evaluation/de/zh.txt', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=20)\n",
      "2020-05-31 16:29:38 | INFO | fairseq_cli.preprocess | [None] Dictionary: 33551 types\n",
      "2020-05-31 16:29:39 | INFO | fairseq_cli.preprocess | [None] /home/jupyter/data/fairseq/evaluation/de/zh.txt: 22075 sents, 44300 tokens, 50.1% replaced by <unk>\n",
      "2020-05-31 16:29:39 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /home/jupyter/fairseq_data/de/de-zh-1\n",
      "usage: fairseq-eval-lm [-h] [--no-progress-bar] [--log-interval N]\n",
      "                       [--log-format {json,none,simple,tqdm}]\n",
      "                       [--tensorboard-logdir DIR] [--seed N] [--cpu] [--tpu]\n",
      "                       [--bf16] [--fp16] [--memory-efficient-bf16]\n",
      "                       [--memory-efficient-fp16] [--fp16-no-flatten-grads]\n",
      "                       [--fp16-init-scale FP16_INIT_SCALE]\n",
      "                       [--fp16-scale-window FP16_SCALE_WINDOW]\n",
      "                       [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]\n",
      "                       [--min-loss-scale D]\n",
      "                       [--threshold-loss-scale THRESHOLD_LOSS_SCALE]\n",
      "                       [--user-dir USER_DIR]\n",
      "                       [--empty-cache-freq EMPTY_CACHE_FREQ]\n",
      "                       [--all-gather-list-size ALL_GATHER_LIST_SIZE]\n",
      "                       [--model-parallel-size N]\n",
      "                       [--checkpoint-suffix CHECKPOINT_SUFFIX]\n",
      "                       [--quantization-config-path QUANTIZATION_CONFIG_PATH]\n",
      "                       [--criterion {label_smoothed_cross_entropy,cross_entropy,sentence_prediction,binary_cross_entropy,label_smoothed_cross_entropy_with_alignment,masked_lm,legacy_masked_lm_loss,adaptive_loss,composite_loss,sentence_ranking,nat_loss,vocab_parallel_cross_entropy}]\n",
      "                       [--tokenizer {nltk,moses,space}]\n",
      "                       [--bpe {gpt2,byte_bpe,characters,subword_nmt,sentencepiece,hf_byte_bpe,bytes,fastbpe,bert}]\n",
      "                       [--optimizer {adamax,adadelta,lamb,nag,adagrad,adam,sgd,adafactor}]\n",
      "                       [--lr-scheduler {tri_stage,inverse_sqrt,polynomial_decay,cosine,triangular,reduce_lr_on_plateau,fixed}]\n",
      "                       [--task TASK] [--num-workers N]\n",
      "                       [--skip-invalid-size-inputs-valid-test]\n",
      "                       [--max-tokens N] [--max-sentences N]\n",
      "                       [--required-batch-size-multiple N]\n",
      "                       [--dataset-impl FORMAT] [--data-buffer-size N]\n",
      "                       [--gen-subset SPLIT] [--num-shards N] [--shard-id ID]\n",
      "                       [--distributed-world-size N]\n",
      "                       [--distributed-rank DISTRIBUTED_RANK]\n",
      "                       [--distributed-backend DISTRIBUTED_BACKEND]\n",
      "                       [--distributed-init-method DISTRIBUTED_INIT_METHOD]\n",
      "                       [--distributed-port DISTRIBUTED_PORT]\n",
      "                       [--device-id DEVICE_ID] [--distributed-no-spawn]\n",
      "                       [--ddp-backend {c10d,no_c10d}] [--bucket-cap-mb MB]\n",
      "                       [--fix-batches-to-gpus] [--find-unused-parameters]\n",
      "                       [--fast-stat-sync] [--broadcast-buffers]\n",
      "                       [--distributed-wrapper {DDP,SlowMo}]\n",
      "                       [--slowmo-momentum SLOWMO_MOMENTUM]\n",
      "                       [--slowmo-algorithm {LocalSGD,SGP}]\n",
      "                       [--localsgd-frequency LOCALSGD_FREQUENCY]\n",
      "                       [--nprocs-per-node N] [--path FILE]\n",
      "                       [--remove-bpe [REMOVE_BPE]] [--quiet]\n",
      "                       [--model-overrides DICT] [--results-path RESDIR]\n",
      "                       [--output-word-probs] [--output-word-stats]\n",
      "                       [--context-window N] [--softmax-batch N] [--momentum M]\n",
      "                       [--weight-decay WD] [--force-anneal N] [--lr-shrink LS]\n",
      "                       [--warmup-updates N]\n",
      "                       [--sample-break-mode {none,complete,complete_doc,eos}]\n",
      "                       [--tokens-per-sample TOKENS_PER_SAMPLE]\n",
      "                       [--output-dictionary-size OUTPUT_DICTIONARY_SIZE]\n",
      "                       [--self-target] [--future-target] [--past-target]\n",
      "                       [--add-bos-token] [--max-target-positions N]\n",
      "                       [--truncate-sequence]\n",
      "                       data\n",
      "fairseq-eval-lm: error: unrecognized arguments: True\n"
     ]
    }
   ],
   "source": [
    "%env skip-invalid_size_inputs_valid_test=True\n",
    "%env tgt_lang=zh\n",
    "# Processes data (only --testpref)\n",
    "! fairseq-preprocess --only-source --testpref $outpath/$tgt_lang.txt --destdir $destdir/$src_lang-$tgt_lang-1 --workers 20 --joined-dictionary --srcdict $modelpath/dict.txt\n",
    "# run evalution\n",
    "! fairseq-eval-lm $destdir/$src_lang-$tgt_lang-1 --path $modelpath/model.pt --max-sentences 2 --tokens-per-sample 512 --context-window 400 --skip-invalid-size-inputs-valid-test $skip_invalid_size_inputs_valid_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### de vs fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_lang=fr\n",
      "2020-05-31 14:20:34 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/home/jupyter/fairseq_data/de/de-fr', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, quantization_config_path=None, seed=1, source_lang=None, srcdict='/home/jupyter/fairseq_models/wmt19.de/dict.txt', target_lang=None, task='translation', tensorboard_logdir='', testpref='/home/jupyter/data/fairseq/evaluation/de/fr.txt', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=20)\n",
      "2020-05-31 14:20:34 | INFO | fairseq_cli.preprocess | [None] Dictionary: 33551 types\n",
      "2020-05-31 14:20:37 | INFO | fairseq_cli.preprocess | [None] /home/jupyter/data/fairseq/evaluation/de/fr.txt: 100000 sents, 797805 tokens, 51.3% replaced by <unk>\n",
      "2020-05-31 14:20:37 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /home/jupyter/fairseq_data/de/de-fr\n",
      "2020-05-31 14:20:39 | INFO | fairseq_cli.eval_lm | Namespace(add_bos_token=False, all_gather_list_size=16384, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', context_window=400, cpu=False, criterion='cross_entropy', data='/home/jupyter/fairseq_data/de/de-fr', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', empty_cache_freq=0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, max_sentences=2, max_target_positions=None, max_tokens=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, momentum=0.99, no_progress_bar=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='nag', output_dictionary_size=-1, output_word_probs=False, output_word_stats=False, past_target=False, path='/home/jupyter/fairseq_models/wmt19.de/model.pt', quantization_config_path=None, quiet=False, remove_bpe=None, required_batch_size_multiple=8, results_path=None, sample_break_mode='none', seed=1, self_target=False, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, softmax_batch=9223372036854775807, task='language_modeling', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, tpu=False, truncate_sequence=False, user_dir=None, warmup_updates=0, weight_decay=0.0)\n",
      "2020-05-31 14:20:39 | INFO | fairseq.tasks.language_modeling | dictionary: 33552 types\n",
      "2020-05-31 14:20:39 | INFO | fairseq_cli.eval_lm | loading model(s) from /home/jupyter/fairseq_models/wmt19.de/model.pt\n",
      "2020-05-31 14:20:44 | INFO | fairseq.tasks.language_modeling | dictionary: 33552 types\n",
      "2020-05-31 14:20:44 | INFO | fairseq.data.data_utils | loaded 100000 examples from: /home/jupyter/fairseq_data/de/de-fr/test\n",
      "2020-05-31 14:20:44 | INFO | fairseq_cli.eval_lm | /home/jupyter/fairseq_data/de/de-fr test 7124 examples\n",
      "2020-05-31 14:20:52 | INFO | fairseq_cli.eval_lm | num. model params: 404566016\n",
      "100%|██████████████████████████████| 3562/3562 [48:16<00:00,  1.31it/s, wps=275]2020-05-31 15:09:08 | INFO | fairseq.data.iterators | Data loading buffer is empty or nearly empty. This may indicate a data loading bottleneck, and increasing the number of workers (--num-workers) may help.\n",
      "2020-05-31 15:09:08 | INFO | fairseq_cli.eval_lm | Evaluated 797805 tokens in 2784.7s (286.49 tokens/s)\n",
      "2020-05-31 15:09:08 | INFO | fairseq_cli.eval_lm | Loss (base 2): 22.9919, Perplexity: 8341396.50\n"
     ]
    }
   ],
   "source": [
    "%env tgt_lang=fr\n",
    "# Processes data (only --testpref)\n",
    "! fairseq-preprocess --only-source --testpref $outpath/$tgt_lang.txt --destdir $destdir/$src_lang-$tgt_lang --workers 20 --joined-dictionary --srcdict $modelpath/dict.txt\n",
    "# run evalution\n",
    "! fairseq-eval-lm $destdir/$src_lang-$tgt_lang --path $modelpath/model.pt --max-sentences 2 --tokens-per-sample 512 --context-window 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### de vs de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_lang=de\n",
      "2020-05-31 15:15:38 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/home/jupyter/fairseq_data/de/de-de', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, quantization_config_path=None, seed=1, source_lang=None, srcdict='/home/jupyter/fairseq_models/wmt19.de/dict.txt', target_lang=None, task='translation', tensorboard_logdir='', testpref='/home/jupyter/data/fairseq/evaluation/de/de.txt', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=20)\n",
      "2020-05-31 15:15:38 | INFO | fairseq_cli.preprocess | [None] Dictionary: 33551 types\n",
      "2020-05-31 15:15:41 | INFO | fairseq_cli.preprocess | [None] /home/jupyter/data/fairseq/evaluation/de/de.txt: 100000 sents, 778387 tokens, 25.2% replaced by <unk>\n",
      "2020-05-31 15:15:41 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /home/jupyter/fairseq_data/de/de-de\n",
      "2020-05-31 15:15:43 | INFO | fairseq_cli.eval_lm | Namespace(add_bos_token=False, all_gather_list_size=16384, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', context_window=400, cpu=False, criterion='cross_entropy', data='/home/jupyter/fairseq_data/de/de-de', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', empty_cache_freq=0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, max_sentences=2, max_target_positions=None, max_tokens=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, momentum=0.99, no_progress_bar=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='nag', output_dictionary_size=-1, output_word_probs=False, output_word_stats=False, past_target=False, path='/home/jupyter/fairseq_models/wmt19.de/model.pt', quantization_config_path=None, quiet=False, remove_bpe=None, required_batch_size_multiple=8, results_path=None, sample_break_mode='none', seed=1, self_target=False, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, softmax_batch=9223372036854775807, task='language_modeling', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, tpu=False, truncate_sequence=False, user_dir=None, warmup_updates=0, weight_decay=0.0)\n",
      "2020-05-31 15:15:43 | INFO | fairseq.tasks.language_modeling | dictionary: 33552 types\n",
      "2020-05-31 15:15:43 | INFO | fairseq_cli.eval_lm | loading model(s) from /home/jupyter/fairseq_models/wmt19.de/model.pt\n",
      "2020-05-31 15:15:49 | INFO | fairseq.tasks.language_modeling | dictionary: 33552 types\n",
      "2020-05-31 15:15:49 | INFO | fairseq.data.data_utils | loaded 100000 examples from: /home/jupyter/fairseq_data/de/de-de/test\n",
      "2020-05-31 15:15:49 | INFO | fairseq_cli.eval_lm | /home/jupyter/fairseq_data/de/de-de test 6950 examples\n",
      "2020-05-31 15:15:56 | INFO | fairseq_cli.eval_lm | num. model params: 404566016\n",
      "100%|██████████████████████████████| 3475/3475 [45:37<00:00,  1.21it/s, wps=284]2020-05-31 16:01:34 | INFO | fairseq.data.iterators | Data loading buffer is empty or nearly empty. This may indicate a data loading bottleneck, and increasing the number of workers (--num-workers) may help.\n",
      "2020-05-31 16:01:34 | INFO | fairseq_cli.eval_lm | Evaluated 778387 tokens in 2633.8s (295.54 tokens/s)\n",
      "2020-05-31 16:01:34 | INFO | fairseq_cli.eval_lm | Loss (base 2): 16.1539, Perplexity: 72912.62\n"
     ]
    }
   ],
   "source": [
    "%env tgt_lang=de\n",
    "# Processes data (only --testpref)\n",
    "! fairseq-preprocess --only-source --testpref $outpath/$tgt_lang.txt --destdir $destdir/$src_lang-$tgt_lang --workers 20 --joined-dictionary --srcdict $modelpath/dict.txt\n",
    "# run evalution\n",
    "! fairseq-eval-lm $destdir/$src_lang-$tgt_lang --path $modelpath/model.pt --max-sentences 2 --tokens-per-sample 512 --context-window 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### de vs it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_lang=it\n",
      "2020-05-31 16:30:36 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/home/jupyter/fairseq_data/de/de-it', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, quantization_config_path=None, seed=1, source_lang=None, srcdict='/home/jupyter/fairseq_models/wmt19.de/dict.txt', target_lang=None, task='translation', tensorboard_logdir='', testpref='/home/jupyter/data/fairseq/evaluation/de/it.txt', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=20)\n",
      "2020-05-31 16:30:36 | INFO | fairseq_cli.preprocess | [None] Dictionary: 33551 types\n",
      "2020-05-31 16:30:39 | INFO | fairseq_cli.preprocess | [None] /home/jupyter/data/fairseq/evaluation/de/it.txt: 100000 sents, 682297 tokens, 54.4% replaced by <unk>\n",
      "2020-05-31 16:30:39 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /home/jupyter/fairseq_data/de/de-it\n",
      "2020-05-31 16:30:41 | INFO | fairseq_cli.eval_lm | Namespace(add_bos_token=False, all_gather_list_size=16384, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', context_window=400, cpu=False, criterion='cross_entropy', data='/home/jupyter/fairseq_data/de/de-it', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', empty_cache_freq=0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, max_sentences=2, max_target_positions=None, max_tokens=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, momentum=0.99, no_progress_bar=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='nag', output_dictionary_size=-1, output_word_probs=False, output_word_stats=False, past_target=False, path='/home/jupyter/fairseq_models/wmt19.de/model.pt', quantization_config_path=None, quiet=False, remove_bpe=None, required_batch_size_multiple=8, results_path=None, sample_break_mode='none', seed=1, self_target=False, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, softmax_batch=9223372036854775807, task='language_modeling', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, tpu=False, truncate_sequence=False, user_dir=None, warmup_updates=0, weight_decay=0.0)\n",
      "2020-05-31 16:30:41 | INFO | fairseq.tasks.language_modeling | dictionary: 33552 types\n",
      "2020-05-31 16:30:41 | INFO | fairseq_cli.eval_lm | loading model(s) from /home/jupyter/fairseq_models/wmt19.de/model.pt\n",
      "2020-05-31 16:30:46 | INFO | fairseq.tasks.language_modeling | dictionary: 33552 types\n",
      "2020-05-31 16:30:46 | INFO | fairseq.data.data_utils | loaded 100000 examples from: /home/jupyter/fairseq_data/de/de-it/test\n",
      "2020-05-31 16:30:46 | INFO | fairseq_cli.eval_lm | /home/jupyter/fairseq_data/de/de-it test 6092 examples\n",
      "2020-05-31 16:30:57 | INFO | fairseq_cli.eval_lm | num. model params: 404566016\n",
      "100%|██████████████████████████████| 3046/3046 [41:18<00:00,  1.21it/s, wps=275]2020-05-31 17:12:16 | INFO | fairseq.data.iterators | Data loading buffer is empty or nearly empty. This may indicate a data loading bottleneck, and increasing the number of workers (--num-workers) may help.\n",
      "2020-05-31 17:12:16 | INFO | fairseq_cli.eval_lm | Evaluated 682297 tokens in 2381.9s (286.46 tokens/s)\n",
      "2020-05-31 17:12:16 | INFO | fairseq_cli.eval_lm | Loss (base 2): 23.7999, Perplexity: 14604692.00\n"
     ]
    }
   ],
   "source": [
    "%env tgt_lang=it\n",
    "# Processes data (only --testpref)\n",
    "! fairseq-preprocess --only-source --testpref $outpath/$tgt_lang.txt --destdir $destdir/$src_lang-$tgt_lang --workers 20 --joined-dictionary --srcdict $modelpath/dict.txt\n",
    "# run evalution\n",
    "! fairseq-eval-lm $destdir/$src_lang-$tgt_lang --path $modelpath/model.pt --max-sentences 2 --tokens-per-sample 512 --context-window 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### de vs ru   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_lang=ru\n",
      "2020-05-31 17:13:24 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/home/jupyter/fairseq_data/de/de-ru', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, quantization_config_path=None, seed=1, source_lang=None, srcdict='/home/jupyter/fairseq_models/wmt19.de/dict.txt', target_lang=None, task='translation', tensorboard_logdir='', testpref='/home/jupyter/data/fairseq/evaluation/de/ru.txt', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=20)\n",
      "2020-05-31 17:13:24 | INFO | fairseq_cli.preprocess | [None] Dictionary: 33551 types\n",
      "2020-05-31 17:13:28 | INFO | fairseq_cli.preprocess | [None] /home/jupyter/data/fairseq/evaluation/de/ru.txt: 100000 sents, 665396 tokens, 76.5% replaced by <unk>\n",
      "2020-05-31 17:13:28 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /home/jupyter/fairseq_data/de/de-ru\n",
      "2020-05-31 17:13:30 | INFO | fairseq_cli.eval_lm | Namespace(add_bos_token=False, all_gather_list_size=16384, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', context_window=400, cpu=False, criterion='cross_entropy', data='/home/jupyter/fairseq_data/de/de-ru', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', empty_cache_freq=0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, max_sentences=2, max_target_positions=None, max_tokens=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, momentum=0.99, no_progress_bar=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='nag', output_dictionary_size=-1, output_word_probs=False, output_word_stats=False, past_target=False, path='/home/jupyter/fairseq_models/wmt19.de/model.pt', quantization_config_path=None, quiet=False, remove_bpe=None, required_batch_size_multiple=8, results_path=None, sample_break_mode='none', seed=1, self_target=False, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, softmax_batch=9223372036854775807, task='language_modeling', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, tpu=False, truncate_sequence=False, user_dir=None, warmup_updates=0, weight_decay=0.0)\n",
      "2020-05-31 17:13:30 | INFO | fairseq.tasks.language_modeling | dictionary: 33552 types\n",
      "2020-05-31 17:13:30 | INFO | fairseq_cli.eval_lm | loading model(s) from /home/jupyter/fairseq_models/wmt19.de/model.pt\n",
      "2020-05-31 17:13:35 | INFO | fairseq.tasks.language_modeling | dictionary: 33552 types\n",
      "2020-05-31 17:13:35 | INFO | fairseq.data.data_utils | loaded 100000 examples from: /home/jupyter/fairseq_data/de/de-ru/test\n",
      "2020-05-31 17:13:35 | INFO | fairseq_cli.eval_lm | /home/jupyter/fairseq_data/de/de-ru test 5942 examples\n",
      "2020-05-31 17:13:46 | INFO | fairseq_cli.eval_lm | num. model params: 404566016\n",
      "100%|██████████████████████████████| 2971/2971 [29:54<00:00,  1.88it/s, wps=371]2020-05-31 17:43:41 | INFO | fairseq.data.iterators | Data loading buffer is empty or nearly empty. This may indicate a data loading bottleneck, and increasing the number of workers (--num-workers) may help.\n",
      "2020-05-31 17:43:41 | INFO | fairseq_cli.eval_lm | Evaluated 665396 tokens in 1757.0s (378.72 tokens/s)\n",
      "2020-05-31 17:43:41 | INFO | fairseq_cli.eval_lm | Loss (base 2): 28.3790, Perplexity: 349077696.00\n"
     ]
    }
   ],
   "source": [
    "%env tgt_lang=ru\n",
    "# Processes data (only --testpref)\n",
    "! fairseq-preprocess --only-source --testpref $outpath/$tgt_lang.txt --destdir $destdir/$src_lang-$tgt_lang --workers 20 --joined-dictionary --srcdict $modelpath/dict.txt\n",
    "# run evalution\n",
    "! fairseq-eval-lm $destdir/$src_lang-$tgt_lang --path $modelpath/model.pt --max-sentences 2 --tokens-per-sample 512 --context-window 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### de vs es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_lang=es\n",
      "2020-05-31 17:47:55 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/home/jupyter/fairseq_data/de/de-es', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, quantization_config_path=None, seed=1, source_lang=None, srcdict='/home/jupyter/fairseq_models/wmt19.de/dict.txt', target_lang=None, task='translation', tensorboard_logdir='', testpref='/home/jupyter/data/fairseq/evaluation/de/es.txt', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=20)\n",
      "2020-05-31 17:47:55 | INFO | fairseq_cli.preprocess | [None] Dictionary: 33551 types\n",
      "2020-05-31 17:47:59 | INFO | fairseq_cli.preprocess | [None] /home/jupyter/data/fairseq/evaluation/de/es.txt: 100000 sents, 716155 tokens, 53.5% replaced by <unk>\n",
      "2020-05-31 17:47:59 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /home/jupyter/fairseq_data/de/de-es\n",
      "2020-05-31 17:48:00 | INFO | fairseq_cli.eval_lm | Namespace(add_bos_token=False, all_gather_list_size=16384, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', context_window=400, cpu=False, criterion='cross_entropy', data='/home/jupyter/fairseq_data/de/de-es', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', empty_cache_freq=0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, max_sentences=2, max_target_positions=None, max_tokens=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, momentum=0.99, no_progress_bar=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='nag', output_dictionary_size=-1, output_word_probs=False, output_word_stats=False, past_target=False, path='/home/jupyter/fairseq_models/wmt19.de/model.pt', quantization_config_path=None, quiet=False, remove_bpe=None, required_batch_size_multiple=8, results_path=None, sample_break_mode='none', seed=1, self_target=False, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, softmax_batch=9223372036854775807, task='language_modeling', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, tpu=False, truncate_sequence=False, user_dir=None, warmup_updates=0, weight_decay=0.0)\n",
      "2020-05-31 17:48:00 | INFO | fairseq.tasks.language_modeling | dictionary: 33552 types\n",
      "2020-05-31 17:48:00 | INFO | fairseq_cli.eval_lm | loading model(s) from /home/jupyter/fairseq_models/wmt19.de/model.pt\n",
      "2020-05-31 17:48:06 | INFO | fairseq.tasks.language_modeling | dictionary: 33552 types\n",
      "2020-05-31 17:48:06 | INFO | fairseq.data.data_utils | loaded 100000 examples from: /home/jupyter/fairseq_data/de/de-es/test\n",
      "2020-05-31 17:48:06 | INFO | fairseq_cli.eval_lm | /home/jupyter/fairseq_data/de/de-es test 6395 examples\n",
      "2020-05-31 17:48:13 | INFO | fairseq_cli.eval_lm | num. model params: 404566016\n",
      "100%|██████████████████████████████| 3198/3198 [43:30<00:00,  2.14it/s, wps=274]2020-05-31 18:31:44 | INFO | fairseq.data.iterators | Data loading buffer is empty or nearly empty. This may indicate a data loading bottleneck, and increasing the number of workers (--num-workers) may help.\n",
      "2020-05-31 18:31:44 | INFO | fairseq_cli.eval_lm | Evaluated 716155 tokens in 2508.8s (285.45 tokens/s)\n",
      "2020-05-31 18:31:44 | INFO | fairseq_cli.eval_lm | Loss (base 2): 23.1027, Perplexity: 9007501.00\n"
     ]
    }
   ],
   "source": [
    "%env tgt_lang=es\n",
    "# Processes data (only --testpref)\n",
    "! fairseq-preprocess --only-source --testpref $outpath/$tgt_lang.txt --destdir $destdir/$src_lang-$tgt_lang --workers 20 --joined-dictionary --srcdict $modelpath/dict.txt\n",
    "# run evalution\n",
    "! fairseq-eval-lm $destdir/$src_lang-$tgt_lang --path $modelpath/model.pt --max-sentences 2 --tokens-per-sample 512 --context-window 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
