{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare text data for evaluation : en, zh, fr, de, it, ru and es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used [anki's](http://www.manythings.org/anki/) data because the data is almost parallel.  \n",
    "[anki.sh] script downloads and extracts for the specified pair the corresponding parallel data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/meta_XLM\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jupyter/meta_XLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: outpath=/home/jupyter/data/fairseq/evaluation/ru\n",
      "env: n_samples=100000\n"
     ]
    }
   ],
   "source": [
    "%env outpath=/home/jupyter/data/fairseq/evaluation/ru\n",
    "%env n_samples=100000\n",
    "! chmod +x anki.sh\n",
    "! chmod +x fairseq/samples.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### download and extract && rename and reduce the number of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "--2020-05-31 14:12:15--  http://www.manythings.org/anki/cmn-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.24.108.196, 172.67.173.198, 104.24.109.196, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.24.108.196|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 963049 (940K) [application/zip]\n",
      "Saving to: ‘/home/jupyter/data/fairseq/evaluation/ru/cmn-eng.zip’\n",
      "\n",
      "cmn-eng.zip         100%[===================>] 940.48K  3.27MB/s    in 0.3s    \n",
      "\n",
      "2020-05-31 14:12:15 (3.27 MB/s) - ‘/home/jupyter/data/fairseq/evaluation/ru/cmn-eng.zip’ saved [963049/963049]\n",
      "\n",
      "Archive:  /home/jupyter/data/fairseq/evaluation/ru/cmn-eng.zip\n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/ru/cmn.txt  \n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/ru/_about.txt  \n",
      "download and extract cmn-eng data in /home/jupyter/data/fairseq/evaluation/ru\n",
      "===========================\n",
      "===========================\n",
      "select 100000 of /home/jupyter/data/fairseq/evaluation/ru/en-zh.zh.txt to /home/jupyter/data/fairseq/evaluation/ru/zh.txt \n",
      "===========================\n",
      "===========================\n",
      "--2020-05-31 14:12:15--  http://www.manythings.org/anki/fra-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.24.108.196, 172.67.173.198, 104.24.109.196, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.24.108.196|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5982778 (5.7M) [application/zip]\n",
      "Saving to: ‘/home/jupyter/data/fairseq/evaluation/ru/fra-eng.zip’\n",
      "\n",
      "fra-eng.zip         100%[===================>]   5.71M  13.7MB/s    in 0.4s    \n",
      "\n",
      "2020-05-31 14:12:16 (13.7 MB/s) - ‘/home/jupyter/data/fairseq/evaluation/ru/fra-eng.zip’ saved [5982778/5982778]\n",
      "\n",
      "Archive:  /home/jupyter/data/fairseq/evaluation/ru/fra-eng.zip\n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/ru/_about.txt  \n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/ru/fra.txt  \n",
      "download and extract fra-eng data in /home/jupyter/data/fairseq/evaluation/ru\n",
      "===========================\n",
      "===========================\n",
      "select 100000 of /home/jupyter/data/fairseq/evaluation/ru/en-fr.fr.txt to /home/jupyter/data/fairseq/evaluation/ru/fr.txt \n",
      "===========================\n",
      "===========================\n",
      "--2020-05-31 14:12:18--  http://www.manythings.org/anki/deu-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.24.108.196, 172.67.173.198, 104.24.109.196, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.24.108.196|:80... connected.\n",
      "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n",
      "Archive:  /home/jupyter/data/fairseq/evaluation/ru/deu-eng.zip\n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/ru/_about.txt  \n",
      "download and extract deu-eng data in /home/jupyter/data/fairseq/evaluation/ru\n",
      "===========================\n",
      "===========================\n",
      "select 100000 of /home/jupyter/data/fairseq/evaluation/ru/de-en.de.txt to /home/jupyter/data/fairseq/evaluation/ru/de.txt \n",
      "===========================\n",
      "===========================\n",
      "--2020-05-31 14:12:21--  http://www.manythings.org/anki/ita-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 172.67.173.198, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7345811 (7.0M) [application/zip]\n",
      "Saving to: ‘/home/jupyter/data/fairseq/evaluation/ru/ita-eng.zip’\n",
      "\n",
      "ita-eng.zip         100%[===================>]   7.00M  16.3MB/s    in 0.4s    \n",
      "\n",
      "2020-05-31 14:12:22 (16.3 MB/s) - ‘/home/jupyter/data/fairseq/evaluation/ru/ita-eng.zip’ saved [7345811/7345811]\n",
      "\n",
      "Archive:  /home/jupyter/data/fairseq/evaluation/ru/ita-eng.zip\n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/ru/ita.txt  \n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/ru/_about.txt  \n",
      "download and extract ita-eng data in /home/jupyter/data/fairseq/evaluation/ru\n",
      "===========================\n",
      "===========================\n",
      "select 100000 of /home/jupyter/data/fairseq/evaluation/ru/en-it.it.txt to /home/jupyter/data/fairseq/evaluation/ru/it.txt \n",
      "===========================\n",
      "===========================\n",
      "--2020-05-31 14:12:25--  http://www.manythings.org/anki/rus-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 172.67.173.198, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12863721 (12M) [application/zip]\n",
      "Saving to: ‘/home/jupyter/data/fairseq/evaluation/ru/rus-eng.zip’\n",
      "\n",
      "rus-eng.zip         100%[===================>]  12.27M  21.9MB/s    in 0.6s    \n",
      "\n",
      "2020-05-31 14:12:26 (21.9 MB/s) - ‘/home/jupyter/data/fairseq/evaluation/ru/rus-eng.zip’ saved [12863721/12863721]\n",
      "\n",
      "Archive:  /home/jupyter/data/fairseq/evaluation/ru/rus-eng.zip\n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/ru/rus.txt  \n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/ru/_about.txt  \n",
      "download and extract rus-eng data in /home/jupyter/data/fairseq/evaluation/ru\n",
      "===========================\n",
      "===========================\n",
      "select 100000 of /home/jupyter/data/fairseq/evaluation/ru/en-ru.ru.txt to /home/jupyter/data/fairseq/evaluation/ru/ru.txt \n",
      "===========================\n",
      "===========================\n",
      "--2020-05-31 14:12:31--  http://www.manythings.org/anki/spa-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 172.67.173.198, 104.24.108.196, 104.24.109.196, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|172.67.173.198|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4781548 (4.6M) [application/zip]\n",
      "Saving to: ‘/home/jupyter/data/fairseq/evaluation/ru/spa-eng.zip’\n",
      "\n",
      "spa-eng.zip         100%[===================>]   4.56M  11.9MB/s    in 0.4s    \n",
      "\n",
      "2020-05-31 14:12:32 (11.9 MB/s) - ‘/home/jupyter/data/fairseq/evaluation/ru/spa-eng.zip’ saved [4781548/4781548]\n",
      "\n",
      "Archive:  /home/jupyter/data/fairseq/evaluation/ru/spa-eng.zip\n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/ru/_about.txt  \n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/ru/spa.txt  \n",
      "download and extract spa-eng data in /home/jupyter/data/fairseq/evaluation/ru\n",
      "===========================\n",
      "===========================\n",
      "select 100000 of /home/jupyter/data/fairseq/evaluation/ru/en-es.es.txt to /home/jupyter/data/fairseq/evaluation/ru/es.txt \n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "! ./anki.sh en,zh cmn-eng $outpath anki.py && ./fairseq/samples.sh $outpath/en-zh.zh.txt $outpath/zh.txt $n_samples\n",
    "! ./anki.sh en,fr fra-eng $outpath anki.py && ./fairseq/samples.sh $outpath/en-fr.fr.txt $outpath/fr.txt $n_samples\n",
    "! ./anki.sh de,en deu-eng $outpath anki.py && ./fairseq/samples.sh $outpath/de-en.de.txt $outpath/de.txt $n_samples\n",
    "! ./anki.sh en,it ita-eng $outpath anki.py && ./fairseq/samples.sh $outpath/en-it.it.txt $outpath/it.txt $n_samples\n",
    "! ./anki.sh en,ru rus-eng $outpath anki.py && ./fairseq/samples.sh $outpath/en-ru.ru.txt $outpath/ru.txt $n_samples\n",
    "! ./anki.sh en,es spa-eng $outpath anki.py && ./fairseq/samples.sh $outpath/en-es.es.txt $outpath/es.txt $n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### en data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "select 100000 of /home/jupyter/data/fairseq/evaluation/ru/de-en.en.txt to /home/jupyter/data/fairseq/evaluation/ru/en.txt \n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "! ./fairseq/samples.sh $outpath/de-en.en.txt $outpath/en.txt $n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to train your one model, look https://github.com/pytorch/fairseq/tree/master/examples/language_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_path=/home/jupyter/fairseq_models\n"
     ]
    }
   ],
   "source": [
    "%env tgt_path=/home/jupyter/fairseq_models\n",
    "! chmod +x ./fairseq/download_model.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-31 14:13:11--  https://dl.fbaipublicfiles.com/fairseq/models/lm/wmt19.ru.tar.gz\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 2606:4700:10::6816:4b8e, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2198716951 (2.0G) [application/gzip]\n",
      "Saving to: ‘/home/jupyter/fairseq_models/wmt19.ru.tar.gz’\n",
      "\n",
      "wmt19.ru.tar.gz     100%[===================>]   2.05G  25.4MB/s    in 98s     \n",
      "\n",
      "2020-05-31 14:14:50 (21.4 MB/s) - ‘/home/jupyter/fairseq_models/wmt19.ru.tar.gz’ saved [2198716951/2198716951]\n",
      "\n",
      "wmt19.ru/\n",
      "wmt19.ru/model.pt\n",
      "wmt19.ru/dict.txt\n",
      "wmt19.ru/bpecodes\n"
     ]
    }
   ],
   "source": [
    "! ./fairseq/download_model.sh ru $tgt_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install dependencies and clone fairseq if not already done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! pip install fastBPE sacremoses  \n",
    "! git clone https://github.com/pytorch/fairseq /home/jupyter/fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/fairseq\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jupyter/fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: modelpath=/home/jupyter/fairseq_models/wmt19.ru\n",
      "env: destdir=/home/jupyter/fairseq_data/ru\n",
      "env: src_lang=ru\n"
     ]
    }
   ],
   "source": [
    "#%env modelpath=$tgt_path/wmnt19.ru\n",
    "%env modelpath=/home/jupyter/fairseq_models/wmt19.ru\n",
    "%env destdir=/home/jupyter/fairseq_data/ru\n",
    "%env src_lang=ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ru vs en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_lang=en\n",
      "2020-05-31 14:21:38 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/home/jupyter/fairseq_data/ru/ru-en', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, quantization_config_path=None, seed=1, source_lang=None, srcdict='/home/jupyter/fairseq_models/wmt19.ru/dict.txt', target_lang=None, task='translation', tensorboard_logdir='', testpref='/home/jupyter/data/fairseq/evaluation/ru/en.txt', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=20)\n",
      "2020-05-31 14:21:39 | INFO | fairseq_cli.preprocess | [None] Dictionary: 31231 types\n",
      "2020-05-31 14:21:42 | INFO | fairseq_cli.preprocess | [None] /home/jupyter/data/fairseq/evaluation/ru/en.txt: 100000 sents, 774440 tokens, 48.9% replaced by <unk>\n",
      "2020-05-31 14:21:42 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /home/jupyter/fairseq_data/ru/ru-en\n",
      "2020-05-31 14:21:43 | INFO | fairseq_cli.eval_lm | Namespace(add_bos_token=False, all_gather_list_size=16384, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', context_window=400, cpu=False, criterion='cross_entropy', data='/home/jupyter/fairseq_data/ru/ru-en', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', empty_cache_freq=0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, max_sentences=2, max_target_positions=None, max_tokens=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, momentum=0.99, no_progress_bar=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='nag', output_dictionary_size=-1, output_word_probs=False, output_word_stats=False, past_target=False, path='/home/jupyter/fairseq_models/wmt19.ru/model.pt', quantization_config_path=None, quiet=False, remove_bpe=None, required_batch_size_multiple=8, results_path=None, sample_break_mode='none', seed=1, self_target=False, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, softmax_batch=9223372036854775807, task='language_modeling', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, tpu=False, truncate_sequence=False, user_dir=None, warmup_updates=0, weight_decay=0.0)\n",
      "2020-05-31 14:21:43 | INFO | fairseq.tasks.language_modeling | dictionary: 31232 types\n",
      "2020-05-31 14:21:43 | INFO | fairseq_cli.eval_lm | loading model(s) from /home/jupyter/fairseq_models/wmt19.ru/model.pt\n",
      "2020-05-31 14:21:49 | INFO | fairseq.tasks.language_modeling | dictionary: 31232 types\n",
      "2020-05-31 14:21:49 | INFO | fairseq.data.data_utils | loaded 100000 examples from: /home/jupyter/fairseq_data/ru/ru-en/test\n",
      "2020-05-31 14:21:49 | INFO | fairseq_cli.eval_lm | /home/jupyter/fairseq_data/ru/ru-en test 6915 examples\n",
      "2020-05-31 14:22:00 | INFO | fairseq_cli.eval_lm | num. model params: 399814656\n",
      "100%|██████████████████████████████| 3458/3458 [47:07<00:00,  1.44it/s, wps=274]2020-05-31 15:09:08 | INFO | fairseq.data.iterators | Data loading buffer is empty or nearly empty. This may indicate a data loading bottleneck, and increasing the number of workers (--num-workers) may help.\n",
      "2020-05-31 15:09:08 | INFO | fairseq_cli.eval_lm | Evaluated 774440 tokens in 2717.3s (285.00 tokens/s)\n",
      "2020-05-31 15:09:08 | INFO | fairseq_cli.eval_lm | Loss (base 2): 5.7343, Perplexity: 53.24\n"
     ]
    }
   ],
   "source": [
    "%env tgt_lang=en\n",
    "# Processes data (only --testpref)\n",
    "! fairseq-preprocess --only-source --testpref $outpath/$tgt_lang.txt --destdir $destdir/$src_lang-$tgt_lang --workers 20 --joined-dictionary --srcdict $modelpath/dict.txt\n",
    "# run evalution\n",
    "! fairseq-eval-lm $destdir/$src_lang-$tgt_lang --path $modelpath/model.pt --max-sentences 2 --tokens-per-sample 512 --context-window 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ru vs zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_lang=zh\n",
      "2020-05-31 15:14:55 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/home/jupyter/fairseq_data/ru/ru-zh', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, quantization_config_path=None, seed=1, source_lang=None, srcdict='/home/jupyter/fairseq_models/wmt19.ru/dict.txt', target_lang=None, task='translation', tensorboard_logdir='', testpref='/home/jupyter/data/fairseq/evaluation/ru/zh.txt', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=20)\n",
      "2020-05-31 15:14:55 | INFO | fairseq_cli.preprocess | [None] Dictionary: 31231 types\n",
      "2020-05-31 15:14:56 | INFO | fairseq_cli.preprocess | [None] /home/jupyter/data/fairseq/evaluation/ru/zh.txt: 22075 sents, 44300 tokens, 50.1% replaced by <unk>\n",
      "2020-05-31 15:14:56 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /home/jupyter/fairseq_data/ru/ru-zh\n",
      "2020-05-31 15:14:58 | INFO | fairseq_cli.eval_lm | Namespace(add_bos_token=False, all_gather_list_size=16384, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', context_window=400, cpu=False, criterion='cross_entropy', data='/home/jupyter/fairseq_data/ru/ru-zh', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', empty_cache_freq=0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, max_sentences=2, max_target_positions=None, max_tokens=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, momentum=0.99, no_progress_bar=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='nag', output_dictionary_size=-1, output_word_probs=False, output_word_stats=False, past_target=False, path='/home/jupyter/fairseq_models/wmt19.ru/model.pt', quantization_config_path=None, quiet=False, remove_bpe=None, required_batch_size_multiple=8, results_path=None, sample_break_mode='none', seed=1, self_target=False, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, softmax_batch=9223372036854775807, task='language_modeling', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, tpu=False, truncate_sequence=False, user_dir=None, warmup_updates=0, weight_decay=0.0)\n",
      "2020-05-31 15:14:58 | INFO | fairseq.tasks.language_modeling | dictionary: 31232 types\n",
      "2020-05-31 15:14:58 | INFO | fairseq_cli.eval_lm | loading model(s) from /home/jupyter/fairseq_models/wmt19.ru/model.pt\n",
      "2020-05-31 15:15:04 | INFO | fairseq.tasks.language_modeling | dictionary: 31232 types\n",
      "2020-05-31 15:15:04 | INFO | fairseq.data.data_utils | loaded 22075 examples from: /home/jupyter/fairseq_data/ru/ru-zh/test\n",
      "2020-05-31 15:15:04 | INFO | fairseq_cli.eval_lm | /home/jupyter/fairseq_data/ru/ru-zh test 396 examples\n",
      "2020-05-31 15:15:11 | INFO | fairseq_cli.eval_lm | num. model params: 399814656\n",
      "2020-05-31 15:16:25 | INFO | fairseq_cli.eval_lm | Evaluated 44300 tokens in 71.4s (620.15 tokens/s)\n",
      "2020-05-31 15:16:25 | INFO | fairseq_cli.eval_lm | Loss (base 2): 7.0946, Perplexity: 136.68\n"
     ]
    }
   ],
   "source": [
    "%env tgt_lang=zh\n",
    "# Processes data (only --testpref)\n",
    "! fairseq-preprocess --only-source --testpref $outpath/$tgt_lang.txt --destdir $destdir/$src_lang-$tgt_lang --workers 20 --joined-dictionary --srcdict $modelpath/dict.txt\n",
    "# run evalution\n",
    "! fairseq-eval-lm $destdir/$src_lang-$tgt_lang --path $modelpath/model.pt --max-sentences 2 --tokens-per-sample 512 --context-window 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ru vs fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_lang=fr\n",
      "2020-05-31 15:17:38 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/home/jupyter/fairseq_data/ru/ru-fr', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, quantization_config_path=None, seed=1, source_lang=None, srcdict='/home/jupyter/fairseq_models/wmt19.ru/dict.txt', target_lang=None, task='translation', tensorboard_logdir='', testpref='/home/jupyter/data/fairseq/evaluation/ru/fr.txt', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=20)\n",
      "2020-05-31 15:17:38 | INFO | fairseq_cli.preprocess | [None] Dictionary: 31231 types\n",
      "2020-05-31 15:17:43 | INFO | fairseq_cli.preprocess | [None] /home/jupyter/data/fairseq/evaluation/ru/fr.txt: 100000 sents, 797805 tokens, 66.1% replaced by <unk>\n",
      "2020-05-31 15:17:43 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /home/jupyter/fairseq_data/ru/ru-fr\n",
      "2020-05-31 15:17:44 | INFO | fairseq_cli.eval_lm | Namespace(add_bos_token=False, all_gather_list_size=16384, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', context_window=400, cpu=False, criterion='cross_entropy', data='/home/jupyter/fairseq_data/ru/ru-fr', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', empty_cache_freq=0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, max_sentences=2, max_target_positions=None, max_tokens=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, momentum=0.99, no_progress_bar=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='nag', output_dictionary_size=-1, output_word_probs=False, output_word_stats=False, past_target=False, path='/home/jupyter/fairseq_models/wmt19.ru/model.pt', quantization_config_path=None, quiet=False, remove_bpe=None, required_batch_size_multiple=8, results_path=None, sample_break_mode='none', seed=1, self_target=False, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, softmax_batch=9223372036854775807, task='language_modeling', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, tpu=False, truncate_sequence=False, user_dir=None, warmup_updates=0, weight_decay=0.0)\n",
      "2020-05-31 15:17:44 | INFO | fairseq.tasks.language_modeling | dictionary: 31232 types\n",
      "2020-05-31 15:17:44 | INFO | fairseq_cli.eval_lm | loading model(s) from /home/jupyter/fairseq_models/wmt19.ru/model.pt\n",
      "2020-05-31 15:17:50 | INFO | fairseq.tasks.language_modeling | dictionary: 31232 types\n",
      "2020-05-31 15:17:50 | INFO | fairseq.data.data_utils | loaded 100000 examples from: /home/jupyter/fairseq_data/ru/ru-fr/test\n",
      "2020-05-31 15:17:50 | INFO | fairseq_cli.eval_lm | /home/jupyter/fairseq_data/ru/ru-fr test 7124 examples\n",
      "2020-05-31 15:18:01 | INFO | fairseq_cli.eval_lm | num. model params: 399814656\n",
      "100%|██████████████████████████████| 3562/3562 [46:48<00:00,  1.22it/s, wps=284]2020-05-31 16:04:49 | INFO | fairseq.data.iterators | Data loading buffer is empty or nearly empty. This may indicate a data loading bottleneck, and increasing the number of workers (--num-workers) may help.\n",
      "2020-05-31 16:04:49 | INFO | fairseq_cli.eval_lm | Evaluated 797805 tokens in 2700.7s (295.40 tokens/s)\n",
      "2020-05-31 16:04:49 | INFO | fairseq_cli.eval_lm | Loss (base 2): 4.3653, Perplexity: 20.61\n"
     ]
    }
   ],
   "source": [
    "%env tgt_lang=fr\n",
    "# Processes data (only --testpref)\n",
    "! fairseq-preprocess --only-source --testpref $outpath/$tgt_lang.txt --destdir $destdir/$src_lang-$tgt_lang --workers 20 --joined-dictionary --srcdict $modelpath/dict.txt\n",
    "# run evalution\n",
    "! fairseq-eval-lm $destdir/$src_lang-$tgt_lang --path $modelpath/model.pt --max-sentences 2 --tokens-per-sample 512 --context-window 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ru vs de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_lang=de\n",
      "2020-05-31 16:05:48 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/home/jupyter/fairseq_data/ru/ru-de', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, quantization_config_path=None, seed=1, source_lang=None, srcdict='/home/jupyter/fairseq_models/wmt19.ru/dict.txt', target_lang=None, task='translation', tensorboard_logdir='', testpref='/home/jupyter/data/fairseq/evaluation/ru/de.txt', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=20)\n",
      "2020-05-31 16:05:48 | INFO | fairseq_cli.preprocess | [None] Dictionary: 31231 types\n",
      "2020-05-31 16:05:52 | INFO | fairseq_cli.preprocess | [None] /home/jupyter/data/fairseq/evaluation/ru/de.txt: 100000 sents, 778387 tokens, 79.6% replaced by <unk>\n",
      "2020-05-31 16:05:52 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /home/jupyter/fairseq_data/ru/ru-de\n",
      "2020-05-31 16:05:54 | INFO | fairseq_cli.eval_lm | Namespace(add_bos_token=False, all_gather_list_size=16384, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', context_window=400, cpu=False, criterion='cross_entropy', data='/home/jupyter/fairseq_data/ru/ru-de', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', empty_cache_freq=0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, max_sentences=2, max_target_positions=None, max_tokens=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, momentum=0.99, no_progress_bar=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='nag', output_dictionary_size=-1, output_word_probs=False, output_word_stats=False, past_target=False, path='/home/jupyter/fairseq_models/wmt19.ru/model.pt', quantization_config_path=None, quiet=False, remove_bpe=None, required_batch_size_multiple=8, results_path=None, sample_break_mode='none', seed=1, self_target=False, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, softmax_batch=9223372036854775807, task='language_modeling', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, tpu=False, truncate_sequence=False, user_dir=None, warmup_updates=0, weight_decay=0.0)\n",
      "2020-05-31 16:05:54 | INFO | fairseq.tasks.language_modeling | dictionary: 31232 types\n",
      "2020-05-31 16:05:54 | INFO | fairseq_cli.eval_lm | loading model(s) from /home/jupyter/fairseq_models/wmt19.ru/model.pt\n",
      "2020-05-31 16:05:59 | INFO | fairseq.tasks.language_modeling | dictionary: 31232 types\n",
      "2020-05-31 16:05:59 | INFO | fairseq.data.data_utils | loaded 100000 examples from: /home/jupyter/fairseq_data/ru/ru-de/test\n",
      "2020-05-31 16:05:59 | INFO | fairseq_cli.eval_lm | /home/jupyter/fairseq_data/ru/ru-de test 6950 examples\n",
      "2020-05-31 16:06:06 | INFO | fairseq_cli.eval_lm | num. model params: 399814656\n",
      "100%|██████████████████████████████| 3475/3475 [30:34<00:00,  1.23it/s, wps=424]2020-05-31 16:36:41 | INFO | fairseq.data.iterators | Data loading buffer is empty or nearly empty. This may indicate a data loading bottleneck, and increasing the number of workers (--num-workers) may help.\n",
      "2020-05-31 16:36:41 | INFO | fairseq_cli.eval_lm | Evaluated 778387 tokens in 1776.3s (438.20 tokens/s)\n",
      "2020-05-31 16:36:41 | INFO | fairseq_cli.eval_lm | Loss (base 2): 3.1756, Perplexity: 9.04\n"
     ]
    }
   ],
   "source": [
    "%env tgt_lang=de\n",
    "# Processes data (only --testpref)\n",
    "! fairseq-preprocess --only-source --testpref $outpath/$tgt_lang.txt --destdir $destdir/$src_lang-$tgt_lang --workers 20 --joined-dictionary --srcdict $modelpath/dict.txt\n",
    "# run evalution\n",
    "! fairseq-eval-lm $destdir/$src_lang-$tgt_lang --path $modelpath/model.pt --max-sentences 2 --tokens-per-sample 512 --context-window 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ru vs it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_lang=it\n",
      "2020-05-31 16:37:02 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/home/jupyter/fairseq_data/ru/ru-it', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, quantization_config_path=None, seed=1, source_lang=None, srcdict='/home/jupyter/fairseq_models/wmt19.ru/dict.txt', target_lang=None, task='translation', tensorboard_logdir='', testpref='/home/jupyter/data/fairseq/evaluation/ru/it.txt', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=20)\n",
      "2020-05-31 16:37:02 | INFO | fairseq_cli.preprocess | [None] Dictionary: 31231 types\n",
      "2020-05-31 16:37:06 | INFO | fairseq_cli.preprocess | [None] /home/jupyter/data/fairseq/evaluation/ru/it.txt: 100000 sents, 682297 tokens, 69.9% replaced by <unk>\n",
      "2020-05-31 16:37:06 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /home/jupyter/fairseq_data/ru/ru-it\n",
      "2020-05-31 16:37:07 | INFO | fairseq_cli.eval_lm | Namespace(add_bos_token=False, all_gather_list_size=16384, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', context_window=400, cpu=False, criterion='cross_entropy', data='/home/jupyter/fairseq_data/ru/ru-it', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', empty_cache_freq=0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, max_sentences=2, max_target_positions=None, max_tokens=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, momentum=0.99, no_progress_bar=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='nag', output_dictionary_size=-1, output_word_probs=False, output_word_stats=False, past_target=False, path='/home/jupyter/fairseq_models/wmt19.ru/model.pt', quantization_config_path=None, quiet=False, remove_bpe=None, required_batch_size_multiple=8, results_path=None, sample_break_mode='none', seed=1, self_target=False, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, softmax_batch=9223372036854775807, task='language_modeling', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, tpu=False, truncate_sequence=False, user_dir=None, warmup_updates=0, weight_decay=0.0)\n",
      "2020-05-31 16:37:07 | INFO | fairseq.tasks.language_modeling | dictionary: 31232 types\n",
      "2020-05-31 16:37:07 | INFO | fairseq_cli.eval_lm | loading model(s) from /home/jupyter/fairseq_models/wmt19.ru/model.pt\n",
      "2020-05-31 16:37:13 | INFO | fairseq.tasks.language_modeling | dictionary: 31232 types\n",
      "2020-05-31 16:37:13 | INFO | fairseq.data.data_utils | loaded 100000 examples from: /home/jupyter/fairseq_data/ru/ru-it/test\n",
      "2020-05-31 16:37:13 | INFO | fairseq_cli.eval_lm | /home/jupyter/fairseq_data/ru/ru-it test 6092 examples\n",
      "2020-05-31 16:37:23 | INFO | fairseq_cli.eval_lm | num. model params: 399814656\n",
      "100%|██████████████████████████████| 3046/3046 [40:41<00:00,  1.22it/s, wps=279]2020-05-31 17:18:05 | INFO | fairseq.data.iterators | Data loading buffer is empty or nearly empty. This may indicate a data loading bottleneck, and increasing the number of workers (--num-workers) may help.\n",
      "2020-05-31 17:18:05 | INFO | fairseq_cli.eval_lm | Evaluated 682297 tokens in 2345.9s (290.85 tokens/s)\n",
      "2020-05-31 17:18:05 | INFO | fairseq_cli.eval_lm | Loss (base 2): 4.3502, Perplexity: 20.40\n"
     ]
    }
   ],
   "source": [
    "%env tgt_lang=it\n",
    "# Processes data (only --testpref)\n",
    "! fairseq-preprocess --only-source --testpref $outpath/$tgt_lang.txt --destdir $destdir/$src_lang-$tgt_lang --workers 20 --joined-dictionary --srcdict $modelpath/dict.txt\n",
    "# run evalution\n",
    "! fairseq-eval-lm $destdir/$src_lang-$tgt_lang --path $modelpath/model.pt --max-sentences 2 --tokens-per-sample 512 --context-window 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ru vs ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_lang=ru\n",
      "2020-05-31 17:22:42 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/home/jupyter/fairseq_data/ru/ru-ru', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, quantization_config_path=None, seed=1, source_lang=None, srcdict='/home/jupyter/fairseq_models/wmt19.ru/dict.txt', target_lang=None, task='translation', tensorboard_logdir='', testpref='/home/jupyter/data/fairseq/evaluation/ru/ru.txt', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=20)\n",
      "2020-05-31 17:22:42 | INFO | fairseq_cli.preprocess | [None] Dictionary: 31231 types\n",
      "2020-05-31 17:22:46 | INFO | fairseq_cli.preprocess | [None] /home/jupyter/data/fairseq/evaluation/ru/ru.txt: 100000 sents, 665396 tokens, 35.8% replaced by <unk>\n",
      "2020-05-31 17:22:46 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /home/jupyter/fairseq_data/ru/ru-ru\n",
      "2020-05-31 17:22:47 | INFO | fairseq_cli.eval_lm | Namespace(add_bos_token=False, all_gather_list_size=16384, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', context_window=400, cpu=False, criterion='cross_entropy', data='/home/jupyter/fairseq_data/ru/ru-ru', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', empty_cache_freq=0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, max_sentences=2, max_target_positions=None, max_tokens=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, momentum=0.99, no_progress_bar=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='nag', output_dictionary_size=-1, output_word_probs=False, output_word_stats=False, past_target=False, path='/home/jupyter/fairseq_models/wmt19.ru/model.pt', quantization_config_path=None, quiet=False, remove_bpe=None, required_batch_size_multiple=8, results_path=None, sample_break_mode='none', seed=1, self_target=False, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, softmax_batch=9223372036854775807, task='language_modeling', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, tpu=False, truncate_sequence=False, user_dir=None, warmup_updates=0, weight_decay=0.0)\n",
      "2020-05-31 17:22:48 | INFO | fairseq.tasks.language_modeling | dictionary: 31232 types\n",
      "2020-05-31 17:22:48 | INFO | fairseq_cli.eval_lm | loading model(s) from /home/jupyter/fairseq_models/wmt19.ru/model.pt\n",
      "2020-05-31 17:22:53 | INFO | fairseq.tasks.language_modeling | dictionary: 31232 types\n",
      "2020-05-31 17:22:53 | INFO | fairseq.data.data_utils | loaded 100000 examples from: /home/jupyter/fairseq_data/ru/ru-ru/test\n",
      "2020-05-31 17:22:53 | INFO | fairseq_cli.eval_lm | /home/jupyter/fairseq_data/ru/ru-ru test 5942 examples\n",
      "2020-05-31 17:23:04 | INFO | fairseq_cli.eval_lm | num. model params: 399814656\n",
      "100%|██████████████████████████████| 2971/2971 [24:08<00:00,  4.00it/s, wps=459]2020-05-31 17:47:12 | INFO | fairseq.data.iterators | Data loading buffer is empty or nearly empty. This may indicate a data loading bottleneck, and increasing the number of workers (--num-workers) may help.\n",
      "2020-05-31 17:47:12 | INFO | fairseq_cli.eval_lm | Evaluated 665396 tokens in 1429.4s (465.51 tokens/s)\n",
      "2020-05-31 17:47:12 | INFO | fairseq_cli.eval_lm | Loss (base 2): 7.3750, Perplexity: 166.00\n"
     ]
    }
   ],
   "source": [
    "%env tgt_lang=ru\n",
    "# Processes data (only --testpref)\n",
    "! fairseq-preprocess --only-source --testpref $outpath/$tgt_lang.txt --destdir $destdir/$src_lang-$tgt_lang --workers 20 --joined-dictionary --srcdict $modelpath/dict.txt\n",
    "# run evalution\n",
    "! fairseq-eval-lm $destdir/$src_lang-$tgt_lang --path $modelpath/model.pt --max-sentences 2 --tokens-per-sample 512 --context-window 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ru vs es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_lang=es\n",
      "2020-05-31 17:47:45 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/home/jupyter/fairseq_data/ru/ru-es', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, quantization_config_path=None, seed=1, source_lang=None, srcdict='/home/jupyter/fairseq_models/wmt19.ru/dict.txt', target_lang=None, task='translation', tensorboard_logdir='', testpref='/home/jupyter/data/fairseq/evaluation/ru/es.txt', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=20)\n",
      "2020-05-31 17:47:45 | INFO | fairseq_cli.preprocess | [None] Dictionary: 31231 types\n",
      "2020-05-31 17:47:49 | INFO | fairseq_cli.preprocess | [None] /home/jupyter/data/fairseq/evaluation/ru/es.txt: 100000 sents, 716155 tokens, 64.0% replaced by <unk>\n",
      "2020-05-31 17:47:49 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /home/jupyter/fairseq_data/ru/ru-es\n",
      "2020-05-31 17:47:50 | INFO | fairseq_cli.eval_lm | Namespace(add_bos_token=False, all_gather_list_size=16384, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', context_window=400, cpu=False, criterion='cross_entropy', data='/home/jupyter/fairseq_data/ru/ru-es', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', empty_cache_freq=0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, max_sentences=2, max_target_positions=None, max_tokens=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, momentum=0.99, no_progress_bar=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='nag', output_dictionary_size=-1, output_word_probs=False, output_word_stats=False, past_target=False, path='/home/jupyter/fairseq_models/wmt19.ru/model.pt', quantization_config_path=None, quiet=False, remove_bpe=None, required_batch_size_multiple=8, results_path=None, sample_break_mode='none', seed=1, self_target=False, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, softmax_batch=9223372036854775807, task='language_modeling', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, tpu=False, truncate_sequence=False, user_dir=None, warmup_updates=0, weight_decay=0.0)\n",
      "2020-05-31 17:47:50 | INFO | fairseq.tasks.language_modeling | dictionary: 31232 types\n",
      "2020-05-31 17:47:50 | INFO | fairseq_cli.eval_lm | loading model(s) from /home/jupyter/fairseq_models/wmt19.ru/model.pt\n",
      "2020-05-31 17:47:59 | INFO | fairseq.tasks.language_modeling | dictionary: 31232 types\n",
      "2020-05-31 17:47:59 | INFO | fairseq.data.data_utils | loaded 100000 examples from: /home/jupyter/fairseq_data/ru/ru-es/test\n",
      "2020-05-31 17:47:59 | INFO | fairseq_cli.eval_lm | /home/jupyter/fairseq_data/ru/ru-es test 6395 examples\n",
      "2020-05-31 17:48:03 | INFO | fairseq_cli.eval_lm | num. model params: 399814656\n",
      "100%|██████████████████████████████| 3198/3198 [43:09<00:00,  1.43it/s, wps=277]2020-05-31 18:31:12 | INFO | fairseq.data.iterators | Data loading buffer is empty or nearly empty. This may indicate a data loading bottleneck, and increasing the number of workers (--num-workers) may help.\n",
      "2020-05-31 18:31:12 | INFO | fairseq_cli.eval_lm | Evaluated 716155 tokens in 2487.6s (287.89 tokens/s)\n",
      "2020-05-31 18:31:12 | INFO | fairseq_cli.eval_lm | Loss (base 2): 4.6477, Perplexity: 25.07\n"
     ]
    }
   ],
   "source": [
    "%env tgt_lang=es\n",
    "# Processes data (only --testpref)\n",
    "! fairseq-preprocess --only-source --testpref $outpath/$tgt_lang.txt --destdir $destdir/$src_lang-$tgt_lang --workers 20 --joined-dictionary --srcdict $modelpath/dict.txt\n",
    "# run evalution\n",
    "! fairseq-eval-lm $destdir/$src_lang-$tgt_lang --path $modelpath/model.pt --max-sentences 2 --tokens-per-sample 512 --context-window 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
