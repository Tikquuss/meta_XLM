{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare text data for evaluation : en, zh, fr, de, it, ru and es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used [anki's](http://www.manythings.org/anki/) data because the data is almost parallel.  \n",
    "[anki.sh] script downloads and extracts for the specified pair the corresponding parallel data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/meta_XLM\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jupyter/meta_XLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: outpath=/home/jupyter/data/fairseq/evaluation/en\n",
      "env: n_samples=100000\n"
     ]
    }
   ],
   "source": [
    "%env outpath=/home/jupyter/data/fairseq/evaluation/en\n",
    "%env n_samples=100000\n",
    "! chmod +x anki.sh\n",
    "! chmod +x fairseq/samples.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### download and extract && rename and reduce the number of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "--2020-05-31 14:09:54--  http://www.manythings.org/anki/cmn-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 172.67.173.198, 104.24.108.196, 104.24.109.196, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|172.67.173.198|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 963049 (940K) [application/zip]\n",
      "Saving to: ‘/home/jupyter/data/fairseq/evaluation/en/cmn-eng.zip’\n",
      "\n",
      "cmn-eng.zip         100%[===================>] 940.48K  3.38MB/s    in 0.3s    \n",
      "\n",
      "2020-05-31 14:09:55 (3.38 MB/s) - ‘/home/jupyter/data/fairseq/evaluation/en/cmn-eng.zip’ saved [963049/963049]\n",
      "\n",
      "Archive:  /home/jupyter/data/fairseq/evaluation/en/cmn-eng.zip\n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/en/cmn.txt  \n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/en/_about.txt  \n",
      "download and extract cmn-eng data in /home/jupyter/data/fairseq/evaluation/en\n",
      "===========================\n",
      "===========================\n",
      "select 100000 of /home/jupyter/data/fairseq/evaluation/en/en-zh.zh.txt to /home/jupyter/data/fairseq/evaluation/en/zh.txt \n",
      "===========================\n",
      "===========================\n",
      "--2020-05-31 14:09:55--  http://www.manythings.org/anki/fra-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.24.108.196, 104.24.109.196, 172.67.173.198, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.24.108.196|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5982778 (5.7M) [application/zip]\n",
      "Saving to: ‘/home/jupyter/data/fairseq/evaluation/en/fra-eng.zip’\n",
      "\n",
      "fra-eng.zip         100%[===================>]   5.71M  13.5MB/s    in 0.4s    \n",
      "\n",
      "2020-05-31 14:09:56 (13.5 MB/s) - ‘/home/jupyter/data/fairseq/evaluation/en/fra-eng.zip’ saved [5982778/5982778]\n",
      "\n",
      "Archive:  /home/jupyter/data/fairseq/evaluation/en/fra-eng.zip\n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/en/_about.txt  \n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/en/fra.txt  \n",
      "download and extract fra-eng data in /home/jupyter/data/fairseq/evaluation/en\n",
      "===========================\n",
      "===========================\n",
      "select 100000 of /home/jupyter/data/fairseq/evaluation/en/en-fr.fr.txt to /home/jupyter/data/fairseq/evaluation/en/fr.txt \n",
      "===========================\n",
      "===========================\n",
      "--2020-05-31 14:09:58--  http://www.manythings.org/anki/deu-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 172.67.173.198, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7876575 (7.5M) [application/zip]\n",
      "Saving to: ‘/home/jupyter/data/fairseq/evaluation/en/deu-eng.zip’\n",
      "\n",
      "deu-eng.zip         100%[===================>]   7.51M  16.0MB/s    in 0.5s    \n",
      "\n",
      "2020-05-31 14:09:59 (16.0 MB/s) - ‘/home/jupyter/data/fairseq/evaluation/en/deu-eng.zip’ saved [7876575/7876575]\n",
      "\n",
      "Archive:  /home/jupyter/data/fairseq/evaluation/en/deu-eng.zip\n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/en/deu.txt  \n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/en/_about.txt  \n",
      "download and extract deu-eng data in /home/jupyter/data/fairseq/evaluation/en\n",
      "===========================\n",
      "===========================\n",
      "select 100000 of /home/jupyter/data/fairseq/evaluation/en/de-en.de.txt to /home/jupyter/data/fairseq/evaluation/en/de.txt \n",
      "===========================\n",
      "===========================\n",
      "--2020-05-31 14:10:01--  http://www.manythings.org/anki/ita-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 172.67.173.198, 104.24.108.196, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7345811 (7.0M) [application/zip]\n",
      "Saving to: ‘/home/jupyter/data/fairseq/evaluation/en/ita-eng.zip’\n",
      "\n",
      "ita-eng.zip         100%[===================>]   7.00M  16.2MB/s    in 0.4s    \n",
      "\n",
      "2020-05-31 14:10:02 (16.2 MB/s) - ‘/home/jupyter/data/fairseq/evaluation/en/ita-eng.zip’ saved [7345811/7345811]\n",
      "\n",
      "Archive:  /home/jupyter/data/fairseq/evaluation/en/ita-eng.zip\n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/en/ita.txt  \n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/en/_about.txt  \n",
      "download and extract ita-eng data in /home/jupyter/data/fairseq/evaluation/en\n",
      "===========================\n",
      "===========================\n",
      "select 100000 of /home/jupyter/data/fairseq/evaluation/en/en-it.it.txt to /home/jupyter/data/fairseq/evaluation/en/it.txt \n",
      "===========================\n",
      "===========================\n",
      "--2020-05-31 14:10:05--  http://www.manythings.org/anki/rus-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.24.108.196, 104.24.109.196, 172.67.173.198, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.24.108.196|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12863721 (12M) [application/zip]\n",
      "Saving to: ‘/home/jupyter/data/fairseq/evaluation/en/rus-eng.zip’\n",
      "\n",
      "rus-eng.zip         100%[===================>]  12.27M  21.5MB/s    in 0.6s    \n",
      "\n",
      "2020-05-31 14:10:06 (21.5 MB/s) - ‘/home/jupyter/data/fairseq/evaluation/en/rus-eng.zip’ saved [12863721/12863721]\n",
      "\n",
      "Archive:  /home/jupyter/data/fairseq/evaluation/en/rus-eng.zip\n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/en/rus.txt  \n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/en/_about.txt  \n",
      "download and extract rus-eng data in /home/jupyter/data/fairseq/evaluation/en\n",
      "===========================\n",
      "===========================\n",
      "select 100000 of /home/jupyter/data/fairseq/evaluation/en/en-ru.ru.txt to /home/jupyter/data/fairseq/evaluation/en/ru.txt \n",
      "===========================\n",
      "===========================\n",
      "--2020-05-31 14:10:11--  http://www.manythings.org/anki/spa-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 172.67.173.198, 104.24.108.196, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4781548 (4.6M) [application/zip]\n",
      "Saving to: ‘/home/jupyter/data/fairseq/evaluation/en/spa-eng.zip’\n",
      "\n",
      "spa-eng.zip         100%[===================>]   4.56M  11.9MB/s    in 0.4s    \n",
      "\n",
      "2020-05-31 14:10:12 (11.9 MB/s) - ‘/home/jupyter/data/fairseq/evaluation/en/spa-eng.zip’ saved [4781548/4781548]\n",
      "\n",
      "Archive:  /home/jupyter/data/fairseq/evaluation/en/spa-eng.zip\n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/en/_about.txt  \n",
      "  inflating: /home/jupyter/data/fairseq/evaluation/en/spa.txt  \n",
      "download and extract spa-eng data in /home/jupyter/data/fairseq/evaluation/en\n",
      "===========================\n",
      "===========================\n",
      "select 100000 of /home/jupyter/data/fairseq/evaluation/en/en-es.es.txt to /home/jupyter/data/fairseq/evaluation/en/es.txt \n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "! ./anki.sh en,zh cmn-eng $outpath anki.py && ./fairseq/samples.sh $outpath/en-zh.zh.txt $outpath/zh.txt $n_samples\n",
    "! ./anki.sh en,fr fra-eng $outpath anki.py && ./fairseq/samples.sh $outpath/en-fr.fr.txt $outpath/fr.txt $n_samples\n",
    "! ./anki.sh de,en deu-eng $outpath anki.py && ./fairseq/samples.sh $outpath/de-en.de.txt $outpath/de.txt $n_samples\n",
    "! ./anki.sh en,it ita-eng $outpath anki.py && ./fairseq/samples.sh $outpath/en-it.it.txt $outpath/it.txt $n_samples\n",
    "! ./anki.sh en,ru rus-eng $outpath anki.py && ./fairseq/samples.sh $outpath/en-ru.ru.txt $outpath/ru.txt $n_samples\n",
    "! ./anki.sh en,es spa-eng $outpath anki.py && ./fairseq/samples.sh $outpath/en-es.es.txt $outpath/es.txt $n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### en data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "select 100000 of /home/jupyter/data/fairseq/evaluation/en/de-en.en.txt to /home/jupyter/data/fairseq/evaluation/en/en.txt \n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "! ./fairseq/samples.sh $outpath/de-en.en.txt $outpath/en.txt $n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to train your one model, look https://github.com/pytorch/fairseq/tree/master/examples/language_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_path=/home/jupyter/fairseq_models\n"
     ]
    }
   ],
   "source": [
    "%env tgt_path=/home/jupyter/fairseq_models\n",
    "! chmod +x ./fairseq/download_model.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-31 14:11:23--  https://dl.fbaipublicfiles.com/fairseq/models/lm/wmt19.en.tar.gz\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 2606:4700:10::6816:4a8e, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3590918000 (3.3G) [application/gzip]\n",
      "Saving to: ‘/home/jupyter/fairseq_models/wmt19.en.tar.gz’\n",
      "\n",
      "wmt19.en.tar.gz     100%[===================>]   3.34G  11.6MB/s    in 2m 29s  \n",
      "\n",
      "2020-05-31 14:13:52 (23.0 MB/s) - ‘/home/jupyter/fairseq_models/wmt19.en.tar.gz’ saved [3590918000/3590918000]\n",
      "\n",
      "wmt19.en/\n",
      "wmt19.en/model.pt\n",
      "wmt19.en/dict.txt\n",
      "wmt19.en/bpecodes\n"
     ]
    }
   ],
   "source": [
    "! ./fairseq/download_model.sh en $tgt_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install dependencies and clone fairseq if not already done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! pip install fastBPE sacremoses  \n",
    "! git clone https://github.com/pytorch/fairseq /home/jupyter/fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/fairseq\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jupyter/fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: modelpath=/home/jupyter/fairseq_models/wmt19.en\n",
      "env: destdir=/home/jupyter/fairseq_data/en\n",
      "env: src_lang=en\n"
     ]
    }
   ],
   "source": [
    "#%env modelpath=$tgt_path/wmnt19.en\n",
    "%env modelpath=/home/jupyter/fairseq_models/wmt19.en\n",
    "%env destdir=/home/jupyter/fairseq_data/en\n",
    "%env src_lang=en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### en vs en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_lang=en\n",
      "2020-05-31 14:20:18 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/home/jupyter/fairseq_data/en/en-en', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, quantization_config_path=None, seed=1, source_lang=None, srcdict='/home/jupyter/fairseq_models/wmt19.en/dict.txt', target_lang=None, task='translation', tensorboard_logdir='', testpref='/home/jupyter/data/fairseq/evaluation/en/en.txt', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=20)\n",
      "2020-05-31 14:20:18 | INFO | fairseq_cli.preprocess | [None] Dictionary: 42021 types\n",
      "2020-05-31 14:20:20 | INFO | fairseq_cli.preprocess | [None] /home/jupyter/data/fairseq/evaluation/en/en.txt: 100000 sents, 774440 tokens, 21.3% replaced by <unk>\n",
      "2020-05-31 14:20:20 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /home/jupyter/fairseq_data/en/en-en\n",
      "2020-05-31 14:20:22 | INFO | fairseq_cli.eval_lm | Namespace(add_bos_token=False, all_gather_list_size=16384, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', context_window=400, cpu=False, criterion='cross_entropy', data='/home/jupyter/fairseq_data/en/en-en', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', empty_cache_freq=0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, max_sentences=2, max_target_positions=None, max_tokens=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, momentum=0.99, no_progress_bar=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='nag', output_dictionary_size=-1, output_word_probs=False, output_word_stats=False, past_target=False, path='/home/jupyter/fairseq_models/wmt19.en/model.pt', quantization_config_path=None, quiet=False, remove_bpe=None, required_batch_size_multiple=8, results_path=None, sample_break_mode='none', seed=1, self_target=False, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, softmax_batch=9223372036854775807, task='language_modeling', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, tpu=False, truncate_sequence=False, user_dir=None, warmup_updates=0, weight_decay=0.0)\n",
      "2020-05-31 14:20:22 | INFO | fairseq.tasks.language_modeling | dictionary: 42022 types\n",
      "2020-05-31 14:20:22 | INFO | fairseq_cli.eval_lm | loading model(s) from /home/jupyter/fairseq_models/wmt19.en/model.pt\n",
      "2020-05-31 14:20:31 | INFO | fairseq.tasks.language_modeling | dictionary: 42022 types\n",
      "2020-05-31 14:20:31 | INFO | fairseq.data.data_utils | loaded 100000 examples from: /home/jupyter/fairseq_data/en/en-en/test\n",
      "2020-05-31 14:20:31 | INFO | fairseq_cli.eval_lm | /home/jupyter/fairseq_data/en/en-en test 6915 examples\n",
      "2020-05-31 14:20:36 | INFO | fairseq_cli.eval_lm | num. model params: 655837184\n",
      "100%|██████████████████████████████| 3458/3458 [54:52<00:00,  1.44it/s, wps=235]2020-05-31 15:15:28 | INFO | fairseq.data.iterators | Data loading buffer is empty or nearly empty. This may indicate a data loading bottleneck, and increasing the number of workers (--num-workers) may help.\n",
      "2020-05-31 15:15:28 | INFO | fairseq_cli.eval_lm | Evaluated 774440 tokens in 3213.1s (241.03 tokens/s)\n",
      "2020-05-31 15:15:28 | INFO | fairseq_cli.eval_lm | Loss (base 2): 6.7914, Perplexity: 110.77\n"
     ]
    }
   ],
   "source": [
    "%env tgt_lang=en\n",
    "# Processes data (only --testpref)\n",
    "! fairseq-preprocess --only-source --testpref $outpath/$tgt_lang.txt --destdir $destdir/$src_lang-$tgt_lang --workers 20 --joined-dictionary --srcdict $modelpath/dict.txt\n",
    "# run evalution\n",
    "! fairseq-eval-lm $destdir/$src_lang-$tgt_lang --path $modelpath/model.pt --max-sentences 2 --tokens-per-sample 512 --context-window 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### en vs zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_lang=zh\n",
      "2020-05-31 15:16:14 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/home/jupyter/fairseq_data/en/en-zh', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, quantization_config_path=None, seed=1, source_lang=None, srcdict='/home/jupyter/fairseq_models/wmt19.en/dict.txt', target_lang=None, task='translation', tensorboard_logdir='', testpref='/home/jupyter/data/fairseq/evaluation/en/zh.txt', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=20)\n",
      "2020-05-31 15:16:14 | INFO | fairseq_cli.preprocess | [None] Dictionary: 42021 types\n",
      "2020-05-31 15:16:15 | INFO | fairseq_cli.preprocess | [None] /home/jupyter/data/fairseq/evaluation/en/zh.txt: 22075 sents, 44300 tokens, 50.1% replaced by <unk>\n",
      "2020-05-31 15:16:15 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /home/jupyter/fairseq_data/en/en-zh\n",
      "2020-05-31 15:16:17 | INFO | fairseq_cli.eval_lm | Namespace(add_bos_token=False, all_gather_list_size=16384, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', context_window=400, cpu=False, criterion='cross_entropy', data='/home/jupyter/fairseq_data/en/en-zh', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', empty_cache_freq=0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, max_sentences=2, max_target_positions=None, max_tokens=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, momentum=0.99, no_progress_bar=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='nag', output_dictionary_size=-1, output_word_probs=False, output_word_stats=False, past_target=False, path='/home/jupyter/fairseq_models/wmt19.en/model.pt', quantization_config_path=None, quiet=False, remove_bpe=None, required_batch_size_multiple=8, results_path=None, sample_break_mode='none', seed=1, self_target=False, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, softmax_batch=9223372036854775807, task='language_modeling', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, tpu=False, truncate_sequence=False, user_dir=None, warmup_updates=0, weight_decay=0.0)\n",
      "2020-05-31 15:16:17 | INFO | fairseq.tasks.language_modeling | dictionary: 42022 types\n",
      "2020-05-31 15:16:17 | INFO | fairseq_cli.eval_lm | loading model(s) from /home/jupyter/fairseq_models/wmt19.en/model.pt\n",
      "2020-05-31 15:16:27 | INFO | fairseq.tasks.language_modeling | dictionary: 42022 types\n",
      "2020-05-31 15:16:27 | INFO | fairseq.data.data_utils | loaded 22075 examples from: /home/jupyter/fairseq_data/en/en-zh/test\n",
      "2020-05-31 15:16:27 | INFO | fairseq_cli.eval_lm | /home/jupyter/fairseq_data/en/en-zh test 396 examples\n",
      "2020-05-31 15:16:34 | INFO | fairseq_cli.eval_lm | num. model params: 655837184\n",
      "2020-05-31 15:19:47 | INFO | fairseq_cli.eval_lm | Evaluated 44300 tokens in 188.1s (235.56 tokens/s)\n",
      "2020-05-31 15:19:47 | INFO | fairseq_cli.eval_lm | Loss (base 2): 2.0899, Perplexity: 4.26\n"
     ]
    }
   ],
   "source": [
    "%env tgt_lang=zh\n",
    "# Processes data (only --testpref)\n",
    "! fairseq-preprocess --only-source --testpref $outpath/$tgt_lang.txt --destdir $destdir/$src_lang-$tgt_lang --workers 20 --joined-dictionary --srcdict $modelpath/dict.txt\n",
    "# run evalution\n",
    "! fairseq-eval-lm $destdir/$src_lang-$tgt_lang --path $modelpath/model.pt --max-sentences 2 --tokens-per-sample 512 --context-window 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### en vs fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_lang=fr\n",
      "2020-05-31 15:20:29 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/home/jupyter/fairseq_data/en/en-fr', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, quantization_config_path=None, seed=1, source_lang=None, srcdict='/home/jupyter/fairseq_models/wmt19.en/dict.txt', target_lang=None, task='translation', tensorboard_logdir='', testpref='/home/jupyter/data/fairseq/evaluation/en/fr.txt', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=20)\n",
      "2020-05-31 15:20:29 | INFO | fairseq_cli.preprocess | [None] Dictionary: 42021 types\n",
      "2020-05-31 15:20:33 | INFO | fairseq_cli.preprocess | [None] /home/jupyter/data/fairseq/evaluation/en/fr.txt: 100000 sents, 797805 tokens, 51.3% replaced by <unk>\n",
      "2020-05-31 15:20:33 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /home/jupyter/fairseq_data/en/en-fr\n",
      "2020-05-31 15:20:35 | INFO | fairseq_cli.eval_lm | Namespace(add_bos_token=False, all_gather_list_size=16384, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', context_window=400, cpu=False, criterion='cross_entropy', data='/home/jupyter/fairseq_data/en/en-fr', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', empty_cache_freq=0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, max_sentences=2, max_target_positions=None, max_tokens=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, momentum=0.99, no_progress_bar=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='nag', output_dictionary_size=-1, output_word_probs=False, output_word_stats=False, past_target=False, path='/home/jupyter/fairseq_models/wmt19.en/model.pt', quantization_config_path=None, quiet=False, remove_bpe=None, required_batch_size_multiple=8, results_path=None, sample_break_mode='none', seed=1, self_target=False, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, softmax_batch=9223372036854775807, task='language_modeling', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, tpu=False, truncate_sequence=False, user_dir=None, warmup_updates=0, weight_decay=0.0)\n",
      "2020-05-31 15:20:35 | INFO | fairseq.tasks.language_modeling | dictionary: 42022 types\n",
      "2020-05-31 15:20:35 | INFO | fairseq_cli.eval_lm | loading model(s) from /home/jupyter/fairseq_models/wmt19.en/model.pt\n",
      "2020-05-31 15:20:44 | INFO | fairseq.tasks.language_modeling | dictionary: 42022 types\n",
      "2020-05-31 15:20:44 | INFO | fairseq.data.data_utils | loaded 100000 examples from: /home/jupyter/fairseq_data/en/en-fr/test\n",
      "2020-05-31 15:20:44 | INFO | fairseq_cli.eval_lm | /home/jupyter/fairseq_data/en/en-fr test 7124 examples\n",
      "2020-05-31 15:20:55 | INFO | fairseq_cli.eval_lm | num. model params: 655837184\n",
      "100%|████████████████████████████| 3562/3562 [1:01:44<00:00,  1.25it/s, wps=215]2020-05-31 16:22:39 | INFO | fairseq.data.iterators | Data loading buffer is empty or nearly empty. This may indicate a data loading bottleneck, and increasing the number of workers (--num-workers) may help.\n",
      "2020-05-31 16:22:39 | INFO | fairseq_cli.eval_lm | Evaluated 797805 tokens in 3610.4s (220.97 tokens/s)\n",
      "2020-05-31 16:22:39 | INFO | fairseq_cli.eval_lm | Loss (base 2): 5.5023, Perplexity: 45.33\n"
     ]
    }
   ],
   "source": [
    "%env tgt_lang=fr\n",
    "# Processes data (only --testpref)\n",
    "! fairseq-preprocess --only-source --testpref $outpath/$tgt_lang.txt --destdir $destdir/$src_lang-$tgt_lang --workers 20 --joined-dictionary --srcdict $modelpath/dict.txt\n",
    "# run evalution\n",
    "! fairseq-eval-lm $destdir/$src_lang-$tgt_lang --path $modelpath/model.pt --max-sentences 2 --tokens-per-sample 512 --context-window 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### en vs de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_lang=de\n",
      "2020-05-31 16:25:31 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/home/jupyter/fairseq_data/en/en-de', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, quantization_config_path=None, seed=1, source_lang=None, srcdict='/home/jupyter/fairseq_models/wmt19.en/dict.txt', target_lang=None, task='translation', tensorboard_logdir='', testpref='/home/jupyter/data/fairseq/evaluation/en/de.txt', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=20)\n",
      "2020-05-31 16:25:31 | INFO | fairseq_cli.preprocess | [None] Dictionary: 42021 types\n",
      "2020-05-31 16:25:34 | INFO | fairseq_cli.preprocess | [None] /home/jupyter/data/fairseq/evaluation/en/de.txt: 100000 sents, 778387 tokens, 25.2% replaced by <unk>\n",
      "2020-05-31 16:25:34 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /home/jupyter/fairseq_data/en/en-de\n",
      "2020-05-31 16:25:36 | INFO | fairseq_cli.eval_lm | Namespace(add_bos_token=False, all_gather_list_size=16384, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', context_window=400, cpu=False, criterion='cross_entropy', data='/home/jupyter/fairseq_data/en/en-de', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', empty_cache_freq=0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, max_sentences=2, max_target_positions=None, max_tokens=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, momentum=0.99, no_progress_bar=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='nag', output_dictionary_size=-1, output_word_probs=False, output_word_stats=False, past_target=False, path='/home/jupyter/fairseq_models/wmt19.en/model.pt', quantization_config_path=None, quiet=False, remove_bpe=None, required_batch_size_multiple=8, results_path=None, sample_break_mode='none', seed=1, self_target=False, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, softmax_batch=9223372036854775807, task='language_modeling', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, tpu=False, truncate_sequence=False, user_dir=None, warmup_updates=0, weight_decay=0.0)\n",
      "2020-05-31 16:25:36 | INFO | fairseq.tasks.language_modeling | dictionary: 42022 types\n",
      "2020-05-31 16:25:36 | INFO | fairseq_cli.eval_lm | loading model(s) from /home/jupyter/fairseq_models/wmt19.en/model.pt\n",
      "2020-05-31 16:25:45 | INFO | fairseq.tasks.language_modeling | dictionary: 42022 types\n",
      "2020-05-31 16:25:45 | INFO | fairseq.data.data_utils | loaded 100000 examples from: /home/jupyter/fairseq_data/en/en-de/test\n",
      "2020-05-31 16:25:45 | INFO | fairseq_cli.eval_lm | /home/jupyter/fairseq_data/en/en-de test 6950 examples\n",
      "2020-05-31 16:25:52 | INFO | fairseq_cli.eval_lm | num. model params: 655837184\n",
      "100%|████████████████████████████| 3475/3475 [1:02:37<00:00,  1.19s/it, wps=207]2020-05-31 17:28:29 | INFO | fairseq.data.iterators | Data loading buffer is empty or nearly empty. This may indicate a data loading bottleneck, and increasing the number of workers (--num-workers) may help.\n",
      "2020-05-31 17:28:29 | INFO | fairseq_cli.eval_lm | Evaluated 778387 tokens in 3660.0s (212.67 tokens/s)\n",
      "2020-05-31 17:28:29 | INFO | fairseq_cli.eval_lm | Loss (base 2): 10.6465, Perplexity: 1602.92\n"
     ]
    }
   ],
   "source": [
    "%env tgt_lang=de\n",
    "# Processes data (only --testpref)\n",
    "! fairseq-preprocess --only-source --testpref $outpath/$tgt_lang.txt --destdir $destdir/$src_lang-$tgt_lang --workers 20 --joined-dictionary --srcdict $modelpath/dict.txt\n",
    "# run evalution\n",
    "! fairseq-eval-lm $destdir/$src_lang-$tgt_lang --path $modelpath/model.pt --max-sentences 2 --tokens-per-sample 512 --context-window 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### en vs it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_lang=it\n",
      "2020-05-31 17:47:50 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/home/jupyter/fairseq_data/en/en-it', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, quantization_config_path=None, seed=1, source_lang=None, srcdict='/home/jupyter/fairseq_models/wmt19.en/dict.txt', target_lang=None, task='translation', tensorboard_logdir='', testpref='/home/jupyter/data/fairseq/evaluation/en/it.txt', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=20)\n",
      "2020-05-31 17:47:51 | INFO | fairseq_cli.preprocess | [None] Dictionary: 42021 types\n",
      "2020-05-31 17:47:54 | INFO | fairseq_cli.preprocess | [None] /home/jupyter/data/fairseq/evaluation/en/it.txt: 100000 sents, 682297 tokens, 54.4% replaced by <unk>\n",
      "2020-05-31 17:47:54 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /home/jupyter/fairseq_data/en/en-it\n",
      "2020-05-31 17:47:56 | INFO | fairseq_cli.eval_lm | Namespace(add_bos_token=False, all_gather_list_size=16384, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', context_window=400, cpu=False, criterion='cross_entropy', data='/home/jupyter/fairseq_data/en/en-it', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', empty_cache_freq=0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, max_sentences=2, max_target_positions=None, max_tokens=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, momentum=0.99, no_progress_bar=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='nag', output_dictionary_size=-1, output_word_probs=False, output_word_stats=False, past_target=False, path='/home/jupyter/fairseq_models/wmt19.en/model.pt', quantization_config_path=None, quiet=False, remove_bpe=None, required_batch_size_multiple=8, results_path=None, sample_break_mode='none', seed=1, self_target=False, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, softmax_batch=9223372036854775807, task='language_modeling', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, tpu=False, truncate_sequence=False, user_dir=None, warmup_updates=0, weight_decay=0.0)\n",
      "2020-05-31 17:47:56 | INFO | fairseq.tasks.language_modeling | dictionary: 42022 types\n",
      "2020-05-31 17:47:56 | INFO | fairseq_cli.eval_lm | loading model(s) from /home/jupyter/fairseq_models/wmt19.en/model.pt\n",
      "2020-05-31 17:48:06 | INFO | fairseq.tasks.language_modeling | dictionary: 42022 types\n",
      "2020-05-31 17:48:06 | INFO | fairseq.data.data_utils | loaded 100000 examples from: /home/jupyter/fairseq_data/en/en-it/test\n",
      "2020-05-31 17:48:06 | INFO | fairseq_cli.eval_lm | /home/jupyter/fairseq_data/en/en-it test 6092 examples\n",
      "2020-05-31 17:48:14 | INFO | fairseq_cli.eval_lm | num. model params: 655837184\n",
      "100%|██████████████████████████████| 3046/3046 [48:55<00:00,  2.55it/s, wps=232]2020-05-31 18:37:09 | INFO | fairseq.data.iterators | Data loading buffer is empty or nearly empty. This may indicate a data loading bottleneck, and increasing the number of workers (--num-workers) may help.\n",
      "2020-05-31 18:37:09 | INFO | fairseq_cli.eval_lm | Evaluated 682297 tokens in 2864.1s (238.23 tokens/s)\n",
      "2020-05-31 18:37:09 | INFO | fairseq_cli.eval_lm | Loss (base 2): 5.3980, Perplexity: 42.17\n"
     ]
    }
   ],
   "source": [
    "%env tgt_lang=it\n",
    "# Processes data (only --testpref)\n",
    "! fairseq-preprocess --only-source --testpref $outpath/$tgt_lang.txt --destdir $destdir/$src_lang-$tgt_lang --workers 20 --joined-dictionary --srcdict $modelpath/dict.txt\n",
    "# run evalution\n",
    "! fairseq-eval-lm $destdir/$src_lang-$tgt_lang --path $modelpath/model.pt --max-sentences 2 --tokens-per-sample 512 --context-window 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### en vs ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_lang=ru\n",
      "2020-05-31 18:37:41 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/home/jupyter/fairseq_data/en/en-ru', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, quantization_config_path=None, seed=1, source_lang=None, srcdict='/home/jupyter/fairseq_models/wmt19.en/dict.txt', target_lang=None, task='translation', tensorboard_logdir='', testpref='/home/jupyter/data/fairseq/evaluation/en/ru.txt', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=20)\n",
      "2020-05-31 18:37:41 | INFO | fairseq_cli.preprocess | [None] Dictionary: 42021 types\n",
      "2020-05-31 18:37:45 | INFO | fairseq_cli.preprocess | [None] /home/jupyter/data/fairseq/evaluation/en/ru.txt: 100000 sents, 665396 tokens, 76.5% replaced by <unk>\n",
      "2020-05-31 18:37:45 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /home/jupyter/fairseq_data/en/en-ru\n",
      "2020-05-31 18:37:47 | INFO | fairseq_cli.eval_lm | Namespace(add_bos_token=False, all_gather_list_size=16384, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', context_window=400, cpu=False, criterion='cross_entropy', data='/home/jupyter/fairseq_data/en/en-ru', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', empty_cache_freq=0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, max_sentences=2, max_target_positions=None, max_tokens=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, momentum=0.99, no_progress_bar=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='nag', output_dictionary_size=-1, output_word_probs=False, output_word_stats=False, past_target=False, path='/home/jupyter/fairseq_models/wmt19.en/model.pt', quantization_config_path=None, quiet=False, remove_bpe=None, required_batch_size_multiple=8, results_path=None, sample_break_mode='none', seed=1, self_target=False, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, softmax_batch=9223372036854775807, task='language_modeling', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, tpu=False, truncate_sequence=False, user_dir=None, warmup_updates=0, weight_decay=0.0)\n",
      "2020-05-31 18:37:47 | INFO | fairseq.tasks.language_modeling | dictionary: 42022 types\n",
      "2020-05-31 18:37:47 | INFO | fairseq_cli.eval_lm | loading model(s) from /home/jupyter/fairseq_models/wmt19.en/model.pt\n",
      "2020-05-31 18:37:56 | INFO | fairseq.tasks.language_modeling | dictionary: 42022 types\n",
      "2020-05-31 18:37:56 | INFO | fairseq.data.data_utils | loaded 100000 examples from: /home/jupyter/fairseq_data/en/en-ru/test\n",
      "2020-05-31 18:37:56 | INFO | fairseq_cli.eval_lm | /home/jupyter/fairseq_data/en/en-ru test 5942 examples\n",
      "2020-05-31 18:38:00 | INFO | fairseq_cli.eval_lm | num. model params: 655837184\n",
      "100%|██████████████████████████████| 2971/2971 [19:10<00:00,  2.58it/s, wps=578]2020-05-31 18:57:11 | INFO | fairseq.data.iterators | Data loading buffer is empty or nearly empty. This may indicate a data loading bottleneck, and increasing the number of workers (--num-workers) may help.\n",
      "2020-05-31 18:57:11 | INFO | fairseq_cli.eval_lm | Evaluated 665396 tokens in 1147.6s (579.80 tokens/s)\n",
      "2020-05-31 18:57:11 | INFO | fairseq_cli.eval_lm | Loss (base 2): 5.0398, Perplexity: 32.89\n"
     ]
    }
   ],
   "source": [
    "%env tgt_lang=ru\n",
    "# Processes data (only --testpref)\n",
    "! fairseq-preprocess --only-source --testpref $outpath/$tgt_lang.txt --destdir $destdir/$src_lang-$tgt_lang --workers 20 --joined-dictionary --srcdict $modelpath/dict.txt\n",
    "# run evalution\n",
    "! fairseq-eval-lm $destdir/$src_lang-$tgt_lang --path $modelpath/model.pt --max-sentences 2 --tokens-per-sample 512 --context-window 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### en vs es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: tgt_lang=es\n",
      "2020-05-31 19:03:49 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/home/jupyter/fairseq_data/en/en-es', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer='nag', padding_factor=8, quantization_config_path=None, seed=1, source_lang=None, srcdict='/home/jupyter/fairseq_models/wmt19.en/dict.txt', target_lang=None, task='translation', tensorboard_logdir='', testpref='/home/jupyter/data/fairseq/evaluation/en/es.txt', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=20)\n",
      "2020-05-31 19:03:49 | INFO | fairseq_cli.preprocess | [None] Dictionary: 42021 types\n",
      "2020-05-31 19:03:52 | INFO | fairseq_cli.preprocess | [None] /home/jupyter/data/fairseq/evaluation/en/es.txt: 100000 sents, 716155 tokens, 53.5% replaced by <unk>\n",
      "2020-05-31 19:03:52 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /home/jupyter/fairseq_data/en/en-es\n",
      "2020-05-31 19:03:54 | INFO | fairseq_cli.eval_lm | Namespace(add_bos_token=False, all_gather_list_size=16384, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', context_window=400, cpu=False, criterion='cross_entropy', data='/home/jupyter/fairseq_data/en/en-es', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', empty_cache_freq=0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, max_sentences=2, max_target_positions=None, max_tokens=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, momentum=0.99, no_progress_bar=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='nag', output_dictionary_size=-1, output_word_probs=False, output_word_stats=False, past_target=False, path='/home/jupyter/fairseq_models/wmt19.en/model.pt', quantization_config_path=None, quiet=False, remove_bpe=None, required_batch_size_multiple=8, results_path=None, sample_break_mode='none', seed=1, self_target=False, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, softmax_batch=9223372036854775807, task='language_modeling', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, tpu=False, truncate_sequence=False, user_dir=None, warmup_updates=0, weight_decay=0.0)\n",
      "2020-05-31 19:03:54 | INFO | fairseq.tasks.language_modeling | dictionary: 42022 types\n",
      "2020-05-31 19:03:54 | INFO | fairseq_cli.eval_lm | loading model(s) from /home/jupyter/fairseq_models/wmt19.en/model.pt\n",
      "2020-05-31 19:04:03 | INFO | fairseq.tasks.language_modeling | dictionary: 42022 types\n",
      "2020-05-31 19:04:03 | INFO | fairseq.data.data_utils | loaded 100000 examples from: /home/jupyter/fairseq_data/en/en-es/test\n",
      "2020-05-31 19:04:03 | INFO | fairseq_cli.eval_lm | /home/jupyter/fairseq_data/en/en-es test 6395 examples\n",
      "2020-05-31 19:04:06 | INFO | fairseq_cli.eval_lm | num. model params: 655837184\n",
      "100%|██████████████████████████████| 3198/3198 [20:46<00:00,  3.00it/s, wps=575]2020-05-31 19:24:53 | INFO | fairseq.data.iterators | Data loading buffer is empty or nearly empty. This may indicate a data loading bottleneck, and increasing the number of workers (--num-workers) may help.\n",
      "2020-05-31 19:24:53 | INFO | fairseq_cli.eval_lm | Evaluated 716155 tokens in 1242.5s (576.40 tokens/s)\n",
      "2020-05-31 19:24:53 | INFO | fairseq_cli.eval_lm | Loss (base 2): 5.6929, Perplexity: 51.73\n"
     ]
    }
   ],
   "source": [
    "%env tgt_lang=es\n",
    "# Processes data (only --testpref)\n",
    "! fairseq-preprocess --only-source --testpref $outpath/$tgt_lang.txt --destdir $destdir/$src_lang-$tgt_lang --workers 20 --joined-dictionary --srcdict $modelpath/dict.txt\n",
    "# run evalution\n",
    "! fairseq-eval-lm $destdir/$src_lang-$tgt_lang --path $modelpath/model.pt --max-sentences 2 --tokens-per-sample 512 --context-window 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
